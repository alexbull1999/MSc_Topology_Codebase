Starting Surface Distance Metric Analysis job...
Job ID: 181761
Node: gpuvm15
Time: Fri 11 Jul 23:11:23 BST 2025
Loading CUDA...
Activating conda environment...
Activated conda environment: /vol/bitbucket/ahb24/tda_entailment_new
Python location: /vol/bitbucket/ahb24/tda_entailment_new/bin/python
Checking GPU availability...
Fri Jul 11 23:11:25 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:06.0 Off |                    0 |
| N/A   42C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Testing PyTorch and CUDA...
PyTorch version: 2.4.1
CUDA available: True
CUDA device: Tesla T4
GPU memory: 15.6 GB
PyTorch setup verified!

Starting AutoEncoder Pipeline...

SUPERVISED CONTRASTIVE AUTOENCODER - FULL PIPELINE
============================================================
Start time: 2025-07-11 23:11:49.415219

Using device: cuda
Experiment setup complete: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149
Loading SNLI data...
==================================================
Starting data loading pipeline...
==================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
Loaded 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
Loaded 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
Loaded 9824 test samples
Generating lattice containment embeddings for training...
Generating lattice containment embeddings on cuda
Processing 549367 samples in batches of 1000
Processing batch 1/550
Processing batch 2/550
Processing batch 3/550
Processing batch 4/550
Processing batch 5/550
Processing batch 6/550
Processing batch 7/550
Processing batch 8/550
Processing batch 9/550
Processing batch 10/550
Processing batch 11/550
Processing batch 12/550
Processing batch 13/550
Processing batch 14/550
Processing batch 15/550
Processing batch 16/550
Processing batch 17/550
Processing batch 18/550
Processing batch 19/550
Processing batch 20/550
Processing batch 21/550
Processing batch 22/550
Processing batch 23/550
Processing batch 24/550
Processing batch 25/550
Processing batch 26/550
Processing batch 27/550
Processing batch 28/550
Processing batch 29/550
Processing batch 30/550
Processing batch 31/550
Processing batch 32/550
Processing batch 33/550
Processing batch 34/550
Processing batch 35/550
Processing batch 36/550
Processing batch 37/550
Processing batch 38/550
Processing batch 39/550
Processing batch 40/550
Processing batch 41/550
Processing batch 42/550
Processing batch 43/550
Processing batch 44/550
Processing batch 45/550
Processing batch 46/550
Processing batch 47/550
Processing batch 48/550
Processing batch 49/550
Processing batch 50/550
Processing batch 51/550
Processing batch 52/550
Processing batch 53/550
Processing batch 54/550
Processing batch 55/550
Processing batch 56/550
Processing batch 57/550
Processing batch 58/550
Processing batch 59/550
Processing batch 60/550
Processing batch 61/550
Processing batch 62/550
Processing batch 63/550
Processing batch 64/550
Processing batch 65/550
Processing batch 66/550
Processing batch 67/550
Processing batch 68/550
Processing batch 69/550
Processing batch 70/550
Processing batch 71/550
Processing batch 72/550
Processing batch 73/550
Processing batch 74/550
Processing batch 75/550
Processing batch 76/550
Processing batch 77/550
Processing batch 78/550
Processing batch 79/550
Processing batch 80/550
Processing batch 81/550
Processing batch 82/550
Processing batch 83/550
Processing batch 84/550
Processing batch 85/550
Processing batch 86/550
Processing batch 87/550
Processing batch 88/550
Processing batch 89/550
Processing batch 90/550
Processing batch 91/550
Processing batch 92/550
Processing batch 93/550
Processing batch 94/550
Processing batch 95/550
Processing batch 96/550
Processing batch 97/550
Processing batch 98/550
Processing batch 99/550
Processing batch 100/550
Processing batch 101/550
Processing batch 102/550
Processing batch 103/550
Processing batch 104/550
Processing batch 105/550
Processing batch 106/550
Processing batch 107/550
Processing batch 108/550
Processing batch 109/550
Processing batch 110/550
Processing batch 111/550
Processing batch 112/550
Processing batch 113/550
Processing batch 114/550
Processing batch 115/550
Processing batch 116/550
Processing batch 117/550
Processing batch 118/550
Processing batch 119/550
Processing batch 120/550
Processing batch 121/550
Processing batch 122/550
Processing batch 123/550
Processing batch 124/550
Processing batch 125/550
Processing batch 126/550
Processing batch 127/550
Processing batch 128/550
Processing batch 129/550
Processing batch 130/550
Processing batch 131/550
Processing batch 132/550
Processing batch 133/550
Processing batch 134/550
Processing batch 135/550
Processing batch 136/550
Processing batch 137/550
Processing batch 138/550
Processing batch 139/550
Processing batch 140/550
Processing batch 141/550
Processing batch 142/550
Processing batch 143/550
Processing batch 144/550
Processing batch 145/550
Processing batch 146/550
Processing batch 147/550
Processing batch 148/550
Processing batch 149/550
Processing batch 150/550
Processing batch 151/550
Processing batch 152/550
Processing batch 153/550
Processing batch 154/550
Processing batch 155/550
Processing batch 156/550
Processing batch 157/550
Processing batch 158/550
Processing batch 159/550
Processing batch 160/550
Processing batch 161/550
Processing batch 162/550
Processing batch 163/550
Processing batch 164/550
Processing batch 165/550
Processing batch 166/550
Processing batch 167/550
Processing batch 168/550
Processing batch 169/550
Processing batch 170/550
Processing batch 171/550
Processing batch 172/550
Processing batch 173/550
Processing batch 174/550
Processing batch 175/550
Processing batch 176/550
Processing batch 177/550
Processing batch 178/550
Processing batch 179/550
Processing batch 180/550
Processing batch 181/550
Processing batch 182/550
Processing batch 183/550
Processing batch 184/550
Processing batch 185/550
Processing batch 186/550
Processing batch 187/550
Processing batch 188/550
Processing batch 189/550
Processing batch 190/550
Processing batch 191/550
Processing batch 192/550
Processing batch 193/550
Processing batch 194/550
Processing batch 195/550
Processing batch 196/550
Processing batch 197/550
Processing batch 198/550
Processing batch 199/550
Processing batch 200/550
Processing batch 201/550
Processing batch 202/550
Processing batch 203/550
Processing batch 204/550
Processing batch 205/550
Processing batch 206/550
Processing batch 207/550
Processing batch 208/550
Processing batch 209/550
Processing batch 210/550
Processing batch 211/550
Processing batch 212/550
Processing batch 213/550
Processing batch 214/550
Processing batch 215/550
Processing batch 216/550
Processing batch 217/550
Processing batch 218/550
Processing batch 219/550
Processing batch 220/550
Processing batch 221/550
Processing batch 222/550
Processing batch 223/550
Processing batch 224/550
Processing batch 225/550
Processing batch 226/550
Processing batch 227/550
Processing batch 228/550
Processing batch 229/550
Processing batch 230/550
Processing batch 231/550
Processing batch 232/550
Processing batch 233/550
Processing batch 234/550
Processing batch 235/550
Processing batch 236/550
Processing batch 237/550
Processing batch 238/550
Processing batch 239/550
Processing batch 240/550
Processing batch 241/550
Processing batch 242/550
Processing batch 243/550
Processing batch 244/550
Processing batch 245/550
Processing batch 246/550
Processing batch 247/550
Processing batch 248/550
Processing batch 249/550
Processing batch 250/550
Processing batch 251/550
Processing batch 252/550
Processing batch 253/550
Processing batch 254/550
Processing batch 255/550
Processing batch 256/550
Processing batch 257/550
Processing batch 258/550
Processing batch 259/550
Processing batch 260/550
Processing batch 261/550
Processing batch 262/550
Processing batch 263/550
Processing batch 264/550
Processing batch 265/550
Processing batch 266/550
Processing batch 267/550
Processing batch 268/550
Processing batch 269/550
Processing batch 270/550
Processing batch 271/550
Processing batch 272/550
Processing batch 273/550
Processing batch 274/550
Processing batch 275/550
Processing batch 276/550
Processing batch 277/550
Processing batch 278/550
Processing batch 279/550
Processing batch 280/550
Processing batch 281/550
Processing batch 282/550
Processing batch 283/550
Processing batch 284/550
Processing batch 285/550
Processing batch 286/550
Processing batch 287/550
Processing batch 288/550
Processing batch 289/550
Processing batch 290/550
Processing batch 291/550
Processing batch 292/550
Processing batch 293/550
Processing batch 294/550
Processing batch 295/550
Processing batch 296/550
Processing batch 297/550
Processing batch 298/550
Processing batch 299/550
Processing batch 300/550
Processing batch 301/550
Processing batch 302/550
Processing batch 303/550
Processing batch 304/550
Processing batch 305/550
Processing batch 306/550
Processing batch 307/550
Processing batch 308/550
Processing batch 309/550
Processing batch 310/550
Processing batch 311/550
Processing batch 312/550
Processing batch 313/550
Processing batch 314/550
Processing batch 315/550
Processing batch 316/550
Processing batch 317/550
Processing batch 318/550
Processing batch 319/550
Processing batch 320/550
Processing batch 321/550
Processing batch 322/550
Processing batch 323/550
Processing batch 324/550
Processing batch 325/550
Processing batch 326/550
Processing batch 327/550
Processing batch 328/550
Processing batch 329/550
Processing batch 330/550
Processing batch 331/550
Processing batch 332/550
Processing batch 333/550
Processing batch 334/550
Processing batch 335/550
Processing batch 336/550
Processing batch 337/550
Processing batch 338/550
Processing batch 339/550
Processing batch 340/550
Processing batch 341/550
Processing batch 342/550
Processing batch 343/550
Processing batch 344/550
Processing batch 345/550
Processing batch 346/550
Processing batch 347/550
Processing batch 348/550
Processing batch 349/550
Processing batch 350/550
Processing batch 351/550
Processing batch 352/550
Processing batch 353/550
Processing batch 354/550
Processing batch 355/550
Processing batch 356/550
Processing batch 357/550
Processing batch 358/550
Processing batch 359/550
Processing batch 360/550
Processing batch 361/550
Processing batch 362/550
Processing batch 363/550
Processing batch 364/550
Processing batch 365/550
Processing batch 366/550
Processing batch 367/550
Processing batch 368/550
Processing batch 369/550
Processing batch 370/550
Processing batch 371/550
Processing batch 372/550
Processing batch 373/550
Processing batch 374/550
Processing batch 375/550
Processing batch 376/550
Processing batch 377/550
Processing batch 378/550
Processing batch 379/550
Processing batch 380/550
Processing batch 381/550
Processing batch 382/550
Processing batch 383/550
Processing batch 384/550
Processing batch 385/550
Processing batch 386/550
Processing batch 387/550
Processing batch 388/550
Processing batch 389/550
Processing batch 390/550
Processing batch 391/550
Processing batch 392/550
Processing batch 393/550
Processing batch 394/550
Processing batch 395/550
Processing batch 396/550
Processing batch 397/550
Processing batch 398/550
Processing batch 399/550
Processing batch 400/550
Processing batch 401/550
Processing batch 402/550
Processing batch 403/550
Processing batch 404/550
Processing batch 405/550
Processing batch 406/550
Processing batch 407/550
Processing batch 408/550
Processing batch 409/550
Processing batch 410/550
Processing batch 411/550
Processing batch 412/550
Processing batch 413/550
Processing batch 414/550
Processing batch 415/550
Processing batch 416/550
Processing batch 417/550
Processing batch 418/550
Processing batch 419/550
Processing batch 420/550
Processing batch 421/550
Processing batch 422/550
Processing batch 423/550
Processing batch 424/550
Processing batch 425/550
Processing batch 426/550
Processing batch 427/550
Processing batch 428/550
Processing batch 429/550
Processing batch 430/550
Processing batch 431/550
Processing batch 432/550
Processing batch 433/550
Processing batch 434/550
Processing batch 435/550
Processing batch 436/550
Processing batch 437/550
Processing batch 438/550
Processing batch 439/550
Processing batch 440/550
Processing batch 441/550
Processing batch 442/550
Processing batch 443/550
Processing batch 444/550
Processing batch 445/550
Processing batch 446/550
Processing batch 447/550
Processing batch 448/550
Processing batch 449/550
Processing batch 450/550
Processing batch 451/550
Processing batch 452/550
Processing batch 453/550
Processing batch 454/550
Processing batch 455/550
Processing batch 456/550
Processing batch 457/550
Processing batch 458/550
Processing batch 459/550
Processing batch 460/550
Processing batch 461/550
Processing batch 462/550
Processing batch 463/550
Processing batch 464/550
Processing batch 465/550
Processing batch 466/550
Processing batch 467/550
Processing batch 468/550
Processing batch 469/550
Processing batch 470/550
Processing batch 471/550
Processing batch 472/550
Processing batch 473/550
Processing batch 474/550
Processing batch 475/550
Processing batch 476/550
Processing batch 477/550
Processing batch 478/550
Processing batch 479/550
Processing batch 480/550
Processing batch 481/550
Processing batch 482/550
Processing batch 483/550
Processing batch 484/550
Processing batch 485/550
Processing batch 486/550
Processing batch 487/550
Processing batch 488/550
Processing batch 489/550
Processing batch 490/550
Processing batch 491/550
Processing batch 492/550
Processing batch 493/550
Processing batch 494/550
Processing batch 495/550
Processing batch 496/550
Processing batch 497/550
Processing batch 498/550
Processing batch 499/550
Processing batch 500/550
Processing batch 501/550
Processing batch 502/550
Processing batch 503/550
Processing batch 504/550
Processing batch 505/550
Processing batch 506/550
Processing batch 507/550
Processing batch 508/550
Processing batch 509/550
Processing batch 510/550
Processing batch 511/550
Processing batch 512/550
Processing batch 513/550
Processing batch 514/550
Processing batch 515/550
Processing batch 516/550
Processing batch 517/550
Processing batch 518/550
Processing batch 519/550
Processing batch 520/550
Processing batch 521/550
Processing batch 522/550
Processing batch 523/550
Processing batch 524/550
Processing batch 525/550
Processing batch 526/550
Processing batch 527/550
Processing batch 528/550
Processing batch 529/550
Processing batch 530/550
Processing batch 531/550
Processing batch 532/550
Processing batch 533/550
Processing batch 534/550
Processing batch 535/550
Processing batch 536/550
Processing batch 537/550
Processing batch 538/550
Processing batch 539/550
Processing batch 540/550
Processing batch 541/550
Processing batch 542/550
Processing batch 543/550
Processing batch 544/550
Processing batch 545/550
Processing batch 546/550
Processing batch 547/550
Processing batch 548/550
Processing batch 549/550
Processing batch 550/550
Generated lattice embeddings shape: torch.Size([549367, 768])
Generating lattice containment embeddings for validation...
Generating lattice containment embeddings on cuda
Processing 9842 samples in batches of 1000
Processing batch 1/10
Processing batch 2/10
Processing batch 3/10
Processing batch 4/10
Processing batch 5/10
Processing batch 6/10
Processing batch 7/10
Processing batch 8/10
Processing batch 9/10
Processing batch 10/10
Generated lattice embeddings shape: torch.Size([9842, 768])
Generating lattice containment embeddings for test...
Generating lattice containment embeddings on cuda
Processing 9824 samples in batches of 1000
Processing batch 1/10
Processing batch 2/10
Processing batch 3/10
Processing batch 4/10
Processing batch 5/10
Processing batch 6/10
Processing batch 7/10
Processing batch 8/10
Processing batch 9/10
Processing batch 10/10
Generated lattice embeddings shape: torch.Size([9824, 768])

Dataset Statistics:
------------------------------
Train: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
Validation: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
Test: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Creating balanced data loaders...
Batch size: 30
Samples per class per batch: 10
Effective batch size: 30
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class: 10
  Batch size: 30
  Number of batches: 18276
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class: 10
  Batch size: 30
  Number of batches: 323
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
Data loading completed!
Train: 549367 samples
Val: 9842 samples
Test: 9824 samples
Creating model and trainer...
==================================================
Model created with 1,089,355 parameters
Loss function created (α=1.0)
Optimizer created (lr=0.001)
Trainer initialized on device: cuda
Model parameters: 1,089,355
Starting model training...
==================================================
Starting SIMPLIFIED training (pure contrastive loss)...
==================================================

Epoch 1/50
------------------------------
Batch 0/18276: Loss = 1.9676 (C: 1.9676, R: 0.0000)
Batch 100/18276: Loss = 1.3970 (C: 1.3970, R: 0.0000)
Batch 200/18276: Loss = 1.0922 (C: 1.0922, R: 0.0000)
Batch 300/18276: Loss = 1.3173 (C: 1.3173, R: 0.0000)
Batch 400/18276: Loss = 1.6112 (C: 1.6112, R: 0.0000)
Batch 500/18276: Loss = 1.3819 (C: 1.3819, R: 0.0000)
Batch 600/18276: Loss = 1.1732 (C: 1.1732, R: 0.0000)
Batch 700/18276: Loss = 1.7199 (C: 1.7199, R: 0.0000)
Batch 800/18276: Loss = 1.4103 (C: 1.4103, R: 0.0000)
Batch 900/18276: Loss = 1.2113 (C: 1.2113, R: 0.0000)
Batch 1000/18276: Loss = 1.7083 (C: 1.7083, R: 0.0000)
Batch 1100/18276: Loss = 1.4034 (C: 1.4034, R: 0.0000)
Batch 1200/18276: Loss = 1.5479 (C: 1.5479, R: 0.0000)
Batch 1300/18276: Loss = 1.4097 (C: 1.4097, R: 0.0000)
Batch 1400/18276: Loss = 1.5035 (C: 1.5035, R: 0.0000)
Batch 1500/18276: Loss = 2.0014 (C: 2.0014, R: 0.0000)
Batch 1600/18276: Loss = 1.6413 (C: 1.6413, R: 0.0000)
Batch 1700/18276: Loss = 1.9215 (C: 1.9215, R: 0.0000)
Batch 1800/18276: Loss = 1.9081 (C: 1.9081, R: 0.0000)
Batch 1900/18276: Loss = 1.5468 (C: 1.5468, R: 0.0000)
Batch 2000/18276: Loss = 1.5543 (C: 1.5543, R: 0.0000)
Batch 2100/18276: Loss = 1.4055 (C: 1.4055, R: 0.0000)
Batch 2200/18276: Loss = 1.7039 (C: 1.7039, R: 0.0000)
Batch 2300/18276: Loss = 1.1739 (C: 1.1739, R: 0.0000)
Batch 2400/18276: Loss = 1.5371 (C: 1.5371, R: 0.0000)
Batch 2500/18276: Loss = 1.6560 (C: 1.6560, R: 0.0000)
Batch 2600/18276: Loss = 1.5934 (C: 1.5934, R: 0.0000)
Batch 2700/18276: Loss = 1.3656 (C: 1.3656, R: 0.0000)
Batch 2800/18276: Loss = 1.5623 (C: 1.5623, R: 0.0000)
Batch 2900/18276: Loss = 1.3809 (C: 1.3809, R: 0.0000)
Batch 3000/18276: Loss = 1.5746 (C: 1.5746, R: 0.0000)
Batch 3100/18276: Loss = 1.2060 (C: 1.2060, R: 0.0000)
Batch 3200/18276: Loss = 1.5982 (C: 1.5982, R: 0.0000)
Batch 3300/18276: Loss = 1.5351 (C: 1.5351, R: 0.0000)
Batch 3400/18276: Loss = 1.5506 (C: 1.5506, R: 0.0000)
Batch 3500/18276: Loss = 1.7209 (C: 1.7209, R: 0.0000)
Batch 3600/18276: Loss = 1.7088 (C: 1.7088, R: 0.0000)
Batch 3700/18276: Loss = 1.7004 (C: 1.7004, R: 0.0000)
Batch 3800/18276: Loss = 1.4114 (C: 1.4114, R: 0.0000)
Batch 3900/18276: Loss = 1.5564 (C: 1.5564, R: 0.0000)
Batch 4000/18276: Loss = 1.5474 (C: 1.5474, R: 0.0000)
Batch 4100/18276: Loss = 1.6523 (C: 1.6523, R: 0.0000)
Batch 4200/18276: Loss = 1.4750 (C: 1.4750, R: 0.0000)
Batch 4300/18276: Loss = 1.7877 (C: 1.7877, R: 0.0000)
Batch 4400/18276: Loss = 1.7946 (C: 1.7946, R: 0.0000)
Batch 4500/18276: Loss = 1.4001 (C: 1.4001, R: 0.0000)
Batch 4600/18276: Loss = 1.6857 (C: 1.6857, R: 0.0000)
Batch 4700/18276: Loss = 1.9568 (C: 1.9568, R: 0.0000)
Batch 4800/18276: Loss = 1.4872 (C: 1.4872, R: 0.0000)
Batch 4900/18276: Loss = 1.5829 (C: 1.5829, R: 0.0000)
Batch 5000/18276: Loss = 1.5580 (C: 1.5580, R: 0.0000)
Batch 5100/18276: Loss = 1.8160 (C: 1.8160, R: 0.0000)
Batch 5200/18276: Loss = 1.4103 (C: 1.4103, R: 0.0000)
Batch 5300/18276: Loss = 1.4204 (C: 1.4204, R: 0.0000)
Batch 5400/18276: Loss = 1.2693 (C: 1.2693, R: 0.0000)
Batch 5500/18276: Loss = 1.4014 (C: 1.4014, R: 0.0000)
Batch 5600/18276: Loss = 1.4204 (C: 1.4204, R: 0.0000)
Batch 5700/18276: Loss = 1.6523 (C: 1.6523, R: 0.0000)
Batch 5800/18276: Loss = 1.2393 (C: 1.2393, R: 0.0000)
Batch 5900/18276: Loss = 1.5780 (C: 1.5780, R: 0.0000)
Batch 6000/18276: Loss = 1.6637 (C: 1.6637, R: 0.0000)
Batch 6100/18276: Loss = 1.5719 (C: 1.5719, R: 0.0000)
Batch 6200/18276: Loss = 1.4201 (C: 1.4201, R: 0.0000)
Batch 6300/18276: Loss = 1.2691 (C: 1.2691, R: 0.0000)
Batch 6400/18276: Loss = 0.9794 (C: 0.9794, R: 0.0000)
Batch 6500/18276: Loss = 1.6862 (C: 1.6862, R: 0.0000)
Batch 6600/18276: Loss = 1.6353 (C: 1.6353, R: 0.0000)
Batch 6700/18276: Loss = 1.4225 (C: 1.4225, R: 0.0000)
Batch 6800/18276: Loss = 1.7205 (C: 1.7205, R: 0.0000)
Batch 6900/18276: Loss = 1.8079 (C: 1.8079, R: 0.0000)
Batch 7000/18276: Loss = 1.2091 (C: 1.2091, R: 0.0000)
Batch 7100/18276: Loss = 1.8988 (C: 1.8988, R: 0.0000)
Batch 7200/18276: Loss = 1.5747 (C: 1.5747, R: 0.0000)
Batch 7300/18276: Loss = 1.4081 (C: 1.4081, R: 0.0000)
Batch 7400/18276: Loss = 1.5496 (C: 1.5496, R: 0.0000)
Batch 7500/18276: Loss = 1.9512 (C: 1.9512, R: 0.0000)
Batch 7600/18276: Loss = 1.7917 (C: 1.7917, R: 0.0000)
Batch 7700/18276: Loss = 1.5492 (C: 1.5492, R: 0.0000)
Batch 7800/18276: Loss = 1.6575 (C: 1.6575, R: 0.0000)
Batch 7900/18276: Loss = 1.4134 (C: 1.4134, R: 0.0000)
Batch 8000/18276: Loss = 1.2777 (C: 1.2777, R: 0.0000)
Batch 8100/18276: Loss = 1.3630 (C: 1.3630, R: 0.0000)
Batch 8200/18276: Loss = 1.4104 (C: 1.4104, R: 0.0000)
Batch 8300/18276: Loss = 1.3778 (C: 1.3778, R: 0.0000)
Batch 8400/18276: Loss = 1.3648 (C: 1.3648, R: 0.0000)
Batch 8500/18276: Loss = 1.6680 (C: 1.6680, R: 0.0000)
Batch 8600/18276: Loss = 1.7054 (C: 1.7054, R: 0.0000)
Batch 8700/18276: Loss = 1.4000 (C: 1.4000, R: 0.0000)
Batch 8800/18276: Loss = 1.5954 (C: 1.5954, R: 0.0000)
Batch 8900/18276: Loss = 1.2231 (C: 1.2231, R: 0.0000)
Batch 9000/18276: Loss = 1.4820 (C: 1.4820, R: 0.0000)
Batch 9100/18276: Loss = 1.4086 (C: 1.4086, R: 0.0000)
Batch 9200/18276: Loss = 1.5222 (C: 1.5222, R: 0.0000)
Batch 9300/18276: Loss = 1.3552 (C: 1.3552, R: 0.0000)
Batch 9400/18276: Loss = 1.2348 (C: 1.2348, R: 0.0000)
Batch 9500/18276: Loss = 1.3265 (C: 1.3265, R: 0.0000)
Batch 9600/18276: Loss = 1.7774 (C: 1.7774, R: 0.0000)
Batch 9700/18276: Loss = 1.4032 (C: 1.4032, R: 0.0000)
Batch 9800/18276: Loss = 1.2954 (C: 1.2954, R: 0.0000)
Batch 9900/18276: Loss = 1.4014 (C: 1.4014, R: 0.0000)
Batch 10000/18276: Loss = 1.6782 (C: 1.6782, R: 0.0000)
Batch 10100/18276: Loss = 1.0543 (C: 1.0543, R: 0.0000)
Batch 10200/18276: Loss = 1.4080 (C: 1.4080, R: 0.0000)
Batch 10300/18276: Loss = 1.2011 (C: 1.2011, R: 0.0000)
Batch 10400/18276: Loss = 1.1757 (C: 1.1757, R: 0.0000)
Batch 10500/18276: Loss = 1.9882 (C: 1.9882, R: 0.0000)
Batch 10600/18276: Loss = 1.5342 (C: 1.5342, R: 0.0000)
Batch 10700/18276: Loss = 1.1445 (C: 1.1445, R: 0.0000)
Batch 10800/18276: Loss = 0.9476 (C: 0.9476, R: 0.0000)
Batch 10900/18276: Loss = 1.6809 (C: 1.6809, R: 0.0000)
Batch 11000/18276: Loss = 1.5701 (C: 1.5701, R: 0.0000)
Batch 11100/18276: Loss = 1.7106 (C: 1.7106, R: 0.0000)
Batch 11200/18276: Loss = 1.2526 (C: 1.2526, R: 0.0000)
Batch 11300/18276: Loss = 1.3547 (C: 1.3547, R: 0.0000)
Batch 11400/18276: Loss = 1.2399 (C: 1.2399, R: 0.0000)
Batch 11500/18276: Loss = 1.5300 (C: 1.5300, R: 0.0000)
Batch 11600/18276: Loss = 1.9626 (C: 1.9626, R: 0.0000)
Batch 11700/18276: Loss = 1.4317 (C: 1.4317, R: 0.0000)
Batch 11800/18276: Loss = 1.9160 (C: 1.9160, R: 0.0000)
Batch 11900/18276: Loss = 0.8017 (C: 0.8017, R: 0.0000)
Batch 12000/18276: Loss = 1.4884 (C: 1.4884, R: 0.0000)
Batch 12100/18276: Loss = 1.5509 (C: 1.5509, R: 0.0000)
Batch 12200/18276: Loss = 1.4978 (C: 1.4978, R: 0.0000)
Batch 12300/18276: Loss = 1.5975 (C: 1.5975, R: 0.0000)
Batch 12400/18276: Loss = 1.9910 (C: 1.9910, R: 0.0000)
Batch 12500/18276: Loss = 1.3711 (C: 1.3711, R: 0.0000)
Batch 12600/18276: Loss = 1.7976 (C: 1.7976, R: 0.0000)
Batch 12700/18276: Loss = 1.5712 (C: 1.5712, R: 0.0000)
Batch 12800/18276: Loss = 1.5943 (C: 1.5943, R: 0.0000)
Batch 12900/18276: Loss = 1.6614 (C: 1.6614, R: 0.0000)
Batch 13000/18276: Loss = 1.8249 (C: 1.8249, R: 0.0000)
Batch 13100/18276: Loss = 1.2977 (C: 1.2977, R: 0.0000)
Batch 13200/18276: Loss = 1.4037 (C: 1.4037, R: 0.0000)
Batch 13300/18276: Loss = 1.2057 (C: 1.2057, R: 0.0000)
Batch 13400/18276: Loss = 1.5368 (C: 1.5368, R: 0.0000)
Batch 13500/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 13600/18276: Loss = 1.5136 (C: 1.5136, R: 0.0000)
Batch 13700/18276: Loss = 1.7926 (C: 1.7926, R: 0.0000)
Batch 13800/18276: Loss = 1.7032 (C: 1.7032, R: 0.0000)
Batch 13900/18276: Loss = 1.7106 (C: 1.7106, R: 0.0000)
Batch 14000/18276: Loss = 0.9997 (C: 0.9997, R: 0.0000)
Batch 14100/18276: Loss = 1.5714 (C: 1.5714, R: 0.0000)
Batch 14200/18276: Loss = 1.4635 (C: 1.4635, R: 0.0000)
Batch 14300/18276: Loss = 1.3586 (C: 1.3586, R: 0.0000)
Batch 14400/18276: Loss = 1.6546 (C: 1.6546, R: 0.0000)
Batch 14500/18276: Loss = 1.3659 (C: 1.3659, R: 0.0000)
Batch 14600/18276: Loss = 1.6506 (C: 1.6506, R: 0.0000)
Batch 14700/18276: Loss = 1.6999 (C: 1.6999, R: 0.0000)
Batch 14800/18276: Loss = 1.5296 (C: 1.5296, R: 0.0000)
Batch 14900/18276: Loss = 1.6596 (C: 1.6596, R: 0.0000)
Batch 15000/18276: Loss = 0.6713 (C: 0.6713, R: 0.0000)
Batch 15100/18276: Loss = 1.5695 (C: 1.5695, R: 0.0000)
Batch 15200/18276: Loss = 1.3790 (C: 1.3790, R: 0.0000)
Batch 15300/18276: Loss = 1.9780 (C: 1.9780, R: 0.0000)
Batch 15400/18276: Loss = 1.5793 (C: 1.5793, R: 0.0000)
Batch 15500/18276: Loss = 1.3970 (C: 1.3970, R: 0.0000)
Batch 15600/18276: Loss = 1.4269 (C: 1.4269, R: 0.0000)
Batch 15700/18276: Loss = 1.7730 (C: 1.7730, R: 0.0000)
Batch 15800/18276: Loss = 1.0642 (C: 1.0642, R: 0.0000)
Batch 15900/18276: Loss = 1.7253 (C: 1.7253, R: 0.0000)
Batch 16000/18276: Loss = 1.2053 (C: 1.2053, R: 0.0000)
Batch 16100/18276: Loss = 1.8333 (C: 1.8333, R: 0.0000)
Batch 16200/18276: Loss = 1.7385 (C: 1.7385, R: 0.0000)
Batch 16300/18276: Loss = 1.9171 (C: 1.9171, R: 0.0000)
Batch 16400/18276: Loss = 1.8105 (C: 1.8105, R: 0.0000)
Batch 16500/18276: Loss = 1.5592 (C: 1.5592, R: 0.0000)
Batch 16600/18276: Loss = 1.4023 (C: 1.4023, R: 0.0000)
Batch 16700/18276: Loss = 1.4185 (C: 1.4185, R: 0.0000)
Batch 16800/18276: Loss = 1.1441 (C: 1.1441, R: 0.0000)
Batch 16900/18276: Loss = 1.6860 (C: 1.6860, R: 0.0000)
Batch 17000/18276: Loss = 1.3997 (C: 1.3997, R: 0.0000)
Batch 17100/18276: Loss = 1.8070 (C: 1.8070, R: 0.0000)
Batch 17200/18276: Loss = 1.2330 (C: 1.2330, R: 0.0000)
Batch 17300/18276: Loss = 1.4039 (C: 1.4039, R: 0.0000)
Batch 17400/18276: Loss = 1.5743 (C: 1.5743, R: 0.0000)
Batch 17500/18276: Loss = 1.3648 (C: 1.3648, R: 0.0000)
Batch 17600/18276: Loss = 1.6593 (C: 1.6593, R: 0.0000)
Batch 17700/18276: Loss = 1.4382 (C: 1.4382, R: 0.0000)
Batch 17800/18276: Loss = 1.0888 (C: 1.0888, R: 0.0000)
Batch 17900/18276: Loss = 1.8338 (C: 1.8338, R: 0.0000)
Batch 18000/18276: Loss = 1.4236 (C: 1.4236, R: 0.0000)
Batch 18100/18276: Loss = 1.2922 (C: 1.2922, R: 0.0000)
Batch 18200/18276: Loss = 1.2368 (C: 1.2368, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.5687330961227417
  reconstruction_loss raw: 0.0
  total_loss raw: 1.5687330961227417
Epoch 1 completed in 70.14s
Train Loss: 1.5029 (C: 1.5029)
Val Loss: 1.5264 (C: 1.5264)
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/best_model.pt
New best model saved (Val Loss: 1.5264)

Epoch 2/50
------------------------------
Batch 0/18276: Loss = 1.6270 (C: 1.6270, R: 0.0000)
Batch 100/18276: Loss = 0.9796 (C: 0.9796, R: 0.0000)
Batch 200/18276: Loss = 1.4344 (C: 1.4344, R: 0.0000)
Batch 300/18276: Loss = 1.5734 (C: 1.5734, R: 0.0000)
Batch 400/18276: Loss = 1.3784 (C: 1.3784, R: 0.0000)
Batch 500/18276: Loss = 1.5466 (C: 1.5466, R: 0.0000)
Batch 600/18276: Loss = 1.2046 (C: 1.2046, R: 0.0000)
Batch 700/18276: Loss = 1.2089 (C: 1.2089, R: 0.0000)
Batch 800/18276: Loss = 1.6559 (C: 1.6559, R: 0.0000)
Batch 900/18276: Loss = 1.4961 (C: 1.4961, R: 0.0000)
Batch 1000/18276: Loss = 1.2772 (C: 1.2772, R: 0.0000)
Batch 1100/18276: Loss = 0.9797 (C: 0.9797, R: 0.0000)
Batch 1200/18276: Loss = 1.5349 (C: 1.5349, R: 0.0000)
Batch 1300/18276: Loss = 1.4029 (C: 1.4029, R: 0.0000)
Batch 1400/18276: Loss = 1.0655 (C: 1.0655, R: 0.0000)
Batch 1500/18276: Loss = 1.0225 (C: 1.0225, R: 0.0000)
Batch 1600/18276: Loss = 1.2792 (C: 1.2792, R: 0.0000)
Batch 1700/18276: Loss = 1.8351 (C: 1.8351, R: 0.0000)
Batch 1800/18276: Loss = 1.4234 (C: 1.4234, R: 0.0000)
Batch 1900/18276: Loss = 1.6550 (C: 1.6550, R: 0.0000)
Batch 2000/18276: Loss = 1.6668 (C: 1.6668, R: 0.0000)
Batch 2100/18276: Loss = 1.8329 (C: 1.8329, R: 0.0000)
Batch 2200/18276: Loss = 1.6357 (C: 1.6357, R: 0.0000)
Batch 2300/18276: Loss = 1.8131 (C: 1.8131, R: 0.0000)
Batch 2400/18276: Loss = 1.4713 (C: 1.4713, R: 0.0000)
Batch 2500/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 2600/18276: Loss = 1.0235 (C: 1.0235, R: 0.0000)
Batch 2700/18276: Loss = 1.4951 (C: 1.4951, R: 0.0000)
Batch 2800/18276: Loss = 1.7022 (C: 1.7022, R: 0.0000)
Batch 2900/18276: Loss = 1.3531 (C: 1.3531, R: 0.0000)
Batch 3000/18276: Loss = 1.0245 (C: 1.0245, R: 0.0000)
Batch 3100/18276: Loss = 1.6979 (C: 1.6979, R: 0.0000)
Batch 3200/18276: Loss = 1.5633 (C: 1.5633, R: 0.0000)
Batch 3300/18276: Loss = 1.7248 (C: 1.7248, R: 0.0000)
Batch 3400/18276: Loss = 1.5351 (C: 1.5351, R: 0.0000)
Batch 3500/18276: Loss = 1.1974 (C: 1.1974, R: 0.0000)
Batch 3600/18276: Loss = 1.8103 (C: 1.8103, R: 0.0000)
Batch 3700/18276: Loss = 1.2943 (C: 1.2943, R: 0.0000)
Batch 3800/18276: Loss = 1.4075 (C: 1.4075, R: 0.0000)
Batch 3900/18276: Loss = 1.5531 (C: 1.5531, R: 0.0000)
Batch 4000/18276: Loss = 1.5792 (C: 1.5792, R: 0.0000)
Batch 4100/18276: Loss = 1.5725 (C: 1.5725, R: 0.0000)
Batch 4200/18276: Loss = 1.5568 (C: 1.5568, R: 0.0000)
Batch 4300/18276: Loss = 1.8282 (C: 1.8282, R: 0.0000)
Batch 4400/18276: Loss = 1.8981 (C: 1.8981, R: 0.0000)
Batch 4500/18276: Loss = 1.8365 (C: 1.8365, R: 0.0000)
Batch 4600/18276: Loss = 1.5799 (C: 1.5799, R: 0.0000)
Batch 4700/18276: Loss = 1.4129 (C: 1.4129, R: 0.0000)
Batch 4800/18276: Loss = 1.2147 (C: 1.2147, R: 0.0000)
Batch 4900/18276: Loss = 1.3650 (C: 1.3650, R: 0.0000)
Batch 5000/18276: Loss = 1.8072 (C: 1.8072, R: 0.0000)
Batch 5100/18276: Loss = 1.1708 (C: 1.1708, R: 0.0000)
Batch 5200/18276: Loss = 1.7121 (C: 1.7121, R: 0.0000)
Batch 5300/18276: Loss = 0.9966 (C: 0.9966, R: 0.0000)
Batch 5400/18276: Loss = 1.3009 (C: 1.3009, R: 0.0000)
Batch 5500/18276: Loss = 1.1883 (C: 1.1883, R: 0.0000)
Batch 5600/18276: Loss = 1.6407 (C: 1.6407, R: 0.0000)
Batch 5700/18276: Loss = 1.8711 (C: 1.8711, R: 0.0000)
Batch 5800/18276: Loss = 1.4168 (C: 1.4168, R: 0.0000)
Batch 5900/18276: Loss = 1.5667 (C: 1.5667, R: 0.0000)
Batch 6000/18276: Loss = 1.5797 (C: 1.5797, R: 0.0000)
Batch 6100/18276: Loss = 1.4056 (C: 1.4056, R: 0.0000)
Batch 6200/18276: Loss = 0.8054 (C: 0.8054, R: 0.0000)
Batch 6300/18276: Loss = 1.8106 (C: 1.8106, R: 0.0000)
Batch 6400/18276: Loss = 1.3520 (C: 1.3520, R: 0.0000)
Batch 6500/18276: Loss = 1.3067 (C: 1.3067, R: 0.0000)
Batch 6600/18276: Loss = 0.9815 (C: 0.9815, R: 0.0000)
Batch 6700/18276: Loss = 1.8308 (C: 1.8308, R: 0.0000)
Batch 6800/18276: Loss = 1.5376 (C: 1.5376, R: 0.0000)
Batch 6900/18276: Loss = 1.5648 (C: 1.5648, R: 0.0000)
Batch 7000/18276: Loss = 1.0437 (C: 1.0437, R: 0.0000)
Batch 7100/18276: Loss = 0.8018 (C: 0.8018, R: 0.0000)
Batch 7200/18276: Loss = 1.5585 (C: 1.5585, R: 0.0000)
Batch 7300/18276: Loss = 1.6597 (C: 1.6597, R: 0.0000)
Batch 7400/18276: Loss = 1.9171 (C: 1.9171, R: 0.0000)
Batch 7500/18276: Loss = 1.8381 (C: 1.8381, R: 0.0000)
Batch 7600/18276: Loss = 1.4024 (C: 1.4024, R: 0.0000)
Batch 7700/18276: Loss = 1.4039 (C: 1.4039, R: 0.0000)
Batch 7800/18276: Loss = 1.6490 (C: 1.6490, R: 0.0000)
Batch 7900/18276: Loss = 1.7710 (C: 1.7710, R: 0.0000)
Batch 8000/18276: Loss = 1.3651 (C: 1.3651, R: 0.0000)
Batch 8100/18276: Loss = 1.7206 (C: 1.7206, R: 0.0000)
Batch 8200/18276: Loss = 1.5562 (C: 1.5562, R: 0.0000)
Batch 8300/18276: Loss = 1.7023 (C: 1.7023, R: 0.0000)
Batch 8400/18276: Loss = 1.5712 (C: 1.5712, R: 0.0000)
Batch 8500/18276: Loss = 1.1464 (C: 1.1464, R: 0.0000)
Batch 8600/18276: Loss = 1.3716 (C: 1.3716, R: 0.0000)
Batch 8700/18276: Loss = 1.5682 (C: 1.5682, R: 0.0000)
Batch 8800/18276: Loss = 1.1441 (C: 1.1441, R: 0.0000)
Batch 8900/18276: Loss = 1.4940 (C: 1.4940, R: 0.0000)
Batch 9000/18276: Loss = 1.2367 (C: 1.2367, R: 0.0000)
Batch 9100/18276: Loss = 1.0875 (C: 1.0875, R: 0.0000)
Batch 9200/18276: Loss = 1.1676 (C: 1.1676, R: 0.0000)
Batch 9300/18276: Loss = 1.8175 (C: 1.8175, R: 0.0000)
Batch 9400/18276: Loss = 1.4089 (C: 1.4089, R: 0.0000)
Batch 9500/18276: Loss = 1.3869 (C: 1.3869, R: 0.0000)
Batch 9600/18276: Loss = 1.7926 (C: 1.7926, R: 0.0000)
Batch 9700/18276: Loss = 1.5351 (C: 1.5351, R: 0.0000)
Batch 9800/18276: Loss = 1.2054 (C: 1.2054, R: 0.0000)
Batch 9900/18276: Loss = 1.1447 (C: 1.1447, R: 0.0000)
Batch 10000/18276: Loss = 1.0642 (C: 1.0642, R: 0.0000)
Batch 10100/18276: Loss = 1.8697 (C: 1.8697, R: 0.0000)
Batch 10200/18276: Loss = 1.7253 (C: 1.7253, R: 0.0000)
Batch 10300/18276: Loss = 1.4023 (C: 1.4023, R: 0.0000)
Batch 10400/18276: Loss = 1.7880 (C: 1.7880, R: 0.0000)
Batch 10500/18276: Loss = 1.5791 (C: 1.5791, R: 0.0000)
Batch 10600/18276: Loss = 1.8056 (C: 1.8056, R: 0.0000)
Batch 10700/18276: Loss = 1.3664 (C: 1.3664, R: 0.0000)
Batch 10800/18276: Loss = 1.0227 (C: 1.0227, R: 0.0000)
Batch 10900/18276: Loss = 1.6880 (C: 1.6880, R: 0.0000)
Batch 11000/18276: Loss = 1.5481 (C: 1.5481, R: 0.0000)
Batch 11100/18276: Loss = 1.4195 (C: 1.4195, R: 0.0000)
Batch 11200/18276: Loss = 1.6920 (C: 1.6920, R: 0.0000)
Batch 11300/18276: Loss = 1.1895 (C: 1.1895, R: 0.0000)
Batch 11400/18276: Loss = 1.5364 (C: 1.5364, R: 0.0000)
Batch 11500/18276: Loss = 1.4074 (C: 1.4074, R: 0.0000)
Batch 11600/18276: Loss = 1.2380 (C: 1.2380, R: 0.0000)
Batch 11700/18276: Loss = 1.8633 (C: 1.8633, R: 0.0000)
Batch 11800/18276: Loss = 1.6772 (C: 1.6772, R: 0.0000)
Batch 11900/18276: Loss = 1.3640 (C: 1.3640, R: 0.0000)
Batch 12000/18276: Loss = 1.2215 (C: 1.2215, R: 0.0000)
Batch 12100/18276: Loss = 1.4084 (C: 1.4084, R: 0.0000)
Batch 12200/18276: Loss = 1.5698 (C: 1.5698, R: 0.0000)
Batch 12300/18276: Loss = 1.2368 (C: 1.2368, R: 0.0000)
Batch 12400/18276: Loss = 1.8757 (C: 1.8757, R: 0.0000)
Batch 12500/18276: Loss = 1.8382 (C: 1.8382, R: 0.0000)
Batch 12600/18276: Loss = 1.7528 (C: 1.7528, R: 0.0000)
Batch 12700/18276: Loss = 1.8049 (C: 1.8049, R: 0.0000)
Batch 12800/18276: Loss = 1.8258 (C: 1.8258, R: 0.0000)
Batch 12900/18276: Loss = 1.8065 (C: 1.8065, R: 0.0000)
Batch 13000/18276: Loss = 1.6029 (C: 1.6029, R: 0.0000)
Batch 13100/18276: Loss = 1.4304 (C: 1.4304, R: 0.0000)
Batch 13200/18276: Loss = 1.2059 (C: 1.2059, R: 0.0000)
Batch 13300/18276: Loss = 1.7545 (C: 1.7545, R: 0.0000)
Batch 13400/18276: Loss = 1.4935 (C: 1.4935, R: 0.0000)
Batch 13500/18276: Loss = 1.5025 (C: 1.5025, R: 0.0000)
Batch 13600/18276: Loss = 1.4036 (C: 1.4036, R: 0.0000)
Batch 13700/18276: Loss = 1.7202 (C: 1.7202, R: 0.0000)
Batch 13800/18276: Loss = 0.9781 (C: 0.9781, R: 0.0000)
Batch 13900/18276: Loss = 1.1866 (C: 1.1866, R: 0.0000)
Batch 14000/18276: Loss = 1.0528 (C: 1.0528, R: 0.0000)
Batch 14100/18276: Loss = 1.6378 (C: 1.6378, R: 0.0000)
Batch 14200/18276: Loss = 1.7060 (C: 1.7060, R: 0.0000)
Batch 14300/18276: Loss = 1.8270 (C: 1.8270, R: 0.0000)
Batch 14400/18276: Loss = 1.9239 (C: 1.9239, R: 0.0000)
Batch 14500/18276: Loss = 1.0227 (C: 1.0227, R: 0.0000)
Batch 14600/18276: Loss = 1.5771 (C: 1.5771, R: 0.0000)
Batch 14700/18276: Loss = 1.2095 (C: 1.2095, R: 0.0000)
Batch 14800/18276: Loss = 1.3647 (C: 1.3647, R: 0.0000)
Batch 14900/18276: Loss = 1.5810 (C: 1.5810, R: 0.0000)
Batch 15000/18276: Loss = 1.3551 (C: 1.3551, R: 0.0000)
Batch 15100/18276: Loss = 1.7412 (C: 1.7412, R: 0.0000)
Batch 15200/18276: Loss = 1.1795 (C: 1.1795, R: 0.0000)
Batch 15300/18276: Loss = 1.4198 (C: 1.4198, R: 0.0000)
Batch 15400/18276: Loss = 1.8739 (C: 1.8739, R: 0.0000)
Batch 15500/18276: Loss = 1.2103 (C: 1.2103, R: 0.0000)
Batch 15600/18276: Loss = 1.4736 (C: 1.4736, R: 0.0000)
Batch 15700/18276: Loss = 1.7003 (C: 1.7003, R: 0.0000)
Batch 15800/18276: Loss = 1.5331 (C: 1.5331, R: 0.0000)
Batch 15900/18276: Loss = 1.4177 (C: 1.4177, R: 0.0000)
Batch 16000/18276: Loss = 1.5534 (C: 1.5534, R: 0.0000)
Batch 16100/18276: Loss = 1.3824 (C: 1.3824, R: 0.0000)
Batch 16200/18276: Loss = 1.7062 (C: 1.7062, R: 0.0000)
Batch 16300/18276: Loss = 1.4923 (C: 1.4923, R: 0.0000)
Batch 16400/18276: Loss = 1.6969 (C: 1.6969, R: 0.0000)
Batch 16500/18276: Loss = 1.4718 (C: 1.4718, R: 0.0000)
Batch 16600/18276: Loss = 1.1488 (C: 1.1488, R: 0.0000)
Batch 16700/18276: Loss = 1.2379 (C: 1.2379, R: 0.0000)
Batch 16800/18276: Loss = 1.3961 (C: 1.3961, R: 0.0000)
Batch 16900/18276: Loss = 1.2364 (C: 1.2364, R: 0.0000)
Batch 17000/18276: Loss = 1.6996 (C: 1.6996, R: 0.0000)
Batch 17100/18276: Loss = 1.5942 (C: 1.5942, R: 0.0000)
Batch 17200/18276: Loss = 1.5491 (C: 1.5491, R: 0.0000)
Batch 17300/18276: Loss = 1.5474 (C: 1.5474, R: 0.0000)
Batch 17400/18276: Loss = 1.1948 (C: 1.1948, R: 0.0000)
Batch 17500/18276: Loss = 1.2113 (C: 1.2113, R: 0.0000)
Batch 17600/18276: Loss = 1.7033 (C: 1.7033, R: 0.0000)
Batch 17700/18276: Loss = 1.1243 (C: 1.1243, R: 0.0000)
Batch 17800/18276: Loss = 1.0321 (C: 1.0321, R: 0.0000)
Batch 17900/18276: Loss = 1.8626 (C: 1.8626, R: 0.0000)
Batch 18000/18276: Loss = 1.3531 (C: 1.3531, R: 0.0000)
Batch 18100/18276: Loss = 1.5778 (C: 1.5778, R: 0.0000)
Batch 18200/18276: Loss = 1.4048 (C: 1.4048, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.544487476348877
  reconstruction_loss raw: 0.0
  total_loss raw: 1.544487476348877
Epoch 2 completed in 71.92s
Train Loss: 1.4740 (C: 1.4740)
Val Loss: 1.4939 (C: 1.4939)
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/best_model.pt
New best model saved (Val Loss: 1.4939)

Epoch 3/50
------------------------------
Batch 0/18276: Loss = 1.4078 (C: 1.4078, R: 0.0000)
Batch 100/18276: Loss = 1.7111 (C: 1.7111, R: 0.0000)
Batch 200/18276: Loss = 1.8064 (C: 1.8064, R: 0.0000)
Batch 300/18276: Loss = 1.1462 (C: 1.1462, R: 0.0000)
Batch 400/18276: Loss = 1.8953 (C: 1.8953, R: 0.0000)
Batch 500/18276: Loss = 1.4018 (C: 1.4018, R: 0.0000)
Batch 600/18276: Loss = 1.8069 (C: 1.8069, R: 0.0000)
Batch 700/18276: Loss = 1.4020 (C: 1.4020, R: 0.0000)
Batch 800/18276: Loss = 1.4018 (C: 1.4018, R: 0.0000)
Batch 900/18276: Loss = 1.8348 (C: 1.8348, R: 0.0000)
Batch 1000/18276: Loss = 1.5469 (C: 1.5469, R: 0.0000)
Batch 1100/18276: Loss = 1.7004 (C: 1.7004, R: 0.0000)
Batch 1200/18276: Loss = 1.2051 (C: 1.2051, R: 0.0000)
Batch 1300/18276: Loss = 1.2104 (C: 1.2104, R: 0.0000)
Batch 1400/18276: Loss = 1.5737 (C: 1.5737, R: 0.0000)
Batch 1500/18276: Loss = 1.2489 (C: 1.2489, R: 0.0000)
Batch 1600/18276: Loss = 1.6548 (C: 1.6548, R: 0.0000)
Batch 1700/18276: Loss = 1.2365 (C: 1.2365, R: 0.0000)
Batch 1800/18276: Loss = 1.8736 (C: 1.8736, R: 0.0000)
Batch 1900/18276: Loss = 1.2403 (C: 1.2403, R: 0.0000)
Batch 2000/18276: Loss = 1.8076 (C: 1.8076, R: 0.0000)
Batch 2100/18276: Loss = 1.5566 (C: 1.5566, R: 0.0000)
Batch 2200/18276: Loss = 1.7206 (C: 1.7206, R: 0.0000)
Batch 2300/18276: Loss = 1.5818 (C: 1.5818, R: 0.0000)
Batch 2400/18276: Loss = 1.5809 (C: 1.5809, R: 0.0000)
Batch 2500/18276: Loss = 1.4238 (C: 1.4238, R: 0.0000)
Batch 2600/18276: Loss = 1.5671 (C: 1.5671, R: 0.0000)
Batch 2700/18276: Loss = 1.7040 (C: 1.7040, R: 0.0000)
Batch 2800/18276: Loss = 1.5830 (C: 1.5830, R: 0.0000)
Batch 2900/18276: Loss = 1.5479 (C: 1.5479, R: 0.0000)
Batch 3000/18276: Loss = 1.6216 (C: 1.6216, R: 0.0000)
Batch 3100/18276: Loss = 1.4111 (C: 1.4111, R: 0.0000)
Batch 3200/18276: Loss = 1.8026 (C: 1.8026, R: 0.0000)
Batch 3300/18276: Loss = 1.7067 (C: 1.7067, R: 0.0000)
Batch 3400/18276: Loss = 1.3463 (C: 1.3463, R: 0.0000)
Batch 3500/18276: Loss = 1.5737 (C: 1.5737, R: 0.0000)
Batch 3600/18276: Loss = 1.4973 (C: 1.4973, R: 0.0000)
Batch 3700/18276: Loss = 1.5704 (C: 1.5704, R: 0.0000)
Batch 3800/18276: Loss = 1.3595 (C: 1.3595, R: 0.0000)
Batch 3900/18276: Loss = 1.6952 (C: 1.6952, R: 0.0000)
Batch 4000/18276: Loss = 1.4115 (C: 1.4115, R: 0.0000)
Batch 4100/18276: Loss = 1.0262 (C: 1.0262, R: 0.0000)
Batch 4200/18276: Loss = 1.6675 (C: 1.6675, R: 0.0000)
Batch 4300/18276: Loss = 1.6552 (C: 1.6552, R: 0.0000)
Batch 4400/18276: Loss = 0.9774 (C: 0.9774, R: 0.0000)
Batch 4500/18276: Loss = 1.2359 (C: 1.2359, R: 0.0000)
Batch 4600/18276: Loss = 1.5527 (C: 1.5527, R: 0.0000)
Batch 4700/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 4800/18276: Loss = 1.5965 (C: 1.5965, R: 0.0000)
Batch 4900/18276: Loss = 1.5375 (C: 1.5375, R: 0.0000)
Batch 5000/18276: Loss = 1.4374 (C: 1.4374, R: 0.0000)
Batch 5100/18276: Loss = 1.7925 (C: 1.7925, R: 0.0000)
Batch 5200/18276: Loss = 1.0907 (C: 1.0907, R: 0.0000)
Batch 5300/18276: Loss = 1.1446 (C: 1.1446, R: 0.0000)
Batch 5400/18276: Loss = 0.9042 (C: 0.9042, R: 0.0000)
Batch 5500/18276: Loss = 1.6544 (C: 1.6544, R: 0.0000)
Batch 5600/18276: Loss = 1.4900 (C: 1.4900, R: 0.0000)
Batch 5700/18276: Loss = 1.5484 (C: 1.5484, R: 0.0000)
Batch 5800/18276: Loss = 1.5530 (C: 1.5530, R: 0.0000)
Batch 5900/18276: Loss = 1.6773 (C: 1.6773, R: 0.0000)
Batch 6000/18276: Loss = 1.4255 (C: 1.4255, R: 0.0000)
Batch 6100/18276: Loss = 1.5692 (C: 1.5692, R: 0.0000)
Batch 6200/18276: Loss = 1.2376 (C: 1.2376, R: 0.0000)
Batch 6300/18276: Loss = 1.3821 (C: 1.3821, R: 0.0000)
Batch 6400/18276: Loss = 1.2058 (C: 1.2058, R: 0.0000)
Batch 6500/18276: Loss = 1.8116 (C: 1.8116, R: 0.0000)
Batch 6600/18276: Loss = 1.5299 (C: 1.5299, R: 0.0000)
Batch 6700/18276: Loss = 1.4543 (C: 1.4543, R: 0.0000)
Batch 6800/18276: Loss = 1.4090 (C: 1.4090, R: 0.0000)
Batch 6900/18276: Loss = 1.5785 (C: 1.5785, R: 0.0000)
Batch 7000/18276: Loss = 1.2429 (C: 1.2429, R: 0.0000)
Batch 7100/18276: Loss = 1.5777 (C: 1.5777, R: 0.0000)
Batch 7200/18276: Loss = 1.2044 (C: 1.2044, R: 0.0000)
Batch 7300/18276: Loss = 1.1783 (C: 1.1783, R: 0.0000)
Batch 7400/18276: Loss = 1.4767 (C: 1.4767, R: 0.0000)
Batch 7500/18276: Loss = 1.4173 (C: 1.4173, R: 0.0000)
Batch 7600/18276: Loss = 1.4078 (C: 1.4078, R: 0.0000)
Batch 7700/18276: Loss = 1.8138 (C: 1.8138, R: 0.0000)
Batch 7800/18276: Loss = 1.1430 (C: 1.1430, R: 0.0000)
Batch 7900/18276: Loss = 1.6150 (C: 1.6150, R: 0.0000)
Batch 8000/18276: Loss = 1.4197 (C: 1.4197, R: 0.0000)
Batch 8100/18276: Loss = 1.8263 (C: 1.8263, R: 0.0000)
Batch 8200/18276: Loss = 1.4935 (C: 1.4935, R: 0.0000)
Batch 8300/18276: Loss = 1.2373 (C: 1.2373, R: 0.0000)
Batch 8400/18276: Loss = 1.4880 (C: 1.4880, R: 0.0000)
Batch 8500/18276: Loss = 1.4936 (C: 1.4936, R: 0.0000)
Batch 8600/18276: Loss = 1.5901 (C: 1.5901, R: 0.0000)
Batch 8700/18276: Loss = 1.5494 (C: 1.5494, R: 0.0000)
Batch 8800/18276: Loss = 1.3940 (C: 1.3940, R: 0.0000)
Batch 8900/18276: Loss = 1.7066 (C: 1.7066, R: 0.0000)
Batch 9000/18276: Loss = 1.7015 (C: 1.7015, R: 0.0000)
Batch 9100/18276: Loss = 1.7436 (C: 1.7436, R: 0.0000)
Batch 9200/18276: Loss = 1.2093 (C: 1.2093, R: 0.0000)
Batch 9300/18276: Loss = 1.3700 (C: 1.3700, R: 0.0000)
Batch 9400/18276: Loss = 1.0630 (C: 1.0630, R: 0.0000)
Batch 9500/18276: Loss = 1.2388 (C: 1.2388, R: 0.0000)
Batch 9600/18276: Loss = 1.2378 (C: 1.2378, R: 0.0000)
Batch 9700/18276: Loss = 1.2394 (C: 1.2394, R: 0.0000)
Batch 9800/18276: Loss = 1.2072 (C: 1.2072, R: 0.0000)
Batch 9900/18276: Loss = 1.4080 (C: 1.4080, R: 0.0000)
Batch 10000/18276: Loss = 1.0572 (C: 1.0572, R: 0.0000)
Batch 10100/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 10200/18276: Loss = 1.4184 (C: 1.4184, R: 0.0000)
Batch 10300/18276: Loss = 1.8061 (C: 1.8061, R: 0.0000)
Batch 10400/18276: Loss = 1.7270 (C: 1.7270, R: 0.0000)
Batch 10500/18276: Loss = 1.4919 (C: 1.4919, R: 0.0000)
Batch 10600/18276: Loss = 1.0524 (C: 1.0524, R: 0.0000)
Batch 10700/18276: Loss = 1.7241 (C: 1.7241, R: 0.0000)
Batch 10800/18276: Loss = 1.6575 (C: 1.6575, R: 0.0000)
Batch 10900/18276: Loss = 1.3665 (C: 1.3665, R: 0.0000)
Batch 11000/18276: Loss = 1.8050 (C: 1.8050, R: 0.0000)
Batch 11100/18276: Loss = 1.3685 (C: 1.3685, R: 0.0000)
Batch 11200/18276: Loss = 1.5726 (C: 1.5726, R: 0.0000)
Batch 11300/18276: Loss = 1.5506 (C: 1.5506, R: 0.0000)
Batch 11400/18276: Loss = 1.2834 (C: 1.2834, R: 0.0000)
Batch 11500/18276: Loss = 1.4243 (C: 1.4243, R: 0.0000)
Batch 11600/18276: Loss = 1.4421 (C: 1.4421, R: 0.0000)
Batch 11700/18276: Loss = 1.7438 (C: 1.7438, R: 0.0000)
Batch 11800/18276: Loss = 1.5683 (C: 1.5683, R: 0.0000)
Batch 11900/18276: Loss = 1.3803 (C: 1.3803, R: 0.0000)
Batch 12000/18276: Loss = 1.5732 (C: 1.5732, R: 0.0000)
Batch 12100/18276: Loss = 1.9173 (C: 1.9173, R: 0.0000)
Batch 12200/18276: Loss = 1.2056 (C: 1.2056, R: 0.0000)
Batch 12300/18276: Loss = 1.4331 (C: 1.4331, R: 0.0000)
Batch 12400/18276: Loss = 1.3554 (C: 1.3554, R: 0.0000)
Batch 12500/18276: Loss = 1.2387 (C: 1.2387, R: 0.0000)
Batch 12600/18276: Loss = 1.6721 (C: 1.6721, R: 0.0000)
Batch 12700/18276: Loss = 1.4924 (C: 1.4924, R: 0.0000)
Batch 12800/18276: Loss = 1.5977 (C: 1.5977, R: 0.0000)
Batch 12900/18276: Loss = 1.4190 (C: 1.4190, R: 0.0000)
Batch 13000/18276: Loss = 1.5901 (C: 1.5901, R: 0.0000)
Batch 13100/18276: Loss = 1.3953 (C: 1.3953, R: 0.0000)
Batch 13200/18276: Loss = 1.5481 (C: 1.5481, R: 0.0000)
Batch 13300/18276: Loss = 1.8050 (C: 1.8050, R: 0.0000)
Batch 13400/18276: Loss = 1.4034 (C: 1.4034, R: 0.0000)
Batch 13500/18276: Loss = 1.4218 (C: 1.4218, R: 0.0000)
Batch 13600/18276: Loss = 1.5569 (C: 1.5569, R: 0.0000)
Batch 13700/18276: Loss = 1.5798 (C: 1.5798, R: 0.0000)
Batch 13800/18276: Loss = 1.4872 (C: 1.4872, R: 0.0000)
Batch 13900/18276: Loss = 1.1515 (C: 1.1515, R: 0.0000)
Batch 14000/18276: Loss = 1.8065 (C: 1.8065, R: 0.0000)
Batch 14100/18276: Loss = 1.5801 (C: 1.5801, R: 0.0000)
Batch 14200/18276: Loss = 1.4046 (C: 1.4046, R: 0.0000)
Batch 14300/18276: Loss = 1.2294 (C: 1.2294, R: 0.0000)
Batch 14400/18276: Loss = 1.5294 (C: 1.5294, R: 0.0000)
Batch 14500/18276: Loss = 1.8096 (C: 1.8096, R: 0.0000)
Batch 14600/18276: Loss = 1.3543 (C: 1.3543, R: 0.0000)
Batch 14700/18276: Loss = 1.3642 (C: 1.3642, R: 0.0000)
Batch 14800/18276: Loss = 1.2767 (C: 1.2767, R: 0.0000)
Batch 14900/18276: Loss = 1.3545 (C: 1.3545, R: 0.0000)
Batch 15000/18276: Loss = 1.5674 (C: 1.5674, R: 0.0000)
Batch 15100/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 15200/18276: Loss = 1.7071 (C: 1.7071, R: 0.0000)
Batch 15300/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 15400/18276: Loss = 1.5359 (C: 1.5359, R: 0.0000)
Batch 15500/18276: Loss = 1.5792 (C: 1.5792, R: 0.0000)
Batch 15600/18276: Loss = 1.2952 (C: 1.2952, R: 0.0000)
Batch 15700/18276: Loss = 1.0688 (C: 1.0688, R: 0.0000)
Batch 15800/18276: Loss = 1.7560 (C: 1.7560, R: 0.0000)
Batch 15900/18276: Loss = 1.2094 (C: 1.2094, R: 0.0000)
Batch 16000/18276: Loss = 1.7089 (C: 1.7089, R: 0.0000)
Batch 16100/18276: Loss = 1.5666 (C: 1.5666, R: 0.0000)
Batch 16200/18276: Loss = 1.4690 (C: 1.4690, R: 0.0000)
Batch 16300/18276: Loss = 1.5349 (C: 1.5349, R: 0.0000)
Batch 16400/18276: Loss = 1.6854 (C: 1.6854, R: 0.0000)
Batch 16500/18276: Loss = 1.7024 (C: 1.7024, R: 0.0000)
Batch 16600/18276: Loss = 1.4151 (C: 1.4151, R: 0.0000)
Batch 16700/18276: Loss = 1.4876 (C: 1.4876, R: 0.0000)
Batch 16800/18276: Loss = 1.7313 (C: 1.7313, R: 0.0000)
Batch 16900/18276: Loss = 1.4198 (C: 1.4198, R: 0.0000)
Batch 17000/18276: Loss = 1.0536 (C: 1.0536, R: 0.0000)
Batch 17100/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 17200/18276: Loss = 1.1515 (C: 1.1515, R: 0.0000)
Batch 17300/18276: Loss = 1.6660 (C: 1.6660, R: 0.0000)
Batch 17400/18276: Loss = 1.3279 (C: 1.3279, R: 0.0000)
Batch 17500/18276: Loss = 0.9092 (C: 0.9092, R: 0.0000)
Batch 17600/18276: Loss = 1.4096 (C: 1.4096, R: 0.0000)
Batch 17700/18276: Loss = 1.2373 (C: 1.2373, R: 0.0000)
Batch 17800/18276: Loss = 1.2928 (C: 1.2928, R: 0.0000)
Batch 17900/18276: Loss = 1.3546 (C: 1.3546, R: 0.0000)
Batch 18000/18276: Loss = 1.8257 (C: 1.8257, R: 0.0000)
Batch 18100/18276: Loss = 1.4180 (C: 1.4180, R: 0.0000)
Batch 18200/18276: Loss = 1.5252 (C: 1.5252, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.157222867012024
  reconstruction_loss raw: 0.0
  total_loss raw: 1.157222867012024
Epoch 3 completed in 71.72s
Train Loss: 1.4632 (C: 1.4632)
Val Loss: 1.4512 (C: 1.4512)
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/best_model.pt
New best model saved (Val Loss: 1.4512)

Epoch 4/50
------------------------------
Batch 0/18276: Loss = 1.3957 (C: 1.3957, R: 0.0000)
Batch 100/18276: Loss = 1.2363 (C: 1.2363, R: 0.0000)
Batch 200/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 300/18276: Loss = 1.2103 (C: 1.2103, R: 0.0000)
Batch 400/18276: Loss = 1.2377 (C: 1.2377, R: 0.0000)
Batch 500/18276: Loss = 1.4741 (C: 1.4741, R: 0.0000)
Batch 600/18276: Loss = 1.8312 (C: 1.8312, R: 0.0000)
Batch 700/18276: Loss = 1.7564 (C: 1.7564, R: 0.0000)
Batch 800/18276: Loss = 1.6545 (C: 1.6545, R: 0.0000)
Batch 900/18276: Loss = 1.6726 (C: 1.6726, R: 0.0000)
Batch 1000/18276: Loss = 1.1443 (C: 1.1443, R: 0.0000)
Batch 1100/18276: Loss = 1.6533 (C: 1.6533, R: 0.0000)
Batch 1200/18276: Loss = 1.2365 (C: 1.2365, R: 0.0000)
Batch 1300/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 1400/18276: Loss = 1.2398 (C: 1.2398, R: 0.0000)
Batch 1500/18276: Loss = 1.2433 (C: 1.2433, R: 0.0000)
Batch 1600/18276: Loss = 1.1326 (C: 1.1326, R: 0.0000)
Batch 1700/18276: Loss = 1.6670 (C: 1.6670, R: 0.0000)
Batch 1800/18276: Loss = 1.7111 (C: 1.7111, R: 0.0000)
Batch 1900/18276: Loss = 1.4510 (C: 1.4510, R: 0.0000)
Batch 2000/18276: Loss = 1.7914 (C: 1.7914, R: 0.0000)
Batch 2100/18276: Loss = 1.4016 (C: 1.4016, R: 0.0000)
Batch 2200/18276: Loss = 1.4721 (C: 1.4721, R: 0.0000)
Batch 2300/18276: Loss = 1.0232 (C: 1.0232, R: 0.0000)
Batch 2400/18276: Loss = 1.5793 (C: 1.5793, R: 0.0000)
Batch 2500/18276: Loss = 1.1000 (C: 1.1000, R: 0.0000)
Batch 2600/18276: Loss = 1.3509 (C: 1.3509, R: 0.0000)
Batch 2700/18276: Loss = 1.4929 (C: 1.4929, R: 0.0000)
Batch 2800/18276: Loss = 1.7201 (C: 1.7201, R: 0.0000)
Batch 2900/18276: Loss = 1.0402 (C: 1.0402, R: 0.0000)
Batch 3000/18276: Loss = 1.6078 (C: 1.6078, R: 0.0000)
Batch 3100/18276: Loss = 1.4263 (C: 1.4263, R: 0.0000)
Batch 3200/18276: Loss = 1.0372 (C: 1.0372, R: 0.0000)
Batch 3300/18276: Loss = 1.4023 (C: 1.4023, R: 0.0000)
Batch 3400/18276: Loss = 1.5913 (C: 1.5913, R: 0.0000)
Batch 3500/18276: Loss = 1.6865 (C: 1.6865, R: 0.0000)
Batch 3600/18276: Loss = 1.9620 (C: 1.9620, R: 0.0000)
Batch 3700/18276: Loss = 1.4020 (C: 1.4020, R: 0.0000)
Batch 3800/18276: Loss = 1.2350 (C: 1.2350, R: 0.0000)
Batch 3900/18276: Loss = 1.1420 (C: 1.1420, R: 0.0000)
Batch 4000/18276: Loss = 1.7218 (C: 1.7218, R: 0.0000)
Batch 4100/18276: Loss = 1.0223 (C: 1.0223, R: 0.0000)
Batch 4200/18276: Loss = 1.4050 (C: 1.4050, R: 0.0000)
Batch 4300/18276: Loss = 1.4084 (C: 1.4084, R: 0.0000)
Batch 4400/18276: Loss = 1.2985 (C: 1.2985, R: 0.0000)
Batch 4500/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 4600/18276: Loss = 1.4111 (C: 1.4111, R: 0.0000)
Batch 4700/18276: Loss = 0.9313 (C: 0.9313, R: 0.0000)
Batch 4800/18276: Loss = 1.2450 (C: 1.2450, R: 0.0000)
Batch 4900/18276: Loss = 1.0554 (C: 1.0554, R: 0.0000)
Batch 5000/18276: Loss = 1.5736 (C: 1.5736, R: 0.0000)
Batch 5100/18276: Loss = 1.6982 (C: 1.6982, R: 0.0000)
Batch 5200/18276: Loss = 1.4968 (C: 1.4968, R: 0.0000)
Batch 5300/18276: Loss = 1.5429 (C: 1.5429, R: 0.0000)
Batch 5400/18276: Loss = 1.2035 (C: 1.2035, R: 0.0000)
Batch 5500/18276: Loss = 1.5563 (C: 1.5563, R: 0.0000)
Batch 5600/18276: Loss = 0.9462 (C: 0.9462, R: 0.0000)
Batch 5700/18276: Loss = 1.7290 (C: 1.7290, R: 0.0000)
Batch 5800/18276: Loss = 1.7525 (C: 1.7525, R: 0.0000)
Batch 5900/18276: Loss = 1.3929 (C: 1.3929, R: 0.0000)
Batch 6000/18276: Loss = 1.2121 (C: 1.2121, R: 0.0000)
Batch 6100/18276: Loss = 1.2779 (C: 1.2779, R: 0.0000)
Batch 6200/18276: Loss = 1.8133 (C: 1.8133, R: 0.0000)
Batch 6300/18276: Loss = 1.9237 (C: 1.9237, R: 0.0000)
Batch 6400/18276: Loss = 1.6597 (C: 1.6597, R: 0.0000)
Batch 6500/18276: Loss = 1.5427 (C: 1.5427, R: 0.0000)
Batch 6600/18276: Loss = 1.5501 (C: 1.5501, R: 0.0000)
Batch 6700/18276: Loss = 1.7030 (C: 1.7030, R: 0.0000)
Batch 6800/18276: Loss = 1.7601 (C: 1.7601, R: 0.0000)
Batch 6900/18276: Loss = 1.2751 (C: 1.2751, R: 0.0000)
Batch 7000/18276: Loss = 1.4142 (C: 1.4142, R: 0.0000)
Batch 7100/18276: Loss = 1.6656 (C: 1.6656, R: 0.0000)
Batch 7200/18276: Loss = 1.4187 (C: 1.4187, R: 0.0000)
Batch 7300/18276: Loss = 1.8766 (C: 1.8766, R: 0.0000)
Batch 7400/18276: Loss = 1.4889 (C: 1.4889, R: 0.0000)
Batch 7500/18276: Loss = 1.3987 (C: 1.3987, R: 0.0000)
Batch 7600/18276: Loss = 1.3465 (C: 1.3465, R: 0.0000)
Batch 7700/18276: Loss = 1.4092 (C: 1.4092, R: 0.0000)
Batch 7800/18276: Loss = 1.7906 (C: 1.7906, R: 0.0000)
Batch 7900/18276: Loss = 1.3917 (C: 1.3917, R: 0.0000)
Batch 8000/18276: Loss = 1.7238 (C: 1.7238, R: 0.0000)
Batch 8100/18276: Loss = 1.2379 (C: 1.2379, R: 0.0000)
Batch 8200/18276: Loss = 1.7537 (C: 1.7537, R: 0.0000)
Batch 8300/18276: Loss = 1.5639 (C: 1.5639, R: 0.0000)
Batch 8400/18276: Loss = 1.2197 (C: 1.2197, R: 0.0000)
Batch 8500/18276: Loss = 1.3841 (C: 1.3841, R: 0.0000)
Batch 8600/18276: Loss = 1.4118 (C: 1.4118, R: 0.0000)
Batch 8700/18276: Loss = 1.3682 (C: 1.3682, R: 0.0000)
Batch 8800/18276: Loss = 1.4059 (C: 1.4059, R: 0.0000)
Batch 8900/18276: Loss = 1.4126 (C: 1.4126, R: 0.0000)
Batch 9000/18276: Loss = 1.4075 (C: 1.4075, R: 0.0000)
Batch 9100/18276: Loss = 1.1450 (C: 1.1450, R: 0.0000)
Batch 9200/18276: Loss = 1.0540 (C: 1.0540, R: 0.0000)
Batch 9300/18276: Loss = 1.1871 (C: 1.1871, R: 0.0000)
Batch 9400/18276: Loss = 1.6699 (C: 1.6699, R: 0.0000)
Batch 9500/18276: Loss = 1.0393 (C: 1.0393, R: 0.0000)
Batch 9600/18276: Loss = 1.7106 (C: 1.7106, R: 0.0000)
Batch 9700/18276: Loss = 1.8214 (C: 1.8214, R: 0.0000)
Batch 9800/18276: Loss = 1.4018 (C: 1.4018, R: 0.0000)
Batch 9900/18276: Loss = 1.7465 (C: 1.7465, R: 0.0000)
Batch 10000/18276: Loss = 1.5481 (C: 1.5481, R: 0.0000)
Batch 10100/18276: Loss = 1.1976 (C: 1.1976, R: 0.0000)
Batch 10200/18276: Loss = 1.4089 (C: 1.4089, R: 0.0000)
Batch 10300/18276: Loss = 1.4125 (C: 1.4125, R: 0.0000)
Batch 10400/18276: Loss = 1.2281 (C: 1.2281, R: 0.0000)
Batch 10500/18276: Loss = 1.4094 (C: 1.4094, R: 0.0000)
Batch 10600/18276: Loss = 1.7036 (C: 1.7036, R: 0.0000)
Batch 10700/18276: Loss = 1.4181 (C: 1.4181, R: 0.0000)
Batch 10800/18276: Loss = 1.6912 (C: 1.6912, R: 0.0000)
Batch 10900/18276: Loss = 1.4111 (C: 1.4111, R: 0.0000)
Batch 11000/18276: Loss = 1.1738 (C: 1.1738, R: 0.0000)
Batch 11100/18276: Loss = 1.8085 (C: 1.8085, R: 0.0000)
Batch 11200/18276: Loss = 1.5815 (C: 1.5815, R: 0.0000)
Batch 11300/18276: Loss = 1.6977 (C: 1.6977, R: 0.0000)
Batch 11400/18276: Loss = 1.5480 (C: 1.5480, R: 0.0000)
Batch 11500/18276: Loss = 1.5343 (C: 1.5343, R: 0.0000)
Batch 11600/18276: Loss = 1.5517 (C: 1.5517, R: 0.0000)
Batch 11700/18276: Loss = 1.3542 (C: 1.3542, R: 0.0000)
Batch 11800/18276: Loss = 1.1550 (C: 1.1550, R: 0.0000)
Batch 11900/18276: Loss = 1.0232 (C: 1.0232, R: 0.0000)
Batch 12000/18276: Loss = 1.4154 (C: 1.4154, R: 0.0000)
Batch 12100/18276: Loss = 1.6435 (C: 1.6435, R: 0.0000)
Batch 12200/18276: Loss = 1.1712 (C: 1.1712, R: 0.0000)
Batch 12300/18276: Loss = 1.0373 (C: 1.0373, R: 0.0000)
Batch 12400/18276: Loss = 1.3971 (C: 1.3971, R: 0.0000)
Batch 12500/18276: Loss = 1.8053 (C: 1.8053, R: 0.0000)
Batch 12600/18276: Loss = 1.2117 (C: 1.2117, R: 0.0000)
Batch 12700/18276: Loss = 1.2376 (C: 1.2376, R: 0.0000)
Batch 12800/18276: Loss = 1.5428 (C: 1.5428, R: 0.0000)
Batch 12900/18276: Loss = 1.9230 (C: 1.9230, R: 0.0000)
Batch 13000/18276: Loss = 1.8060 (C: 1.8060, R: 0.0000)
Batch 13100/18276: Loss = 1.5852 (C: 1.5852, R: 0.0000)
Batch 13200/18276: Loss = 1.7067 (C: 1.7067, R: 0.0000)
Batch 13300/18276: Loss = 1.4925 (C: 1.4925, R: 0.0000)
Batch 13400/18276: Loss = 1.2016 (C: 1.2016, R: 0.0000)
Batch 13500/18276: Loss = 1.2056 (C: 1.2056, R: 0.0000)
Batch 13600/18276: Loss = 1.2830 (C: 1.2830, R: 0.0000)
Batch 13700/18276: Loss = 1.4741 (C: 1.4741, R: 0.0000)
Batch 13800/18276: Loss = 1.4122 (C: 1.4122, R: 0.0000)
Batch 13900/18276: Loss = 1.3730 (C: 1.3730, R: 0.0000)
Batch 14000/18276: Loss = 1.4850 (C: 1.4850, R: 0.0000)
Batch 14100/18276: Loss = 1.2776 (C: 1.2776, R: 0.0000)
Batch 14200/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 14300/18276: Loss = 1.4947 (C: 1.4947, R: 0.0000)
Batch 14400/18276: Loss = 1.4183 (C: 1.4183, R: 0.0000)
Batch 14500/18276: Loss = 1.4068 (C: 1.4068, R: 0.0000)
Batch 14600/18276: Loss = 1.7861 (C: 1.7861, R: 0.0000)
Batch 14700/18276: Loss = 1.6123 (C: 1.6123, R: 0.0000)
Batch 14800/18276: Loss = 1.2094 (C: 1.2094, R: 0.0000)
Batch 14900/18276: Loss = 1.6976 (C: 1.6976, R: 0.0000)
Batch 15000/18276: Loss = 1.8504 (C: 1.8504, R: 0.0000)
Batch 15100/18276: Loss = 1.1441 (C: 1.1441, R: 0.0000)
Batch 15200/18276: Loss = 1.1945 (C: 1.1945, R: 0.0000)
Batch 15300/18276: Loss = 1.3965 (C: 1.3965, R: 0.0000)
Batch 15400/18276: Loss = 1.9049 (C: 1.9049, R: 0.0000)
Batch 15500/18276: Loss = 1.5485 (C: 1.5485, R: 0.0000)
Batch 15600/18276: Loss = 1.5690 (C: 1.5690, R: 0.0000)
Batch 15700/18276: Loss = 1.3669 (C: 1.3669, R: 0.0000)
Batch 15800/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 15900/18276: Loss = 1.1435 (C: 1.1435, R: 0.0000)
Batch 16000/18276: Loss = 1.1779 (C: 1.1779, R: 0.0000)
Batch 16100/18276: Loss = 1.5421 (C: 1.5421, R: 0.0000)
Batch 16200/18276: Loss = 1.1994 (C: 1.1994, R: 0.0000)
Batch 16300/18276: Loss = 1.6359 (C: 1.6359, R: 0.0000)
Batch 16400/18276: Loss = 1.3548 (C: 1.3548, R: 0.0000)
Batch 16500/18276: Loss = 1.2088 (C: 1.2088, R: 0.0000)
Batch 16600/18276: Loss = 1.3674 (C: 1.3674, R: 0.0000)
Batch 16700/18276: Loss = 1.0567 (C: 1.0567, R: 0.0000)
Batch 16800/18276: Loss = 1.0682 (C: 1.0682, R: 0.0000)
Batch 16900/18276: Loss = 1.7141 (C: 1.7141, R: 0.0000)
Batch 17000/18276: Loss = 1.0280 (C: 1.0280, R: 0.0000)
Batch 17100/18276: Loss = 1.2386 (C: 1.2386, R: 0.0000)
Batch 17200/18276: Loss = 1.8328 (C: 1.8328, R: 0.0000)
Batch 17300/18276: Loss = 1.4108 (C: 1.4108, R: 0.0000)
Batch 17400/18276: Loss = 1.1704 (C: 1.1704, R: 0.0000)
Batch 17500/18276: Loss = 1.3493 (C: 1.3493, R: 0.0000)
Batch 17600/18276: Loss = 1.0624 (C: 1.0624, R: 0.0000)
Batch 17700/18276: Loss = 1.2369 (C: 1.2369, R: 0.0000)
Batch 17800/18276: Loss = 1.6923 (C: 1.6923, R: 0.0000)
Batch 17900/18276: Loss = 1.4194 (C: 1.4194, R: 0.0000)
Batch 18000/18276: Loss = 0.9793 (C: 0.9793, R: 0.0000)
Batch 18100/18276: Loss = 1.8053 (C: 1.8053, R: 0.0000)
Batch 18200/18276: Loss = 1.4196 (C: 1.4196, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.5792646408081055
  reconstruction_loss raw: 0.0
  total_loss raw: 1.5792646408081055
Epoch 4 completed in 72.56s
Train Loss: 1.4598 (C: 1.4598)
Val Loss: 1.4438 (C: 1.4438)
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/best_model.pt
New best model saved (Val Loss: 1.4438)

Epoch 5/50
------------------------------
Batch 0/18276: Loss = 1.8371 (C: 1.8371, R: 0.0000)
Batch 100/18276: Loss = 1.7022 (C: 1.7022, R: 0.0000)
Batch 200/18276: Loss = 1.3607 (C: 1.3607, R: 0.0000)
Batch 300/18276: Loss = 1.7871 (C: 1.7871, R: 0.0000)
Batch 400/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 500/18276: Loss = 1.0371 (C: 1.0371, R: 0.0000)
Batch 600/18276: Loss = 1.6589 (C: 1.6589, R: 0.0000)
Batch 700/18276: Loss = 1.4018 (C: 1.4018, R: 0.0000)
Batch 800/18276: Loss = 1.1444 (C: 1.1444, R: 0.0000)
Batch 900/18276: Loss = 1.3778 (C: 1.3778, R: 0.0000)
Batch 1000/18276: Loss = 1.7018 (C: 1.7018, R: 0.0000)
Batch 1100/18276: Loss = 1.4959 (C: 1.4959, R: 0.0000)
Batch 1200/18276: Loss = 1.5845 (C: 1.5845, R: 0.0000)
Batch 1300/18276: Loss = 1.6286 (C: 1.6286, R: 0.0000)
Batch 1400/18276: Loss = 1.1446 (C: 1.1446, R: 0.0000)
Batch 1500/18276: Loss = 1.3544 (C: 1.3544, R: 0.0000)
Batch 1600/18276: Loss = 1.4150 (C: 1.4150, R: 0.0000)
Batch 1700/18276: Loss = 1.4712 (C: 1.4712, R: 0.0000)
Batch 1800/18276: Loss = 1.4966 (C: 1.4966, R: 0.0000)
Batch 1900/18276: Loss = 1.7239 (C: 1.7239, R: 0.0000)
Batch 2000/18276: Loss = 1.6649 (C: 1.6649, R: 0.0000)
Batch 2100/18276: Loss = 1.2374 (C: 1.2374, R: 0.0000)
Batch 2200/18276: Loss = 1.5477 (C: 1.5477, R: 0.0000)
Batch 2300/18276: Loss = 1.1513 (C: 1.1513, R: 0.0000)
Batch 2400/18276: Loss = 1.2807 (C: 1.2807, R: 0.0000)
Batch 2500/18276: Loss = 1.6671 (C: 1.6671, R: 0.0000)
Batch 2600/18276: Loss = 1.5748 (C: 1.5748, R: 0.0000)
Batch 2700/18276: Loss = 1.8959 (C: 1.8959, R: 0.0000)
Batch 2800/18276: Loss = 1.2824 (C: 1.2824, R: 0.0000)
Batch 2900/18276: Loss = 1.4212 (C: 1.4212, R: 0.0000)
Batch 3000/18276: Loss = 1.9338 (C: 1.9338, R: 0.0000)
Batch 3100/18276: Loss = 1.5529 (C: 1.5529, R: 0.0000)
Batch 3200/18276: Loss = 1.7012 (C: 1.7012, R: 0.0000)
Batch 3300/18276: Loss = 1.2034 (C: 1.2034, R: 0.0000)
Batch 3400/18276: Loss = 1.7097 (C: 1.7097, R: 0.0000)
Batch 3500/18276: Loss = 1.7564 (C: 1.7564, R: 0.0000)
Batch 3600/18276: Loss = 1.8371 (C: 1.8371, R: 0.0000)
Batch 3700/18276: Loss = 1.5477 (C: 1.5477, R: 0.0000)
Batch 3800/18276: Loss = 1.8938 (C: 1.8938, R: 0.0000)
Batch 3900/18276: Loss = 0.9923 (C: 0.9923, R: 0.0000)
Batch 4000/18276: Loss = 1.3654 (C: 1.3654, R: 0.0000)
Batch 4100/18276: Loss = 1.7031 (C: 1.7031, R: 0.0000)
Batch 4200/18276: Loss = 1.4335 (C: 1.4335, R: 0.0000)
Batch 4300/18276: Loss = 1.5642 (C: 1.5642, R: 0.0000)
Batch 4400/18276: Loss = 1.3589 (C: 1.3589, R: 0.0000)
Batch 4500/18276: Loss = 1.1515 (C: 1.1515, R: 0.0000)
Batch 4600/18276: Loss = 1.4179 (C: 1.4179, R: 0.0000)
Batch 4700/18276: Loss = 1.8571 (C: 1.8571, R: 0.0000)
Batch 4800/18276: Loss = 1.3919 (C: 1.3919, R: 0.0000)
Batch 4900/18276: Loss = 1.5488 (C: 1.5488, R: 0.0000)
Batch 5000/18276: Loss = 0.9783 (C: 0.9783, R: 0.0000)
Batch 5100/18276: Loss = 1.2091 (C: 1.2091, R: 0.0000)
Batch 5200/18276: Loss = 0.9780 (C: 0.9780, R: 0.0000)
Batch 5300/18276: Loss = 1.4893 (C: 1.4893, R: 0.0000)
Batch 5400/18276: Loss = 1.7200 (C: 1.7200, R: 0.0000)
Batch 5500/18276: Loss = 1.3001 (C: 1.3001, R: 0.0000)
Batch 5600/18276: Loss = 1.5074 (C: 1.5074, R: 0.0000)
Batch 5700/18276: Loss = 1.5793 (C: 1.5793, R: 0.0000)
Batch 5800/18276: Loss = 1.5946 (C: 1.5946, R: 0.0000)
Batch 5900/18276: Loss = 1.5612 (C: 1.5612, R: 0.0000)
Batch 6000/18276: Loss = 1.4777 (C: 1.4777, R: 0.0000)
Batch 6100/18276: Loss = 1.7036 (C: 1.7036, R: 0.0000)
Batch 6200/18276: Loss = 1.4007 (C: 1.4007, R: 0.0000)
Batch 6300/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 6400/18276: Loss = 1.7374 (C: 1.7374, R: 0.0000)
Batch 6500/18276: Loss = 1.2102 (C: 1.2102, R: 0.0000)
Batch 6600/18276: Loss = 1.7928 (C: 1.7928, R: 0.0000)
Batch 6700/18276: Loss = 1.5811 (C: 1.5811, R: 0.0000)
Batch 6800/18276: Loss = 1.4752 (C: 1.4752, R: 0.0000)
Batch 6900/18276: Loss = 1.6641 (C: 1.6641, R: 0.0000)
Batch 7000/18276: Loss = 1.4727 (C: 1.4727, R: 0.0000)
Batch 7100/18276: Loss = 1.3996 (C: 1.3996, R: 0.0000)
Batch 7200/18276: Loss = 1.5695 (C: 1.5695, R: 0.0000)
Batch 7300/18276: Loss = 1.3558 (C: 1.3558, R: 0.0000)
Batch 7400/18276: Loss = 1.4275 (C: 1.4275, R: 0.0000)
Batch 7500/18276: Loss = 1.6047 (C: 1.6047, R: 0.0000)
Batch 7600/18276: Loss = 1.2976 (C: 1.2976, R: 0.0000)
Batch 7700/18276: Loss = 1.7085 (C: 1.7085, R: 0.0000)
Batch 7800/18276: Loss = 1.5755 (C: 1.5755, R: 0.0000)
Batch 7900/18276: Loss = 1.2073 (C: 1.2073, R: 0.0000)
Batch 8000/18276: Loss = 1.9229 (C: 1.9229, R: 0.0000)
Batch 8100/18276: Loss = 1.2987 (C: 1.2987, R: 0.0000)
Batch 8200/18276: Loss = 1.4878 (C: 1.4878, R: 0.0000)
Batch 8300/18276: Loss = 1.5452 (C: 1.5452, R: 0.0000)
Batch 8400/18276: Loss = 1.7915 (C: 1.7915, R: 0.0000)
Batch 8500/18276: Loss = 1.0393 (C: 1.0393, R: 0.0000)
Batch 8600/18276: Loss = 1.3733 (C: 1.3733, R: 0.0000)
Batch 8700/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 8800/18276: Loss = 1.2049 (C: 1.2049, R: 0.0000)
Batch 8900/18276: Loss = 1.7206 (C: 1.7206, R: 0.0000)
Batch 9000/18276: Loss = 0.8028 (C: 0.8028, R: 0.0000)
Batch 9100/18276: Loss = 1.1529 (C: 1.1529, R: 0.0000)
Batch 9200/18276: Loss = 1.7241 (C: 1.7241, R: 0.0000)
Batch 9300/18276: Loss = 1.5741 (C: 1.5741, R: 0.0000)
Batch 9400/18276: Loss = 1.3156 (C: 1.3156, R: 0.0000)
Batch 9500/18276: Loss = 1.6362 (C: 1.6362, R: 0.0000)
Batch 9600/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 9700/18276: Loss = 1.2357 (C: 1.2357, R: 0.0000)
Batch 9800/18276: Loss = 1.3649 (C: 1.3649, R: 0.0000)
Batch 9900/18276: Loss = 1.4814 (C: 1.4814, R: 0.0000)
Batch 10000/18276: Loss = 1.2375 (C: 1.2375, R: 0.0000)
Batch 10100/18276: Loss = 1.2106 (C: 1.2106, R: 0.0000)
Batch 10200/18276: Loss = 1.4232 (C: 1.4232, R: 0.0000)
Batch 10300/18276: Loss = 1.2378 (C: 1.2378, R: 0.0000)
Batch 10400/18276: Loss = 1.4096 (C: 1.4096, R: 0.0000)
Batch 10500/18276: Loss = 1.6279 (C: 1.6279, R: 0.0000)
Batch 10600/18276: Loss = 1.4135 (C: 1.4135, R: 0.0000)
Batch 10700/18276: Loss = 1.5728 (C: 1.5728, R: 0.0000)
Batch 10800/18276: Loss = 1.8309 (C: 1.8309, R: 0.0000)
Batch 10900/18276: Loss = 1.4640 (C: 1.4640, R: 0.0000)
Batch 11000/18276: Loss = 1.7244 (C: 1.7244, R: 0.0000)
Batch 11100/18276: Loss = 1.3521 (C: 1.3521, R: 0.0000)
Batch 11200/18276: Loss = 1.2915 (C: 1.2915, R: 0.0000)
Batch 11300/18276: Loss = 1.7502 (C: 1.7502, R: 0.0000)
Batch 11400/18276: Loss = 1.5188 (C: 1.5188, R: 0.0000)
Batch 11500/18276: Loss = 1.3477 (C: 1.3477, R: 0.0000)
Batch 11600/18276: Loss = 1.8249 (C: 1.8249, R: 0.0000)
Batch 11700/18276: Loss = 0.9781 (C: 0.9781, R: 0.0000)
Batch 11800/18276: Loss = 1.8371 (C: 1.8371, R: 0.0000)
Batch 11900/18276: Loss = 1.6554 (C: 1.6554, R: 0.0000)
Batch 12000/18276: Loss = 0.9344 (C: 0.9344, R: 0.0000)
Batch 12100/18276: Loss = 1.4229 (C: 1.4229, R: 0.0000)
Batch 12200/18276: Loss = 1.2380 (C: 1.2380, R: 0.0000)
Batch 12300/18276: Loss = 1.4122 (C: 1.4122, R: 0.0000)
Batch 12400/18276: Loss = 1.7051 (C: 1.7051, R: 0.0000)
Batch 12500/18276: Loss = 1.3666 (C: 1.3666, R: 0.0000)
Batch 12600/18276: Loss = 1.9006 (C: 1.9006, R: 0.0000)
Batch 12700/18276: Loss = 1.1062 (C: 1.1062, R: 0.0000)
Batch 12800/18276: Loss = 1.4101 (C: 1.4101, R: 0.0000)
Batch 12900/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 13000/18276: Loss = 1.7201 (C: 1.7201, R: 0.0000)
Batch 13100/18276: Loss = 1.2078 (C: 1.2078, R: 0.0000)
Batch 13200/18276: Loss = 1.4088 (C: 1.4088, R: 0.0000)
Batch 13300/18276: Loss = 1.7090 (C: 1.7090, R: 0.0000)
Batch 13400/18276: Loss = 1.2050 (C: 1.2050, R: 0.0000)
Batch 13500/18276: Loss = 1.4954 (C: 1.4954, R: 0.0000)
Batch 13600/18276: Loss = 1.5681 (C: 1.5681, R: 0.0000)
Batch 13700/18276: Loss = 1.8374 (C: 1.8374, R: 0.0000)
Batch 13800/18276: Loss = 1.0543 (C: 1.0543, R: 0.0000)
Batch 13900/18276: Loss = 1.8140 (C: 1.8140, R: 0.0000)
Batch 14000/18276: Loss = 0.9472 (C: 0.9472, R: 0.0000)
Batch 14100/18276: Loss = 1.0077 (C: 1.0077, R: 0.0000)
Batch 14200/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 14300/18276: Loss = 1.3571 (C: 1.3571, R: 0.0000)
Batch 14400/18276: Loss = 1.5807 (C: 1.5807, R: 0.0000)
Batch 14500/18276: Loss = 1.2087 (C: 1.2087, R: 0.0000)
Batch 14600/18276: Loss = 1.7059 (C: 1.7059, R: 0.0000)
Batch 14700/18276: Loss = 1.5487 (C: 1.5487, R: 0.0000)
Batch 14800/18276: Loss = 1.5742 (C: 1.5742, R: 0.0000)
Batch 14900/18276: Loss = 1.6826 (C: 1.6826, R: 0.0000)
Batch 15000/18276: Loss = 1.3886 (C: 1.3886, R: 0.0000)
Batch 15100/18276: Loss = 1.4220 (C: 1.4220, R: 0.0000)
Batch 15200/18276: Loss = 1.2370 (C: 1.2370, R: 0.0000)
Batch 15300/18276: Loss = 1.9783 (C: 1.9783, R: 0.0000)
Batch 15400/18276: Loss = 1.5334 (C: 1.5334, R: 0.0000)
Batch 15500/18276: Loss = 1.4097 (C: 1.4097, R: 0.0000)
Batch 15600/18276: Loss = 1.5589 (C: 1.5589, R: 0.0000)
Batch 15700/18276: Loss = 1.4704 (C: 1.4704, R: 0.0000)
Batch 15800/18276: Loss = 1.6861 (C: 1.6861, R: 0.0000)
Batch 15900/18276: Loss = 1.4193 (C: 1.4193, R: 0.0000)
Batch 16000/18276: Loss = 1.5539 (C: 1.5539, R: 0.0000)
Batch 16100/18276: Loss = 1.5527 (C: 1.5527, R: 0.0000)
Batch 16200/18276: Loss = 1.1689 (C: 1.1689, R: 0.0000)
Batch 16300/18276: Loss = 1.7024 (C: 1.7024, R: 0.0000)
Batch 16400/18276: Loss = 1.5490 (C: 1.5490, R: 0.0000)
Batch 16500/18276: Loss = 1.5564 (C: 1.5564, R: 0.0000)
Batch 16600/18276: Loss = 1.2909 (C: 1.2909, R: 0.0000)
Batch 16700/18276: Loss = 1.3649 (C: 1.3649, R: 0.0000)
Batch 16800/18276: Loss = 1.2085 (C: 1.2085, R: 0.0000)
Batch 16900/18276: Loss = 1.2347 (C: 1.2347, R: 0.0000)
Batch 17000/18276: Loss = 1.4134 (C: 1.4134, R: 0.0000)
Batch 17100/18276: Loss = 1.1961 (C: 1.1961, R: 0.0000)
Batch 17200/18276: Loss = 1.0555 (C: 1.0555, R: 0.0000)
Batch 17300/18276: Loss = 1.5435 (C: 1.5435, R: 0.0000)
Batch 17400/18276: Loss = 1.4094 (C: 1.4094, R: 0.0000)
Batch 17500/18276: Loss = 1.7260 (C: 1.7260, R: 0.0000)
Batch 17600/18276: Loss = 1.2092 (C: 1.2092, R: 0.0000)
Batch 17700/18276: Loss = 1.5979 (C: 1.5979, R: 0.0000)
Batch 17800/18276: Loss = 1.6883 (C: 1.6883, R: 0.0000)
Batch 17900/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 18000/18276: Loss = 1.8353 (C: 1.8353, R: 0.0000)
Batch 18100/18276: Loss = 1.5556 (C: 1.5556, R: 0.0000)
Batch 18200/18276: Loss = 1.1509 (C: 1.1509, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.2379695177078247
  reconstruction_loss raw: 0.0
  total_loss raw: 1.2379695177078247
Epoch 5 completed in 72.34s
Train Loss: 1.4581 (C: 1.4581)
Val Loss: 1.4307 (C: 1.4307)
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/best_model.pt
New best model saved (Val Loss: 1.4307)
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/checkpoint_epoch_5.pt

Epoch 6/50
------------------------------
Batch 0/18276: Loss = 1.7084 (C: 1.7084, R: 0.0000)
Batch 100/18276: Loss = 1.0220 (C: 1.0220, R: 0.0000)
Batch 200/18276: Loss = 1.4193 (C: 1.4193, R: 0.0000)
Batch 300/18276: Loss = 1.5797 (C: 1.5797, R: 0.0000)
Batch 400/18276: Loss = 1.0536 (C: 1.0536, R: 0.0000)
Batch 500/18276: Loss = 1.1440 (C: 1.1440, R: 0.0000)
Batch 600/18276: Loss = 1.8146 (C: 1.8146, R: 0.0000)
Batch 700/18276: Loss = 1.8056 (C: 1.8056, R: 0.0000)
Batch 800/18276: Loss = 1.5763 (C: 1.5763, R: 0.0000)
Batch 900/18276: Loss = 1.1437 (C: 1.1437, R: 0.0000)
Batch 1000/18276: Loss = 1.7519 (C: 1.7519, R: 0.0000)
Batch 1100/18276: Loss = 1.7067 (C: 1.7067, R: 0.0000)
Batch 1200/18276: Loss = 1.0535 (C: 1.0535, R: 0.0000)
Batch 1300/18276: Loss = 1.3795 (C: 1.3795, R: 0.0000)
Batch 1400/18276: Loss = 1.7246 (C: 1.7246, R: 0.0000)
Batch 1500/18276: Loss = 1.2095 (C: 1.2095, R: 0.0000)
Batch 1600/18276: Loss = 1.4081 (C: 1.4081, R: 0.0000)
Batch 1700/18276: Loss = 1.3949 (C: 1.3949, R: 0.0000)
Batch 1800/18276: Loss = 1.2955 (C: 1.2955, R: 0.0000)
Batch 1900/18276: Loss = 0.9835 (C: 0.9835, R: 0.0000)
Batch 2000/18276: Loss = 1.5692 (C: 1.5692, R: 0.0000)
Batch 2100/18276: Loss = 1.5788 (C: 1.5788, R: 0.0000)
Batch 2200/18276: Loss = 1.5558 (C: 1.5558, R: 0.0000)
Batch 2300/18276: Loss = 1.4978 (C: 1.4978, R: 0.0000)
Batch 2400/18276: Loss = 1.1471 (C: 1.1471, R: 0.0000)
Batch 2500/18276: Loss = 1.4084 (C: 1.4084, R: 0.0000)
Batch 2600/18276: Loss = 1.9795 (C: 1.9795, R: 0.0000)
Batch 2700/18276: Loss = 1.3648 (C: 1.3648, R: 0.0000)
Batch 2800/18276: Loss = 1.5478 (C: 1.5478, R: 0.0000)
Batch 2900/18276: Loss = 1.2503 (C: 1.2503, R: 0.0000)
Batch 3000/18276: Loss = 1.8397 (C: 1.8397, R: 0.0000)
Batch 3100/18276: Loss = 1.5527 (C: 1.5527, R: 0.0000)
Batch 3200/18276: Loss = 1.4453 (C: 1.4453, R: 0.0000)
Batch 3300/18276: Loss = 1.4192 (C: 1.4192, R: 0.0000)
Batch 3400/18276: Loss = 1.6550 (C: 1.6550, R: 0.0000)
Batch 3500/18276: Loss = 1.8734 (C: 1.8734, R: 0.0000)
Batch 3600/18276: Loss = 1.5801 (C: 1.5801, R: 0.0000)
Batch 3700/18276: Loss = 1.7072 (C: 1.7072, R: 0.0000)
Batch 3800/18276: Loss = 1.4238 (C: 1.4238, R: 0.0000)
Batch 3900/18276: Loss = 1.4712 (C: 1.4712, R: 0.0000)
Batch 4000/18276: Loss = 1.2952 (C: 1.2952, R: 0.0000)
Batch 4100/18276: Loss = 1.2382 (C: 1.2382, R: 0.0000)
Batch 4200/18276: Loss = 1.4968 (C: 1.4968, R: 0.0000)
Batch 4300/18276: Loss = 1.5483 (C: 1.5483, R: 0.0000)
Batch 4400/18276: Loss = 1.5349 (C: 1.5349, R: 0.0000)
Batch 4500/18276: Loss = 1.4079 (C: 1.4079, R: 0.0000)
Batch 4600/18276: Loss = 1.4725 (C: 1.4725, R: 0.0000)
Batch 4700/18276: Loss = 1.6981 (C: 1.6981, R: 0.0000)
Batch 4800/18276: Loss = 1.2052 (C: 1.2052, R: 0.0000)
Batch 4900/18276: Loss = 1.5954 (C: 1.5954, R: 0.0000)
Batch 5000/18276: Loss = 1.2334 (C: 1.2334, R: 0.0000)
Batch 5100/18276: Loss = 1.4236 (C: 1.4236, R: 0.0000)
Batch 5200/18276: Loss = 1.7029 (C: 1.7029, R: 0.0000)
Batch 5300/18276: Loss = 1.2998 (C: 1.2998, R: 0.0000)
Batch 5400/18276: Loss = 1.4877 (C: 1.4877, R: 0.0000)
Batch 5500/18276: Loss = 1.3528 (C: 1.3528, R: 0.0000)
Batch 5600/18276: Loss = 1.1780 (C: 1.1780, R: 0.0000)
Batch 5700/18276: Loss = 1.5769 (C: 1.5769, R: 0.0000)
Batch 5800/18276: Loss = 1.9317 (C: 1.9317, R: 0.0000)
Batch 5900/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 6000/18276: Loss = 1.5798 (C: 1.5798, R: 0.0000)
Batch 6100/18276: Loss = 1.5478 (C: 1.5478, R: 0.0000)
Batch 6200/18276: Loss = 1.4192 (C: 1.4192, R: 0.0000)
Batch 6300/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 6400/18276: Loss = 1.0604 (C: 1.0604, R: 0.0000)
Batch 6500/18276: Loss = 1.6591 (C: 1.6591, R: 0.0000)
Batch 6600/18276: Loss = 1.5779 (C: 1.5779, R: 0.0000)
Batch 6700/18276: Loss = 1.5488 (C: 1.5488, R: 0.0000)
Batch 6800/18276: Loss = 1.4085 (C: 1.4085, R: 0.0000)
Batch 6900/18276: Loss = 1.7061 (C: 1.7061, R: 0.0000)
Batch 7000/18276: Loss = 1.7068 (C: 1.7068, R: 0.0000)
Batch 7100/18276: Loss = 1.5459 (C: 1.5459, R: 0.0000)
Batch 7200/18276: Loss = 1.5351 (C: 1.5351, R: 0.0000)
Batch 7300/18276: Loss = 1.6546 (C: 1.6546, R: 0.0000)
Batch 7400/18276: Loss = 1.3637 (C: 1.3637, R: 0.0000)
Batch 7500/18276: Loss = 1.2077 (C: 1.2077, R: 0.0000)
Batch 7600/18276: Loss = 1.2050 (C: 1.2050, R: 0.0000)
Batch 7700/18276: Loss = 1.3610 (C: 1.3610, R: 0.0000)
Batch 7800/18276: Loss = 1.8358 (C: 1.8358, R: 0.0000)
Batch 7900/18276: Loss = 1.4947 (C: 1.4947, R: 0.0000)
Batch 8000/18276: Loss = 1.2359 (C: 1.2359, R: 0.0000)
Batch 8100/18276: Loss = 1.7168 (C: 1.7168, R: 0.0000)
Batch 8200/18276: Loss = 1.7112 (C: 1.7112, R: 0.0000)
Batch 8300/18276: Loss = 1.8757 (C: 1.8757, R: 0.0000)
Batch 8400/18276: Loss = 1.8266 (C: 1.8266, R: 0.0000)
Batch 8500/18276: Loss = 1.3659 (C: 1.3659, R: 0.0000)
Batch 8600/18276: Loss = 1.2719 (C: 1.2719, R: 0.0000)
Batch 8700/18276: Loss = 1.4126 (C: 1.4126, R: 0.0000)
Batch 8800/18276: Loss = 1.7203 (C: 1.7203, R: 0.0000)
Batch 8900/18276: Loss = 1.4019 (C: 1.4019, R: 0.0000)
Batch 9000/18276: Loss = 1.0545 (C: 1.0545, R: 0.0000)
Batch 9100/18276: Loss = 1.1508 (C: 1.1508, R: 0.0000)
Batch 9200/18276: Loss = 1.9160 (C: 1.9160, R: 0.0000)
Batch 9300/18276: Loss = 1.2080 (C: 1.2080, R: 0.0000)
Batch 9400/18276: Loss = 1.0571 (C: 1.0571, R: 0.0000)
Batch 9500/18276: Loss = 1.5351 (C: 1.5351, R: 0.0000)
Batch 9600/18276: Loss = 1.0647 (C: 1.0647, R: 0.0000)
Batch 9700/18276: Loss = 1.9037 (C: 1.9037, R: 0.0000)
Batch 9800/18276: Loss = 1.5547 (C: 1.5547, R: 0.0000)
Batch 9900/18276: Loss = 1.4193 (C: 1.4193, R: 0.0000)
Batch 10000/18276: Loss = 1.1449 (C: 1.1449, R: 0.0000)
Batch 10100/18276: Loss = 1.5956 (C: 1.5956, R: 0.0000)
Batch 10200/18276: Loss = 1.4249 (C: 1.4249, R: 0.0000)
Batch 10300/18276: Loss = 1.5553 (C: 1.5553, R: 0.0000)
Batch 10400/18276: Loss = 1.4225 (C: 1.4225, R: 0.0000)
Batch 10500/18276: Loss = 1.4116 (C: 1.4116, R: 0.0000)
Batch 10600/18276: Loss = 1.9245 (C: 1.9245, R: 0.0000)
Batch 10700/18276: Loss = 1.4878 (C: 1.4878, R: 0.0000)
Batch 10800/18276: Loss = 1.7113 (C: 1.7113, R: 0.0000)
Batch 10900/18276: Loss = 1.4025 (C: 1.4025, R: 0.0000)
Batch 11000/18276: Loss = 1.5801 (C: 1.5801, R: 0.0000)
Batch 11100/18276: Loss = 1.3991 (C: 1.3991, R: 0.0000)
Batch 11200/18276: Loss = 1.5489 (C: 1.5489, R: 0.0000)
Batch 11300/18276: Loss = 1.0234 (C: 1.0234, R: 0.0000)
Batch 11400/18276: Loss = 1.2354 (C: 1.2354, R: 0.0000)
Batch 11500/18276: Loss = 1.3780 (C: 1.3780, R: 0.0000)
Batch 11600/18276: Loss = 1.5793 (C: 1.5793, R: 0.0000)
Batch 11700/18276: Loss = 1.5468 (C: 1.5468, R: 0.0000)
Batch 11800/18276: Loss = 1.2113 (C: 1.2113, R: 0.0000)
Batch 11900/18276: Loss = 1.0231 (C: 1.0231, R: 0.0000)
Batch 12000/18276: Loss = 1.6745 (C: 1.6745, R: 0.0000)
Batch 12100/18276: Loss = 1.3298 (C: 1.3298, R: 0.0000)
Batch 12200/18276: Loss = 1.5468 (C: 1.5468, R: 0.0000)
Batch 12300/18276: Loss = 1.9716 (C: 1.9716, R: 0.0000)
Batch 12400/18276: Loss = 1.5567 (C: 1.5567, R: 0.0000)
Batch 12500/18276: Loss = 1.5797 (C: 1.5797, R: 0.0000)
Batch 12600/18276: Loss = 1.6965 (C: 1.6965, R: 0.0000)
Batch 12700/18276: Loss = 1.2371 (C: 1.2371, R: 0.0000)
Batch 12800/18276: Loss = 1.8080 (C: 1.8080, R: 0.0000)
Batch 12900/18276: Loss = 1.6640 (C: 1.6640, R: 0.0000)
Batch 13000/18276: Loss = 1.1867 (C: 1.1867, R: 0.0000)
Batch 13100/18276: Loss = 1.4026 (C: 1.4026, R: 0.0000)
Batch 13200/18276: Loss = 1.0947 (C: 1.0947, R: 0.0000)
Batch 13300/18276: Loss = 1.3542 (C: 1.3542, R: 0.0000)
Batch 13400/18276: Loss = 1.3972 (C: 1.3972, R: 0.0000)
Batch 13500/18276: Loss = 1.5793 (C: 1.5793, R: 0.0000)
Batch 13600/18276: Loss = 1.8096 (C: 1.8096, R: 0.0000)
Batch 13700/18276: Loss = 1.9819 (C: 1.9819, R: 0.0000)
Batch 13800/18276: Loss = 1.7065 (C: 1.7065, R: 0.0000)
Batch 13900/18276: Loss = 1.3652 (C: 1.3652, R: 0.0000)
Batch 14000/18276: Loss = 1.4111 (C: 1.4111, R: 0.0000)
Batch 14100/18276: Loss = 1.5762 (C: 1.5762, R: 0.0000)
Batch 14200/18276: Loss = 1.5728 (C: 1.5728, R: 0.0000)
Batch 14300/18276: Loss = 1.1450 (C: 1.1450, R: 0.0000)
Batch 14400/18276: Loss = 1.8301 (C: 1.8301, R: 0.0000)
Batch 14500/18276: Loss = 1.5517 (C: 1.5517, R: 0.0000)
Batch 14600/18276: Loss = 1.5511 (C: 1.5511, R: 0.0000)
Batch 14700/18276: Loss = 1.0247 (C: 1.0247, R: 0.0000)
Batch 14800/18276: Loss = 1.3555 (C: 1.3555, R: 0.0000)
Batch 14900/18276: Loss = 1.9790 (C: 1.9790, R: 0.0000)
Batch 15000/18276: Loss = 1.4096 (C: 1.4096, R: 0.0000)
Batch 15100/18276: Loss = 1.1514 (C: 1.1514, R: 0.0000)
Batch 15200/18276: Loss = 1.6683 (C: 1.6683, R: 0.0000)
Batch 15300/18276: Loss = 1.5001 (C: 1.5001, R: 0.0000)
Batch 15400/18276: Loss = 1.7192 (C: 1.7192, R: 0.0000)
Batch 15500/18276: Loss = 1.2376 (C: 1.2376, R: 0.0000)
Batch 15600/18276: Loss = 1.4951 (C: 1.4951, R: 0.0000)
Batch 15700/18276: Loss = 1.4029 (C: 1.4029, R: 0.0000)
Batch 15800/18276: Loss = 1.0298 (C: 1.0298, R: 0.0000)
Batch 15900/18276: Loss = 1.5805 (C: 1.5805, R: 0.0000)
Batch 16000/18276: Loss = 1.2045 (C: 1.2045, R: 0.0000)
Batch 16100/18276: Loss = 1.4118 (C: 1.4118, R: 0.0000)
Batch 16200/18276: Loss = 1.2380 (C: 1.2380, R: 0.0000)
Batch 16300/18276: Loss = 1.6923 (C: 1.6923, R: 0.0000)
Batch 16400/18276: Loss = 1.7325 (C: 1.7325, R: 0.0000)
Batch 16500/18276: Loss = 1.3644 (C: 1.3644, R: 0.0000)
Batch 16600/18276: Loss = 1.4071 (C: 1.4071, R: 0.0000)
Batch 16700/18276: Loss = 1.5795 (C: 1.5795, R: 0.0000)
Batch 16800/18276: Loss = 1.6391 (C: 1.6391, R: 0.0000)
Batch 16900/18276: Loss = 1.7904 (C: 1.7904, R: 0.0000)
Batch 17000/18276: Loss = 1.9185 (C: 1.9185, R: 0.0000)
Batch 17100/18276: Loss = 1.0250 (C: 1.0250, R: 0.0000)
Batch 17200/18276: Loss = 1.4713 (C: 1.4713, R: 0.0000)
Batch 17300/18276: Loss = 1.7708 (C: 1.7708, R: 0.0000)
Batch 17400/18276: Loss = 1.8309 (C: 1.8309, R: 0.0000)
Batch 17500/18276: Loss = 1.7095 (C: 1.7095, R: 0.0000)
Batch 17600/18276: Loss = 1.8313 (C: 1.8313, R: 0.0000)
Batch 17700/18276: Loss = 1.2064 (C: 1.2064, R: 0.0000)
Batch 17800/18276: Loss = 1.0327 (C: 1.0327, R: 0.0000)
Batch 17900/18276: Loss = 1.4313 (C: 1.4313, R: 0.0000)
Batch 18000/18276: Loss = 1.0581 (C: 1.0581, R: 0.0000)
Batch 18100/18276: Loss = 1.9186 (C: 1.9186, R: 0.0000)
Batch 18200/18276: Loss = 1.8041 (C: 1.8041, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 0.97950679063797
  reconstruction_loss raw: 0.0
  total_loss raw: 0.97950679063797
Epoch 6 completed in 72.50s
Train Loss: 1.4561 (C: 1.4561)
Val Loss: 1.4385 (C: 1.4385)
No improvement for 1 epochs

Epoch 7/50
------------------------------
Batch 0/18276: Loss = 1.7136 (C: 1.7136, R: 0.0000)
Batch 100/18276: Loss = 1.4102 (C: 1.4102, R: 0.0000)
Batch 200/18276: Loss = 1.5413 (C: 1.5413, R: 0.0000)
Batch 300/18276: Loss = 1.7028 (C: 1.7028, R: 0.0000)
Batch 400/18276: Loss = 1.0250 (C: 1.0250, R: 0.0000)
Batch 500/18276: Loss = 1.4938 (C: 1.4938, R: 0.0000)
Batch 600/18276: Loss = 1.2091 (C: 1.2091, R: 0.0000)
Batch 700/18276: Loss = 1.5431 (C: 1.5431, R: 0.0000)
Batch 800/18276: Loss = 1.5753 (C: 1.5753, R: 0.0000)
Batch 900/18276: Loss = 1.4496 (C: 1.4496, R: 0.0000)
Batch 1000/18276: Loss = 1.1480 (C: 1.1480, R: 0.0000)
Batch 1100/18276: Loss = 1.1426 (C: 1.1426, R: 0.0000)
Batch 1200/18276: Loss = 1.7029 (C: 1.7029, R: 0.0000)
Batch 1300/18276: Loss = 0.8012 (C: 0.8012, R: 0.0000)
Batch 1400/18276: Loss = 1.4023 (C: 1.4023, R: 0.0000)
Batch 1500/18276: Loss = 1.5335 (C: 1.5335, R: 0.0000)
Batch 1600/18276: Loss = 1.6622 (C: 1.6622, R: 0.0000)
Batch 1700/18276: Loss = 1.5631 (C: 1.5631, R: 0.0000)
Batch 1800/18276: Loss = 1.1443 (C: 1.1443, R: 0.0000)
Batch 1900/18276: Loss = 1.8102 (C: 1.8102, R: 0.0000)
Batch 2000/18276: Loss = 1.4071 (C: 1.4071, R: 0.0000)
Batch 2100/18276: Loss = 1.5830 (C: 1.5830, R: 0.0000)
Batch 2200/18276: Loss = 1.5459 (C: 1.5459, R: 0.0000)
Batch 2300/18276: Loss = 1.4589 (C: 1.4589, R: 0.0000)
Batch 2400/18276: Loss = 1.2850 (C: 1.2850, R: 0.0000)
Batch 2500/18276: Loss = 1.4862 (C: 1.4862, R: 0.0000)
Batch 2600/18276: Loss = 1.6978 (C: 1.6978, R: 0.0000)
Batch 2700/18276: Loss = 1.0374 (C: 1.0374, R: 0.0000)
Batch 2800/18276: Loss = 1.3660 (C: 1.3660, R: 0.0000)
Batch 2900/18276: Loss = 1.5693 (C: 1.5693, R: 0.0000)
Batch 3000/18276: Loss = 1.4088 (C: 1.4088, R: 0.0000)
Batch 3100/18276: Loss = 1.2650 (C: 1.2650, R: 0.0000)
Batch 3200/18276: Loss = 1.7649 (C: 1.7649, R: 0.0000)
Batch 3300/18276: Loss = 1.8103 (C: 1.8103, R: 0.0000)
Batch 3400/18276: Loss = 1.4583 (C: 1.4583, R: 0.0000)
Batch 3500/18276: Loss = 1.3671 (C: 1.3671, R: 0.0000)
Batch 3600/18276: Loss = 1.5812 (C: 1.5812, R: 0.0000)
Batch 3700/18276: Loss = 1.1775 (C: 1.1775, R: 0.0000)
Batch 3800/18276: Loss = 1.2047 (C: 1.2047, R: 0.0000)
Batch 3900/18276: Loss = 1.3655 (C: 1.3655, R: 0.0000)
Batch 4000/18276: Loss = 1.5372 (C: 1.5372, R: 0.0000)
Batch 4100/18276: Loss = 1.2388 (C: 1.2388, R: 0.0000)
Batch 4200/18276: Loss = 1.2048 (C: 1.2048, R: 0.0000)
Batch 4300/18276: Loss = 1.2150 (C: 1.2150, R: 0.0000)
Batch 4400/18276: Loss = 1.7104 (C: 1.7104, R: 0.0000)
Batch 4500/18276: Loss = 1.5963 (C: 1.5963, R: 0.0000)
Batch 4600/18276: Loss = 1.5909 (C: 1.5909, R: 0.0000)
Batch 4700/18276: Loss = 1.9776 (C: 1.9776, R: 0.0000)
Batch 4800/18276: Loss = 1.0229 (C: 1.0229, R: 0.0000)
Batch 4900/18276: Loss = 1.7047 (C: 1.7047, R: 0.0000)
Batch 5000/18276: Loss = 1.5727 (C: 1.5727, R: 0.0000)
Batch 5100/18276: Loss = 1.8027 (C: 1.8027, R: 0.0000)
Batch 5200/18276: Loss = 1.4043 (C: 1.4043, R: 0.0000)
Batch 5300/18276: Loss = 1.7084 (C: 1.7084, R: 0.0000)
Batch 5400/18276: Loss = 1.6494 (C: 1.6494, R: 0.0000)
Batch 5500/18276: Loss = 1.9202 (C: 1.9202, R: 0.0000)
Batch 5600/18276: Loss = 1.7245 (C: 1.7245, R: 0.0000)
Batch 5700/18276: Loss = 1.3584 (C: 1.3584, R: 0.0000)
Batch 5800/18276: Loss = 1.0541 (C: 1.0541, R: 0.0000)
Batch 5900/18276: Loss = 1.7198 (C: 1.7198, R: 0.0000)
Batch 6000/18276: Loss = 1.2274 (C: 1.2274, R: 0.0000)
Batch 6100/18276: Loss = 1.2034 (C: 1.2034, R: 0.0000)
Batch 6200/18276: Loss = 0.9789 (C: 0.9789, R: 0.0000)
Batch 6300/18276: Loss = 1.2372 (C: 1.2372, R: 0.0000)
Batch 6400/18276: Loss = 1.5480 (C: 1.5480, R: 0.0000)
Batch 6500/18276: Loss = 1.3587 (C: 1.3587, R: 0.0000)
Batch 6600/18276: Loss = 1.5732 (C: 1.5732, R: 0.0000)
Batch 6700/18276: Loss = 1.8603 (C: 1.8603, R: 0.0000)
Batch 6800/18276: Loss = 1.4200 (C: 1.4200, R: 0.0000)
Batch 6900/18276: Loss = 1.5776 (C: 1.5776, R: 0.0000)
Batch 7000/18276: Loss = 1.1504 (C: 1.1504, R: 0.0000)
Batch 7100/18276: Loss = 1.3729 (C: 1.3729, R: 0.0000)
Batch 7200/18276: Loss = 1.2047 (C: 1.2047, R: 0.0000)
Batch 7300/18276: Loss = 1.2094 (C: 1.2094, R: 0.0000)
Batch 7400/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 7500/18276: Loss = 1.9244 (C: 1.9244, R: 0.0000)
Batch 7600/18276: Loss = 1.7398 (C: 1.7398, R: 0.0000)
Batch 7700/18276: Loss = 1.4239 (C: 1.4239, R: 0.0000)
Batch 7800/18276: Loss = 1.3957 (C: 1.3957, R: 0.0000)
Batch 7900/18276: Loss = 1.5565 (C: 1.5565, R: 0.0000)
Batch 8000/18276: Loss = 1.4530 (C: 1.4530, R: 0.0000)
Batch 8100/18276: Loss = 1.2372 (C: 1.2372, R: 0.0000)
Batch 8200/18276: Loss = 1.5796 (C: 1.5796, R: 0.0000)
Batch 8300/18276: Loss = 1.5831 (C: 1.5831, R: 0.0000)
Batch 8400/18276: Loss = 1.4051 (C: 1.4051, R: 0.0000)
Batch 8500/18276: Loss = 1.6028 (C: 1.6028, R: 0.0000)
Batch 8600/18276: Loss = 1.0272 (C: 1.0272, R: 0.0000)
Batch 8700/18276: Loss = 1.5727 (C: 1.5727, R: 0.0000)
Batch 8800/18276: Loss = 1.4015 (C: 1.4015, R: 0.0000)
Batch 8900/18276: Loss = 1.8076 (C: 1.8076, R: 0.0000)
Batch 9000/18276: Loss = 1.6977 (C: 1.6977, R: 0.0000)
Batch 9100/18276: Loss = 1.3531 (C: 1.3531, R: 0.0000)
Batch 9200/18276: Loss = 1.0250 (C: 1.0250, R: 0.0000)
Batch 9300/18276: Loss = 1.4097 (C: 1.4097, R: 0.0000)
Batch 9400/18276: Loss = 1.8397 (C: 1.8397, R: 0.0000)
Batch 9500/18276: Loss = 1.5990 (C: 1.5990, R: 0.0000)
Batch 9600/18276: Loss = 1.7205 (C: 1.7205, R: 0.0000)
Batch 9700/18276: Loss = 1.4803 (C: 1.4803, R: 0.0000)
Batch 9800/18276: Loss = 1.3677 (C: 1.3677, R: 0.0000)
Batch 9900/18276: Loss = 1.6668 (C: 1.6668, R: 0.0000)
Batch 10000/18276: Loss = 1.5781 (C: 1.5781, R: 0.0000)
Batch 10100/18276: Loss = 1.2047 (C: 1.2047, R: 0.0000)
Batch 10200/18276: Loss = 1.3549 (C: 1.3549, R: 0.0000)
Batch 10300/18276: Loss = 1.5253 (C: 1.5253, R: 0.0000)
Batch 10400/18276: Loss = 1.4130 (C: 1.4130, R: 0.0000)
Batch 10500/18276: Loss = 1.2341 (C: 1.2341, R: 0.0000)
Batch 10600/18276: Loss = 1.1448 (C: 1.1448, R: 0.0000)
Batch 10700/18276: Loss = 1.2399 (C: 1.2399, R: 0.0000)
Batch 10800/18276: Loss = 1.2522 (C: 1.2522, R: 0.0000)
Batch 10900/18276: Loss = 1.2216 (C: 1.2216, R: 0.0000)
Batch 11000/18276: Loss = 1.4571 (C: 1.4571, R: 0.0000)
Batch 11100/18276: Loss = 1.3364 (C: 1.3364, R: 0.0000)
Batch 11200/18276: Loss = 1.3802 (C: 1.3802, R: 0.0000)
Batch 11300/18276: Loss = 1.5570 (C: 1.5570, R: 0.0000)
Batch 11400/18276: Loss = 0.9474 (C: 0.9474, R: 0.0000)
Batch 11500/18276: Loss = 1.7021 (C: 1.7021, R: 0.0000)
Batch 11600/18276: Loss = 1.8662 (C: 1.8662, R: 0.0000)
Batch 11700/18276: Loss = 1.7078 (C: 1.7078, R: 0.0000)
Batch 11800/18276: Loss = 1.4048 (C: 1.4048, R: 0.0000)
Batch 11900/18276: Loss = 1.3697 (C: 1.3697, R: 0.0000)
Batch 12000/18276: Loss = 1.4911 (C: 1.4911, R: 0.0000)
Batch 12100/18276: Loss = 1.6643 (C: 1.6643, R: 0.0000)
Batch 12200/18276: Loss = 1.4936 (C: 1.4936, R: 0.0000)
Batch 12300/18276: Loss = 1.5727 (C: 1.5727, R: 0.0000)
Batch 12400/18276: Loss = 1.7234 (C: 1.7234, R: 0.0000)
Batch 12500/18276: Loss = 1.4207 (C: 1.4207, R: 0.0000)
Batch 12600/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 12700/18276: Loss = 1.7923 (C: 1.7923, R: 0.0000)
Batch 12800/18276: Loss = 1.5869 (C: 1.5869, R: 0.0000)
Batch 12900/18276: Loss = 1.2960 (C: 1.2960, R: 0.0000)
Batch 13000/18276: Loss = 1.4857 (C: 1.4857, R: 0.0000)
Batch 13100/18276: Loss = 1.0232 (C: 1.0232, R: 0.0000)
Batch 13200/18276: Loss = 1.4180 (C: 1.4180, R: 0.0000)
Batch 13300/18276: Loss = 1.4317 (C: 1.4317, R: 0.0000)
Batch 13400/18276: Loss = 1.3767 (C: 1.3767, R: 0.0000)
Batch 13500/18276: Loss = 1.7094 (C: 1.7094, R: 0.0000)
Batch 13600/18276: Loss = 1.2102 (C: 1.2102, R: 0.0000)
Batch 13700/18276: Loss = 0.6672 (C: 0.6672, R: 0.0000)
Batch 13800/18276: Loss = 1.6562 (C: 1.6562, R: 0.0000)
Batch 13900/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 14000/18276: Loss = 1.2367 (C: 1.2367, R: 0.0000)
Batch 14100/18276: Loss = 1.3898 (C: 1.3898, R: 0.0000)
Batch 14200/18276: Loss = 1.4133 (C: 1.4133, R: 0.0000)
Batch 14300/18276: Loss = 1.5693 (C: 1.5693, R: 0.0000)
Batch 14400/18276: Loss = 1.7064 (C: 1.7064, R: 0.0000)
Batch 14500/18276: Loss = 1.8300 (C: 1.8300, R: 0.0000)
Batch 14600/18276: Loss = 1.2775 (C: 1.2775, R: 0.0000)
Batch 14700/18276: Loss = 1.6549 (C: 1.6549, R: 0.0000)
Batch 14800/18276: Loss = 1.1888 (C: 1.1888, R: 0.0000)
Batch 14900/18276: Loss = 1.4076 (C: 1.4076, R: 0.0000)
Batch 15000/18276: Loss = 1.0073 (C: 1.0073, R: 0.0000)
Batch 15100/18276: Loss = 0.9915 (C: 0.9915, R: 0.0000)
Batch 15200/18276: Loss = 1.3652 (C: 1.3652, R: 0.0000)
Batch 15300/18276: Loss = 1.2101 (C: 1.2101, R: 0.0000)
Batch 15400/18276: Loss = 1.0293 (C: 1.0293, R: 0.0000)
Batch 15500/18276: Loss = 0.8412 (C: 0.8412, R: 0.0000)
Batch 15600/18276: Loss = 1.1621 (C: 1.1621, R: 0.0000)
Batch 15700/18276: Loss = 1.7244 (C: 1.7244, R: 0.0000)
Batch 15800/18276: Loss = 1.7016 (C: 1.7016, R: 0.0000)
Batch 15900/18276: Loss = 1.2360 (C: 1.2360, R: 0.0000)
Batch 16000/18276: Loss = 1.8060 (C: 1.8060, R: 0.0000)
Batch 16100/18276: Loss = 1.6810 (C: 1.6810, R: 0.0000)
Batch 16200/18276: Loss = 1.4913 (C: 1.4913, R: 0.0000)
Batch 16300/18276: Loss = 1.5653 (C: 1.5653, R: 0.0000)
Batch 16400/18276: Loss = 1.8044 (C: 1.8044, R: 0.0000)
Batch 16500/18276: Loss = 1.7095 (C: 1.7095, R: 0.0000)
Batch 16600/18276: Loss = 1.4032 (C: 1.4032, R: 0.0000)
Batch 16700/18276: Loss = 1.2512 (C: 1.2512, R: 0.0000)
Batch 16800/18276: Loss = 1.5823 (C: 1.5823, R: 0.0000)
Batch 16900/18276: Loss = 1.5487 (C: 1.5487, R: 0.0000)
Batch 17000/18276: Loss = 1.8382 (C: 1.8382, R: 0.0000)
Batch 17100/18276: Loss = 1.2362 (C: 1.2362, R: 0.0000)
Batch 17200/18276: Loss = 1.5483 (C: 1.5483, R: 0.0000)
Batch 17300/18276: Loss = 1.5547 (C: 1.5547, R: 0.0000)
Batch 17400/18276: Loss = 1.2380 (C: 1.2380, R: 0.0000)
Batch 17500/18276: Loss = 1.4192 (C: 1.4192, R: 0.0000)
Batch 17600/18276: Loss = 1.7923 (C: 1.7923, R: 0.0000)
Batch 17700/18276: Loss = 0.9342 (C: 0.9342, R: 0.0000)
Batch 17800/18276: Loss = 1.8147 (C: 1.8147, R: 0.0000)
Batch 17900/18276: Loss = 1.6594 (C: 1.6594, R: 0.0000)
Batch 18000/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 18100/18276: Loss = 1.8008 (C: 1.8008, R: 0.0000)
Batch 18200/18276: Loss = 1.4180 (C: 1.4180, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.4105103015899658
  reconstruction_loss raw: 0.0
  total_loss raw: 1.4105103015899658
Epoch 7 completed in 71.97s
Train Loss: 1.4538 (C: 1.4538)
Val Loss: 1.4260 (C: 1.4260)
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/best_model.pt
New best model saved (Val Loss: 1.4260)

Epoch 8/50
------------------------------
Batch 0/18276: Loss = 1.4602 (C: 1.4602, R: 0.0000)
Batch 100/18276: Loss = 1.5731 (C: 1.5731, R: 0.0000)
Batch 200/18276: Loss = 1.2346 (C: 1.2346, R: 0.0000)
Batch 300/18276: Loss = 1.4409 (C: 1.4409, R: 0.0000)
Batch 400/18276: Loss = 1.4241 (C: 1.4241, R: 0.0000)
Batch 500/18276: Loss = 1.7023 (C: 1.7023, R: 0.0000)
Batch 600/18276: Loss = 1.4955 (C: 1.4955, R: 0.0000)
Batch 700/18276: Loss = 1.2357 (C: 1.2357, R: 0.0000)
Batch 800/18276: Loss = 1.2956 (C: 1.2956, R: 0.0000)
Batch 900/18276: Loss = 1.2055 (C: 1.2055, R: 0.0000)
Batch 1000/18276: Loss = 1.2385 (C: 1.2385, R: 0.0000)
Batch 1100/18276: Loss = 1.3548 (C: 1.3548, R: 0.0000)
Batch 1200/18276: Loss = 1.7203 (C: 1.7203, R: 0.0000)
Batch 1300/18276: Loss = 1.0260 (C: 1.0260, R: 0.0000)
Batch 1400/18276: Loss = 1.0661 (C: 1.0661, R: 0.0000)
Batch 1500/18276: Loss = 1.8362 (C: 1.8362, R: 0.0000)
Batch 1600/18276: Loss = 1.3648 (C: 1.3648, R: 0.0000)
Batch 1700/18276: Loss = 1.3528 (C: 1.3528, R: 0.0000)
Batch 1800/18276: Loss = 1.5484 (C: 1.5484, R: 0.0000)
Batch 1900/18276: Loss = 1.7012 (C: 1.7012, R: 0.0000)
Batch 2000/18276: Loss = 1.4089 (C: 1.4089, R: 0.0000)
Batch 2100/18276: Loss = 1.6981 (C: 1.6981, R: 0.0000)
Batch 2200/18276: Loss = 1.2864 (C: 1.2864, R: 0.0000)
Batch 2300/18276: Loss = 1.7084 (C: 1.7084, R: 0.0000)
Batch 2400/18276: Loss = 1.2091 (C: 1.2091, R: 0.0000)
Batch 2500/18276: Loss = 1.7089 (C: 1.7089, R: 0.0000)
Batch 2600/18276: Loss = 1.1388 (C: 1.1388, R: 0.0000)
Batch 2700/18276: Loss = 1.7928 (C: 1.7928, R: 0.0000)
Batch 2800/18276: Loss = 1.5485 (C: 1.5485, R: 0.0000)
Batch 2900/18276: Loss = 1.3522 (C: 1.3522, R: 0.0000)
Batch 3000/18276: Loss = 1.3661 (C: 1.3661, R: 0.0000)
Batch 3100/18276: Loss = 1.6979 (C: 1.6979, R: 0.0000)
Batch 3200/18276: Loss = 1.1949 (C: 1.1949, R: 0.0000)
Batch 3300/18276: Loss = 1.3653 (C: 1.3653, R: 0.0000)
Batch 3400/18276: Loss = 1.4971 (C: 1.4971, R: 0.0000)
Batch 3500/18276: Loss = 0.9048 (C: 0.9048, R: 0.0000)
Batch 3600/18276: Loss = 1.4016 (C: 1.4016, R: 0.0000)
Batch 3700/18276: Loss = 1.4874 (C: 1.4874, R: 0.0000)
Batch 3800/18276: Loss = 1.2342 (C: 1.2342, R: 0.0000)
Batch 3900/18276: Loss = 1.4092 (C: 1.4092, R: 0.0000)
Batch 4000/18276: Loss = 1.2995 (C: 1.2995, R: 0.0000)
Batch 4100/18276: Loss = 1.7040 (C: 1.7040, R: 0.0000)
Batch 4200/18276: Loss = 1.8800 (C: 1.8800, R: 0.0000)
Batch 4300/18276: Loss = 1.5809 (C: 1.5809, R: 0.0000)
Batch 4400/18276: Loss = 1.4073 (C: 1.4073, R: 0.0000)
Batch 4500/18276: Loss = 1.3685 (C: 1.3685, R: 0.0000)
Batch 4600/18276: Loss = 1.3603 (C: 1.3603, R: 0.0000)
Batch 4700/18276: Loss = 1.2773 (C: 1.2773, R: 0.0000)
Batch 4800/18276: Loss = 1.1443 (C: 1.1443, R: 0.0000)
Batch 4900/18276: Loss = 1.5797 (C: 1.5797, R: 0.0000)
Batch 5000/18276: Loss = 1.7418 (C: 1.7418, R: 0.0000)
Batch 5100/18276: Loss = 1.5685 (C: 1.5685, R: 0.0000)
Batch 5200/18276: Loss = 1.7635 (C: 1.7635, R: 0.0000)
Batch 5300/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 5400/18276: Loss = 1.6668 (C: 1.6668, R: 0.0000)
Batch 5500/18276: Loss = 1.7526 (C: 1.7526, R: 0.0000)
Batch 5600/18276: Loss = 1.7165 (C: 1.7165, R: 0.0000)
Batch 5700/18276: Loss = 1.5731 (C: 1.5731, R: 0.0000)
Batch 5800/18276: Loss = 1.8643 (C: 1.8643, R: 0.0000)
Batch 5900/18276: Loss = 1.5487 (C: 1.5487, R: 0.0000)
Batch 6000/18276: Loss = 1.4015 (C: 1.4015, R: 0.0000)
Batch 6100/18276: Loss = 1.7076 (C: 1.7076, R: 0.0000)
Batch 6200/18276: Loss = 1.5741 (C: 1.5741, R: 0.0000)
Batch 6300/18276: Loss = 1.2314 (C: 1.2314, R: 0.0000)
Batch 6400/18276: Loss = 1.8430 (C: 1.8430, R: 0.0000)
Batch 6500/18276: Loss = 1.4889 (C: 1.4889, R: 0.0000)
Batch 6600/18276: Loss = 1.4235 (C: 1.4235, R: 0.0000)
Batch 6700/18276: Loss = 1.3646 (C: 1.3646, R: 0.0000)
Batch 6800/18276: Loss = 1.2511 (C: 1.2511, R: 0.0000)
Batch 6900/18276: Loss = 1.4016 (C: 1.4016, R: 0.0000)
Batch 7000/18276: Loss = 1.5591 (C: 1.5591, R: 0.0000)
Batch 7100/18276: Loss = 1.3546 (C: 1.3546, R: 0.0000)
Batch 7200/18276: Loss = 1.6651 (C: 1.6651, R: 0.0000)
Batch 7300/18276: Loss = 1.1532 (C: 1.1532, R: 0.0000)
Batch 7400/18276: Loss = 1.5722 (C: 1.5722, R: 0.0000)
Batch 7500/18276: Loss = 1.1428 (C: 1.1428, R: 0.0000)
Batch 7600/18276: Loss = 1.2355 (C: 1.2355, R: 0.0000)
Batch 7700/18276: Loss = 1.7968 (C: 1.7968, R: 0.0000)
Batch 7800/18276: Loss = 1.7937 (C: 1.7937, R: 0.0000)
Batch 7900/18276: Loss = 1.4163 (C: 1.4163, R: 0.0000)
Batch 8000/18276: Loss = 1.5347 (C: 1.5347, R: 0.0000)
Batch 8100/18276: Loss = 1.3645 (C: 1.3645, R: 0.0000)
Batch 8200/18276: Loss = 1.7930 (C: 1.7930, R: 0.0000)
Batch 8300/18276: Loss = 1.1437 (C: 1.1437, R: 0.0000)
Batch 8400/18276: Loss = 1.1444 (C: 1.1444, R: 0.0000)
Batch 8500/18276: Loss = 1.6849 (C: 1.6849, R: 0.0000)
Batch 8600/18276: Loss = 1.0541 (C: 1.0541, R: 0.0000)
Batch 8700/18276: Loss = 1.3644 (C: 1.3644, R: 0.0000)
Batch 8800/18276: Loss = 1.2363 (C: 1.2363, R: 0.0000)
Batch 8900/18276: Loss = 1.8739 (C: 1.8739, R: 0.0000)
Batch 9000/18276: Loss = 1.5594 (C: 1.5594, R: 0.0000)
Batch 9100/18276: Loss = 1.4074 (C: 1.4074, R: 0.0000)
Batch 9200/18276: Loss = 1.3665 (C: 1.3665, R: 0.0000)
Batch 9300/18276: Loss = 1.7097 (C: 1.7097, R: 0.0000)
Batch 9400/18276: Loss = 1.8085 (C: 1.8085, R: 0.0000)
Batch 9500/18276: Loss = 1.2364 (C: 1.2364, R: 0.0000)
Batch 9600/18276: Loss = 1.3645 (C: 1.3645, R: 0.0000)
Batch 9700/18276: Loss = 1.4239 (C: 1.4239, R: 0.0000)
Batch 9800/18276: Loss = 1.4080 (C: 1.4080, R: 0.0000)
Batch 9900/18276: Loss = 1.4768 (C: 1.4768, R: 0.0000)
Batch 10000/18276: Loss = 1.4016 (C: 1.4016, R: 0.0000)
Batch 10100/18276: Loss = 1.7234 (C: 1.7234, R: 0.0000)
Batch 10200/18276: Loss = 1.8175 (C: 1.8175, R: 0.0000)
Batch 10300/18276: Loss = 1.2365 (C: 1.2365, R: 0.0000)
Batch 10400/18276: Loss = 1.5807 (C: 1.5807, R: 0.0000)
Batch 10500/18276: Loss = 1.2045 (C: 1.2045, R: 0.0000)
Batch 10600/18276: Loss = 1.2809 (C: 1.2809, R: 0.0000)
Batch 10700/18276: Loss = 1.6358 (C: 1.6358, R: 0.0000)
Batch 10800/18276: Loss = 1.5723 (C: 1.5723, R: 0.0000)
Batch 10900/18276: Loss = 1.3313 (C: 1.3313, R: 0.0000)
Batch 11000/18276: Loss = 1.2049 (C: 1.2049, R: 0.0000)
Batch 11100/18276: Loss = 1.2312 (C: 1.2312, R: 0.0000)
Batch 11200/18276: Loss = 0.8745 (C: 0.8745, R: 0.0000)
Batch 11300/18276: Loss = 1.0271 (C: 1.0271, R: 0.0000)
Batch 11400/18276: Loss = 0.6675 (C: 0.6675, R: 0.0000)
Batch 11500/18276: Loss = 1.7516 (C: 1.7516, R: 0.0000)
Batch 11600/18276: Loss = 1.3951 (C: 1.3951, R: 0.0000)
Batch 11700/18276: Loss = 1.2342 (C: 1.2342, R: 0.0000)
Batch 11800/18276: Loss = 1.2783 (C: 1.2783, R: 0.0000)
Batch 11900/18276: Loss = 1.8954 (C: 1.8954, R: 0.0000)
Batch 12000/18276: Loss = 2.0474 (C: 2.0474, R: 0.0000)
Batch 12100/18276: Loss = 1.4082 (C: 1.4082, R: 0.0000)
Batch 12200/18276: Loss = 1.4114 (C: 1.4114, R: 0.0000)
Batch 12300/18276: Loss = 1.1892 (C: 1.1892, R: 0.0000)
Batch 12400/18276: Loss = 1.2938 (C: 1.2938, R: 0.0000)
Batch 12500/18276: Loss = 1.7965 (C: 1.7965, R: 0.0000)
Batch 12600/18276: Loss = 1.4201 (C: 1.4201, R: 0.0000)
Batch 12700/18276: Loss = 1.7088 (C: 1.7088, R: 0.0000)
Batch 12800/18276: Loss = 1.5727 (C: 1.5727, R: 0.0000)
Batch 12900/18276: Loss = 1.2389 (C: 1.2389, R: 0.0000)
Batch 13000/18276: Loss = 1.4231 (C: 1.4231, R: 0.0000)
Batch 13100/18276: Loss = 1.2955 (C: 1.2955, R: 0.0000)
Batch 13200/18276: Loss = 1.2601 (C: 1.2601, R: 0.0000)
Batch 13300/18276: Loss = 1.3559 (C: 1.3559, R: 0.0000)
Batch 13400/18276: Loss = 1.2046 (C: 1.2046, R: 0.0000)
Batch 13500/18276: Loss = 1.5297 (C: 1.5297, R: 0.0000)
Batch 13600/18276: Loss = 1.2582 (C: 1.2582, R: 0.0000)
Batch 13700/18276: Loss = 0.9163 (C: 0.9163, R: 0.0000)
Batch 13800/18276: Loss = 1.4726 (C: 1.4726, R: 0.0000)
Batch 13900/18276: Loss = 1.0213 (C: 1.0213, R: 0.0000)
Batch 14000/18276: Loss = 1.2791 (C: 1.2791, R: 0.0000)
Batch 14100/18276: Loss = 1.1707 (C: 1.1707, R: 0.0000)
Batch 14200/18276: Loss = 1.2775 (C: 1.2775, R: 0.0000)
Batch 14300/18276: Loss = 1.5736 (C: 1.5736, R: 0.0000)
Batch 14400/18276: Loss = 1.7975 (C: 1.7975, R: 0.0000)
Batch 14500/18276: Loss = 1.4031 (C: 1.4031, R: 0.0000)
Batch 14600/18276: Loss = 1.4319 (C: 1.4319, R: 0.0000)
Batch 14700/18276: Loss = 1.6674 (C: 1.6674, R: 0.0000)
Batch 14800/18276: Loss = 1.1478 (C: 1.1478, R: 0.0000)
Batch 14900/18276: Loss = 1.5802 (C: 1.5802, R: 0.0000)
Batch 15000/18276: Loss = 1.8286 (C: 1.8286, R: 0.0000)
Batch 15100/18276: Loss = 1.2366 (C: 1.2366, R: 0.0000)
Batch 15200/18276: Loss = 1.5739 (C: 1.5739, R: 0.0000)
Batch 15300/18276: Loss = 1.4021 (C: 1.4021, R: 0.0000)
Batch 15400/18276: Loss = 1.8775 (C: 1.8775, R: 0.0000)
Batch 15500/18276: Loss = 1.5742 (C: 1.5742, R: 0.0000)
Batch 15600/18276: Loss = 1.5693 (C: 1.5693, R: 0.0000)
Batch 15700/18276: Loss = 1.5583 (C: 1.5583, R: 0.0000)
Batch 15800/18276: Loss = 1.3987 (C: 1.3987, R: 0.0000)
Batch 15900/18276: Loss = 1.4268 (C: 1.4268, R: 0.0000)
Batch 16000/18276: Loss = 1.7064 (C: 1.7064, R: 0.0000)
Batch 16100/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 16200/18276: Loss = 1.5184 (C: 1.5184, R: 0.0000)
Batch 16300/18276: Loss = 1.6999 (C: 1.6999, R: 0.0000)
Batch 16400/18276: Loss = 1.5532 (C: 1.5532, R: 0.0000)
Batch 16500/18276: Loss = 0.9789 (C: 0.9789, R: 0.0000)
Batch 16600/18276: Loss = 1.8264 (C: 1.8264, R: 0.0000)
Batch 16700/18276: Loss = 1.7015 (C: 1.7015, R: 0.0000)
Batch 16800/18276: Loss = 1.4197 (C: 1.4197, R: 0.0000)
Batch 16900/18276: Loss = 1.3647 (C: 1.3647, R: 0.0000)
Batch 17000/18276: Loss = 1.4058 (C: 1.4058, R: 0.0000)
Batch 17100/18276: Loss = 1.2374 (C: 1.2374, R: 0.0000)
Batch 17200/18276: Loss = 1.4092 (C: 1.4092, R: 0.0000)
Batch 17300/18276: Loss = 1.1440 (C: 1.1440, R: 0.0000)
Batch 17400/18276: Loss = 1.5483 (C: 1.5483, R: 0.0000)
Batch 17500/18276: Loss = 1.2147 (C: 1.2147, R: 0.0000)
Batch 17600/18276: Loss = 1.7076 (C: 1.7076, R: 0.0000)
Batch 17700/18276: Loss = 1.3544 (C: 1.3544, R: 0.0000)
Batch 17800/18276: Loss = 1.1868 (C: 1.1868, R: 0.0000)
Batch 17900/18276: Loss = 1.5559 (C: 1.5559, R: 0.0000)
Batch 18000/18276: Loss = 1.2052 (C: 1.2052, R: 0.0000)
Batch 18100/18276: Loss = 1.4711 (C: 1.4711, R: 0.0000)
Batch 18200/18276: Loss = 1.5693 (C: 1.5693, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.8273615837097168
  reconstruction_loss raw: 0.0
  total_loss raw: 1.8273615837097168
Epoch 8 completed in 74.33s
Train Loss: 1.4510 (C: 1.4510)
Val Loss: 1.4737 (C: 1.4737)
No improvement for 1 epochs

Epoch 9/50
------------------------------
Batch 0/18276: Loss = 1.5597 (C: 1.5597, R: 0.0000)
Batch 100/18276: Loss = 1.2905 (C: 1.2905, R: 0.0000)
Batch 200/18276: Loss = 1.3634 (C: 1.3634, R: 0.0000)
Batch 300/18276: Loss = 1.8370 (C: 1.8370, R: 0.0000)
Batch 400/18276: Loss = 1.5675 (C: 1.5675, R: 0.0000)
Batch 500/18276: Loss = 1.6978 (C: 1.6978, R: 0.0000)
Batch 600/18276: Loss = 1.4176 (C: 1.4176, R: 0.0000)
Batch 700/18276: Loss = 1.5686 (C: 1.5686, R: 0.0000)
Batch 800/18276: Loss = 1.1885 (C: 1.1885, R: 0.0000)
Batch 900/18276: Loss = 0.9055 (C: 0.9055, R: 0.0000)
Batch 1000/18276: Loss = 1.4075 (C: 1.4075, R: 0.0000)
Batch 1100/18276: Loss = 1.9027 (C: 1.9027, R: 0.0000)
Batch 1200/18276: Loss = 1.2137 (C: 1.2137, R: 0.0000)
Batch 1300/18276: Loss = 0.9778 (C: 0.9778, R: 0.0000)
Batch 1400/18276: Loss = 1.0545 (C: 1.0545, R: 0.0000)
Batch 1500/18276: Loss = 1.8755 (C: 1.8755, R: 0.0000)
Batch 1600/18276: Loss = 1.1623 (C: 1.1623, R: 0.0000)
Batch 1700/18276: Loss = 1.4012 (C: 1.4012, R: 0.0000)
Batch 1800/18276: Loss = 1.1467 (C: 1.1467, R: 0.0000)
Batch 1900/18276: Loss = 1.8933 (C: 1.8933, R: 0.0000)
Batch 2000/18276: Loss = 1.7060 (C: 1.7060, R: 0.0000)
Batch 2100/18276: Loss = 1.5761 (C: 1.5761, R: 0.0000)
Batch 2200/18276: Loss = 1.4080 (C: 1.4080, R: 0.0000)
Batch 2300/18276: Loss = 1.2343 (C: 1.2343, R: 0.0000)
Batch 2400/18276: Loss = 1.5566 (C: 1.5566, R: 0.0000)
Batch 2500/18276: Loss = 1.1087 (C: 1.1087, R: 0.0000)
Batch 2600/18276: Loss = 1.0382 (C: 1.0382, R: 0.0000)
Batch 2700/18276: Loss = 1.7027 (C: 1.7027, R: 0.0000)
Batch 2800/18276: Loss = 1.3978 (C: 1.3978, R: 0.0000)
Batch 2900/18276: Loss = 1.4224 (C: 1.4224, R: 0.0000)
Batch 3000/18276: Loss = 1.9180 (C: 1.9180, R: 0.0000)
Batch 3100/18276: Loss = 1.4240 (C: 1.4240, R: 0.0000)
Batch 3200/18276: Loss = 1.3646 (C: 1.3646, R: 0.0000)
Batch 3300/18276: Loss = 1.6521 (C: 1.6521, R: 0.0000)
Batch 3400/18276: Loss = 1.2227 (C: 1.2227, R: 0.0000)
Batch 3500/18276: Loss = 1.2117 (C: 1.2117, R: 0.0000)
Batch 3600/18276: Loss = 1.5537 (C: 1.5537, R: 0.0000)
Batch 3700/18276: Loss = 1.0535 (C: 1.0535, R: 0.0000)
Batch 3800/18276: Loss = 1.7319 (C: 1.7319, R: 0.0000)
Batch 3900/18276: Loss = 1.1550 (C: 1.1550, R: 0.0000)
Batch 4000/18276: Loss = 1.5130 (C: 1.5130, R: 0.0000)
Batch 4100/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 4200/18276: Loss = 1.6841 (C: 1.6841, R: 0.0000)
Batch 4300/18276: Loss = 1.5688 (C: 1.5688, R: 0.0000)
Batch 4400/18276: Loss = 1.4877 (C: 1.4877, R: 0.0000)
Batch 4500/18276: Loss = 1.6855 (C: 1.6855, R: 0.0000)
Batch 4600/18276: Loss = 1.8074 (C: 1.8074, R: 0.0000)
Batch 4700/18276: Loss = 1.3664 (C: 1.3664, R: 0.0000)
Batch 4800/18276: Loss = 1.4161 (C: 1.4161, R: 0.0000)
Batch 4900/18276: Loss = 1.5734 (C: 1.5734, R: 0.0000)
Batch 5000/18276: Loss = 1.1475 (C: 1.1475, R: 0.0000)
Batch 5100/18276: Loss = 1.5594 (C: 1.5594, R: 0.0000)
Batch 5200/18276: Loss = 1.1518 (C: 1.1518, R: 0.0000)
Batch 5300/18276: Loss = 1.8368 (C: 1.8368, R: 0.0000)
Batch 5400/18276: Loss = 1.2050 (C: 1.2050, R: 0.0000)
Batch 5500/18276: Loss = 1.0603 (C: 1.0603, R: 0.0000)
Batch 5600/18276: Loss = 1.8047 (C: 1.8047, R: 0.0000)
Batch 5700/18276: Loss = 1.0347 (C: 1.0347, R: 0.0000)
Batch 5800/18276: Loss = 1.5356 (C: 1.5356, R: 0.0000)
Batch 5900/18276: Loss = 1.2772 (C: 1.2772, R: 0.0000)
Batch 6000/18276: Loss = 1.3158 (C: 1.3158, R: 0.0000)
Batch 6100/18276: Loss = 1.8931 (C: 1.8931, R: 0.0000)
Batch 6200/18276: Loss = 1.8396 (C: 1.8396, R: 0.0000)
Batch 6300/18276: Loss = 1.3755 (C: 1.3755, R: 0.0000)
Batch 6400/18276: Loss = 1.4093 (C: 1.4093, R: 0.0000)
Batch 6500/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 6600/18276: Loss = 1.9238 (C: 1.9238, R: 0.0000)
Batch 6700/18276: Loss = 1.3122 (C: 1.3122, R: 0.0000)
Batch 6800/18276: Loss = 1.2420 (C: 1.2420, R: 0.0000)
Batch 6900/18276: Loss = 1.2090 (C: 1.2090, R: 0.0000)
Batch 7000/18276: Loss = 1.2952 (C: 1.2952, R: 0.0000)
Batch 7100/18276: Loss = 1.4132 (C: 1.4132, R: 0.0000)
Batch 7200/18276: Loss = 1.0230 (C: 1.0230, R: 0.0000)
Batch 7300/18276: Loss = 1.4172 (C: 1.4172, R: 0.0000)
Batch 7400/18276: Loss = 1.5949 (C: 1.5949, R: 0.0000)
Batch 7500/18276: Loss = 1.7194 (C: 1.7194, R: 0.0000)
Batch 7600/18276: Loss = 1.7053 (C: 1.7053, R: 0.0000)
Batch 7700/18276: Loss = 1.7097 (C: 1.7097, R: 0.0000)
Batch 7800/18276: Loss = 1.2371 (C: 1.2371, R: 0.0000)
Batch 7900/18276: Loss = 1.2342 (C: 1.2342, R: 0.0000)
Batch 8000/18276: Loss = 1.8111 (C: 1.8111, R: 0.0000)
Batch 8100/18276: Loss = 1.0375 (C: 1.0375, R: 0.0000)
Batch 8200/18276: Loss = 1.2159 (C: 1.2159, R: 0.0000)
Batch 8300/18276: Loss = 1.4183 (C: 1.4183, R: 0.0000)
Batch 8400/18276: Loss = 1.6644 (C: 1.6644, R: 0.0000)
Batch 8500/18276: Loss = 1.4093 (C: 1.4093, R: 0.0000)
Batch 8600/18276: Loss = 1.4095 (C: 1.4095, R: 0.0000)
Batch 8700/18276: Loss = 1.8018 (C: 1.8018, R: 0.0000)
Batch 8800/18276: Loss = 1.1874 (C: 1.1874, R: 0.0000)
Batch 8900/18276: Loss = 1.7476 (C: 1.7476, R: 0.0000)
Batch 9000/18276: Loss = 1.3335 (C: 1.3335, R: 0.0000)
Batch 9100/18276: Loss = 1.1987 (C: 1.1987, R: 0.0000)
Batch 9200/18276: Loss = 1.4218 (C: 1.4218, R: 0.0000)
Batch 9300/18276: Loss = 1.9787 (C: 1.9787, R: 0.0000)
Batch 9400/18276: Loss = 1.8311 (C: 1.8311, R: 0.0000)
Batch 9500/18276: Loss = 1.4076 (C: 1.4076, R: 0.0000)
Batch 9600/18276: Loss = 1.1491 (C: 1.1491, R: 0.0000)
Batch 9700/18276: Loss = 1.7200 (C: 1.7200, R: 0.0000)
Batch 9800/18276: Loss = 1.2645 (C: 1.2645, R: 0.0000)
Batch 9900/18276: Loss = 1.6829 (C: 1.6829, R: 0.0000)
Batch 10000/18276: Loss = 1.4093 (C: 1.4093, R: 0.0000)
Batch 10100/18276: Loss = 1.6696 (C: 1.6696, R: 0.0000)
Batch 10200/18276: Loss = 1.2353 (C: 1.2353, R: 0.0000)
Batch 10300/18276: Loss = 1.4086 (C: 1.4086, R: 0.0000)
Batch 10400/18276: Loss = 1.5526 (C: 1.5526, R: 0.0000)
Batch 10500/18276: Loss = 1.5963 (C: 1.5963, R: 0.0000)
Batch 10600/18276: Loss = 1.2094 (C: 1.2094, R: 0.0000)
Batch 10700/18276: Loss = 1.5645 (C: 1.5645, R: 0.0000)
Batch 10800/18276: Loss = 1.2325 (C: 1.2325, R: 0.0000)
Batch 10900/18276: Loss = 1.6483 (C: 1.6483, R: 0.0000)
Batch 11000/18276: Loss = 1.0249 (C: 1.0249, R: 0.0000)
Batch 11100/18276: Loss = 1.2103 (C: 1.2103, R: 0.0000)
Batch 11200/18276: Loss = 1.2321 (C: 1.2321, R: 0.0000)
Batch 11300/18276: Loss = 1.4242 (C: 1.4242, R: 0.0000)
Batch 11400/18276: Loss = 1.7058 (C: 1.7058, R: 0.0000)
Batch 11500/18276: Loss = 1.7091 (C: 1.7091, R: 0.0000)
Batch 11600/18276: Loss = 1.7062 (C: 1.7062, R: 0.0000)
Batch 11700/18276: Loss = 1.4876 (C: 1.4876, R: 0.0000)
Batch 11800/18276: Loss = 1.4153 (C: 1.4153, R: 0.0000)
Batch 11900/18276: Loss = 1.3648 (C: 1.3648, R: 0.0000)
Batch 12000/18276: Loss = 1.2363 (C: 1.2363, R: 0.0000)
Batch 12100/18276: Loss = 1.5713 (C: 1.5713, R: 0.0000)
Batch 12200/18276: Loss = 1.5683 (C: 1.5683, R: 0.0000)
Batch 12300/18276: Loss = 1.4962 (C: 1.4962, R: 0.0000)
Batch 12400/18276: Loss = 1.2900 (C: 1.2900, R: 0.0000)
Batch 12500/18276: Loss = 1.4014 (C: 1.4014, R: 0.0000)
Batch 12600/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 12700/18276: Loss = 1.7126 (C: 1.7126, R: 0.0000)
Batch 12800/18276: Loss = 1.1643 (C: 1.1643, R: 0.0000)
Batch 12900/18276: Loss = 1.5792 (C: 1.5792, R: 0.0000)
Batch 13000/18276: Loss = 1.5491 (C: 1.5491, R: 0.0000)
Batch 13100/18276: Loss = 1.5472 (C: 1.5472, R: 0.0000)
Batch 13200/18276: Loss = 1.7120 (C: 1.7120, R: 0.0000)
Batch 13300/18276: Loss = 1.4097 (C: 1.4097, R: 0.0000)
Batch 13400/18276: Loss = 1.6647 (C: 1.6647, R: 0.0000)
Batch 13500/18276: Loss = 1.4418 (C: 1.4418, R: 0.0000)
Batch 13600/18276: Loss = 1.4225 (C: 1.4225, R: 0.0000)
Batch 13700/18276: Loss = 1.4202 (C: 1.4202, R: 0.0000)
Batch 13800/18276: Loss = 0.9780 (C: 0.9780, R: 0.0000)
Batch 13900/18276: Loss = 1.6176 (C: 1.6176, R: 0.0000)
Batch 14000/18276: Loss = 1.9796 (C: 1.9796, R: 0.0000)
Batch 14100/18276: Loss = 1.7758 (C: 1.7758, R: 0.0000)
Batch 14200/18276: Loss = 1.4016 (C: 1.4016, R: 0.0000)
Batch 14300/18276: Loss = 1.5969 (C: 1.5969, R: 0.0000)
Batch 14400/18276: Loss = 1.4023 (C: 1.4023, R: 0.0000)
Batch 14500/18276: Loss = 1.5485 (C: 1.5485, R: 0.0000)
Batch 14600/18276: Loss = 1.4004 (C: 1.4004, R: 0.0000)
Batch 14700/18276: Loss = 1.4041 (C: 1.4041, R: 0.0000)
Batch 14800/18276: Loss = 1.5538 (C: 1.5538, R: 0.0000)
Batch 14900/18276: Loss = 1.1436 (C: 1.1436, R: 0.0000)
Batch 15000/18276: Loss = 1.1548 (C: 1.1548, R: 0.0000)
Batch 15100/18276: Loss = 1.4008 (C: 1.4008, R: 0.0000)
Batch 15200/18276: Loss = 1.5649 (C: 1.5649, R: 0.0000)
Batch 15300/18276: Loss = 1.4083 (C: 1.4083, R: 0.0000)
Batch 15400/18276: Loss = 1.2365 (C: 1.2365, R: 0.0000)
Batch 15500/18276: Loss = 1.7035 (C: 1.7035, R: 0.0000)
Batch 15600/18276: Loss = 1.6989 (C: 1.6989, R: 0.0000)
Batch 15700/18276: Loss = 0.9783 (C: 0.9783, R: 0.0000)
Batch 15800/18276: Loss = 1.5732 (C: 1.5732, R: 0.0000)
Batch 15900/18276: Loss = 1.2054 (C: 1.2054, R: 0.0000)
Batch 16000/18276: Loss = 1.8639 (C: 1.8639, R: 0.0000)
Batch 16100/18276: Loss = 0.9783 (C: 0.9783, R: 0.0000)
Batch 16200/18276: Loss = 1.4421 (C: 1.4421, R: 0.0000)
Batch 16300/18276: Loss = 1.8276 (C: 1.8276, R: 0.0000)
Batch 16400/18276: Loss = 1.8063 (C: 1.8063, R: 0.0000)
Batch 16500/18276: Loss = 1.3543 (C: 1.3543, R: 0.0000)
Batch 16600/18276: Loss = 1.2772 (C: 1.2772, R: 0.0000)
Batch 16700/18276: Loss = 1.9373 (C: 1.9373, R: 0.0000)
Batch 16800/18276: Loss = 1.4029 (C: 1.4029, R: 0.0000)
Batch 16900/18276: Loss = 1.2905 (C: 1.2905, R: 0.0000)
Batch 17000/18276: Loss = 1.5794 (C: 1.5794, R: 0.0000)
Batch 17100/18276: Loss = 1.7067 (C: 1.7067, R: 0.0000)
Batch 17200/18276: Loss = 1.4918 (C: 1.4918, R: 0.0000)
Batch 17300/18276: Loss = 1.6606 (C: 1.6606, R: 0.0000)
Batch 17400/18276: Loss = 0.9046 (C: 0.9046, R: 0.0000)
Batch 17500/18276: Loss = 1.2766 (C: 1.2766, R: 0.0000)
Batch 17600/18276: Loss = 1.5738 (C: 1.5738, R: 0.0000)
Batch 17700/18276: Loss = 1.8580 (C: 1.8580, R: 0.0000)
Batch 17800/18276: Loss = 1.4087 (C: 1.4087, R: 0.0000)
Batch 17900/18276: Loss = 1.5810 (C: 1.5810, R: 0.0000)
Batch 18000/18276: Loss = 1.5809 (C: 1.5809, R: 0.0000)
Batch 18100/18276: Loss = 1.6362 (C: 1.6362, R: 0.0000)
Batch 18200/18276: Loss = 0.9793 (C: 0.9793, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.5523145198822021
  reconstruction_loss raw: 0.0
  total_loss raw: 1.5523145198822021
Epoch 9 completed in 73.98s
Train Loss: 1.4486 (C: 1.4486)
Val Loss: 1.4243 (C: 1.4243)
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/best_model.pt
New best model saved (Val Loss: 1.4243)

Epoch 10/50
------------------------------
Batch 0/18276: Loss = 1.4035 (C: 1.4035, R: 0.0000)
Batch 100/18276: Loss = 1.7202 (C: 1.7202, R: 0.0000)
Batch 200/18276: Loss = 1.6956 (C: 1.6956, R: 0.0000)
Batch 300/18276: Loss = 1.7072 (C: 1.7072, R: 0.0000)
Batch 400/18276: Loss = 1.2374 (C: 1.2374, R: 0.0000)
Batch 500/18276: Loss = 1.8104 (C: 1.8104, R: 0.0000)
Batch 600/18276: Loss = 1.3654 (C: 1.3654, R: 0.0000)
Batch 700/18276: Loss = 1.9989 (C: 1.9989, R: 0.0000)
Batch 800/18276: Loss = 0.9044 (C: 0.9044, R: 0.0000)
Batch 900/18276: Loss = 1.7208 (C: 1.7208, R: 0.0000)
Batch 1000/18276: Loss = 1.3535 (C: 1.3535, R: 0.0000)
Batch 1100/18276: Loss = 1.0351 (C: 1.0351, R: 0.0000)
Batch 1200/18276: Loss = 1.0225 (C: 1.0225, R: 0.0000)
Batch 1300/18276: Loss = 1.5484 (C: 1.5484, R: 0.0000)
Batch 1400/18276: Loss = 1.5711 (C: 1.5711, R: 0.0000)
Batch 1500/18276: Loss = 1.6864 (C: 1.6864, R: 0.0000)
Batch 1600/18276: Loss = 0.9043 (C: 0.9043, R: 0.0000)
Batch 1700/18276: Loss = 1.8267 (C: 1.8267, R: 0.0000)
Batch 1800/18276: Loss = 1.6360 (C: 1.6360, R: 0.0000)
Batch 1900/18276: Loss = 0.9788 (C: 0.9788, R: 0.0000)
Batch 2000/18276: Loss = 1.6652 (C: 1.6652, R: 0.0000)
Batch 2100/18276: Loss = 1.3576 (C: 1.3576, R: 0.0000)
Batch 2200/18276: Loss = 1.5609 (C: 1.5609, R: 0.0000)
Batch 2300/18276: Loss = 1.5536 (C: 1.5536, R: 0.0000)
Batch 2400/18276: Loss = 1.4204 (C: 1.4204, R: 0.0000)
Batch 2500/18276: Loss = 1.5744 (C: 1.5744, R: 0.0000)
Batch 2600/18276: Loss = 1.4485 (C: 1.4485, R: 0.0000)
Batch 2700/18276: Loss = 1.5484 (C: 1.5484, R: 0.0000)
Batch 2800/18276: Loss = 1.6837 (C: 1.6837, R: 0.0000)
Batch 2900/18276: Loss = 1.2094 (C: 1.2094, R: 0.0000)
Batch 3000/18276: Loss = 1.2787 (C: 1.2787, R: 0.0000)
Batch 3100/18276: Loss = 1.5477 (C: 1.5477, R: 0.0000)
Batch 3200/18276: Loss = 1.5681 (C: 1.5681, R: 0.0000)
Batch 3300/18276: Loss = 2.0411 (C: 2.0411, R: 0.0000)
Batch 3400/18276: Loss = 1.2855 (C: 1.2855, R: 0.0000)
Batch 3500/18276: Loss = 1.5699 (C: 1.5699, R: 0.0000)
Batch 3600/18276: Loss = 1.5371 (C: 1.5371, R: 0.0000)
Batch 3700/18276: Loss = 1.7101 (C: 1.7101, R: 0.0000)
Batch 3800/18276: Loss = 1.4062 (C: 1.4062, R: 0.0000)
Batch 3900/18276: Loss = 1.2039 (C: 1.2039, R: 0.0000)
Batch 4000/18276: Loss = 0.9780 (C: 0.9780, R: 0.0000)
Batch 4100/18276: Loss = 1.7081 (C: 1.7081, R: 0.0000)
Batch 4200/18276: Loss = 1.7609 (C: 1.7609, R: 0.0000)
Batch 4300/18276: Loss = 1.3648 (C: 1.3648, R: 0.0000)
Batch 4400/18276: Loss = 1.5710 (C: 1.5710, R: 0.0000)
Batch 4500/18276: Loss = 1.1757 (C: 1.1757, R: 0.0000)
Batch 4600/18276: Loss = 1.2818 (C: 1.2818, R: 0.0000)
Batch 4700/18276: Loss = 1.3545 (C: 1.3545, R: 0.0000)
Batch 4800/18276: Loss = 1.4018 (C: 1.4018, R: 0.0000)
Batch 4900/18276: Loss = 1.5809 (C: 1.5809, R: 0.0000)
Batch 5000/18276: Loss = 1.1510 (C: 1.1510, R: 0.0000)
Batch 5100/18276: Loss = 1.4156 (C: 1.4156, R: 0.0000)
Batch 5200/18276: Loss = 1.8103 (C: 1.8103, R: 0.0000)
Batch 5300/18276: Loss = 1.5734 (C: 1.5734, R: 0.0000)
Batch 5400/18276: Loss = 1.5699 (C: 1.5699, R: 0.0000)
Batch 5500/18276: Loss = 1.4267 (C: 1.4267, R: 0.0000)
Batch 5600/18276: Loss = 1.5667 (C: 1.5667, R: 0.0000)
Batch 5700/18276: Loss = 1.8836 (C: 1.8836, R: 0.0000)
Batch 5800/18276: Loss = 1.2091 (C: 1.2091, R: 0.0000)
Batch 5900/18276: Loss = 1.5353 (C: 1.5353, R: 0.0000)
Batch 6000/18276: Loss = 1.1644 (C: 1.1644, R: 0.0000)
Batch 6100/18276: Loss = 1.9396 (C: 1.9396, R: 0.0000)
Batch 6200/18276: Loss = 1.3645 (C: 1.3645, R: 0.0000)
Batch 6300/18276: Loss = 1.3543 (C: 1.3543, R: 0.0000)
Batch 6400/18276: Loss = 1.3660 (C: 1.3660, R: 0.0000)
Batch 6500/18276: Loss = 1.4108 (C: 1.4108, R: 0.0000)
Batch 6600/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 6700/18276: Loss = 1.4194 (C: 1.4194, R: 0.0000)
Batch 6800/18276: Loss = 1.2092 (C: 1.2092, R: 0.0000)
Batch 6900/18276: Loss = 1.5351 (C: 1.5351, R: 0.0000)
Batch 7000/18276: Loss = 1.7102 (C: 1.7102, R: 0.0000)
Batch 7100/18276: Loss = 1.2044 (C: 1.2044, R: 0.0000)
Batch 7200/18276: Loss = 1.5336 (C: 1.5336, R: 0.0000)
Batch 7300/18276: Loss = 1.5686 (C: 1.5686, R: 0.0000)
Batch 7400/18276: Loss = 1.4013 (C: 1.4013, R: 0.0000)
Batch 7500/18276: Loss = 1.6651 (C: 1.6651, R: 0.0000)
Batch 7600/18276: Loss = 1.7921 (C: 1.7921, R: 0.0000)
Batch 7700/18276: Loss = 1.0444 (C: 1.0444, R: 0.0000)
Batch 7800/18276: Loss = 1.2368 (C: 1.2368, R: 0.0000)
Batch 7900/18276: Loss = 1.4188 (C: 1.4188, R: 0.0000)
Batch 8000/18276: Loss = 1.2778 (C: 1.2778, R: 0.0000)
Batch 8100/18276: Loss = 1.4096 (C: 1.4096, R: 0.0000)
Batch 8200/18276: Loss = 1.7241 (C: 1.7241, R: 0.0000)
Batch 8300/18276: Loss = 1.7080 (C: 1.7080, R: 0.0000)
Batch 8400/18276: Loss = 1.2786 (C: 1.2786, R: 0.0000)
Batch 8500/18276: Loss = 1.4243 (C: 1.4243, R: 0.0000)
Batch 8600/18276: Loss = 1.7040 (C: 1.7040, R: 0.0000)
Batch 8700/18276: Loss = 1.4196 (C: 1.4196, R: 0.0000)
Batch 8800/18276: Loss = 1.5678 (C: 1.5678, R: 0.0000)
Batch 8900/18276: Loss = 1.5991 (C: 1.5991, R: 0.0000)
Batch 9000/18276: Loss = 1.4227 (C: 1.4227, R: 0.0000)
Batch 9100/18276: Loss = 1.1648 (C: 1.1648, R: 0.0000)
Batch 9200/18276: Loss = 1.7607 (C: 1.7607, R: 0.0000)
Batch 9300/18276: Loss = 1.7592 (C: 1.7592, R: 0.0000)
Batch 9400/18276: Loss = 1.4240 (C: 1.4240, R: 0.0000)
Batch 9500/18276: Loss = 1.7188 (C: 1.7188, R: 0.0000)
Batch 9600/18276: Loss = 1.6686 (C: 1.6686, R: 0.0000)
Batch 9700/18276: Loss = 1.9172 (C: 1.9172, R: 0.0000)
Batch 9800/18276: Loss = 1.8424 (C: 1.8424, R: 0.0000)
Batch 9900/18276: Loss = 1.4079 (C: 1.4079, R: 0.0000)
Batch 10000/18276: Loss = 1.4102 (C: 1.4102, R: 0.0000)
Batch 10100/18276: Loss = 1.0228 (C: 1.0228, R: 0.0000)
Batch 10200/18276: Loss = 1.4109 (C: 1.4109, R: 0.0000)
Batch 10300/18276: Loss = 1.6679 (C: 1.6679, R: 0.0000)
Batch 10400/18276: Loss = 1.7231 (C: 1.7231, R: 0.0000)
Batch 10500/18276: Loss = 1.2067 (C: 1.2067, R: 0.0000)
Batch 10600/18276: Loss = 1.1486 (C: 1.1486, R: 0.0000)
Batch 10700/18276: Loss = 1.4288 (C: 1.4288, R: 0.0000)
Batch 10800/18276: Loss = 1.5801 (C: 1.5801, R: 0.0000)
Batch 10900/18276: Loss = 1.2391 (C: 1.2391, R: 0.0000)
Batch 11000/18276: Loss = 1.8580 (C: 1.8580, R: 0.0000)
Batch 11100/18276: Loss = 1.4128 (C: 1.4128, R: 0.0000)
Batch 11200/18276: Loss = 1.2976 (C: 1.2976, R: 0.0000)
Batch 11300/18276: Loss = 1.6274 (C: 1.6274, R: 0.0000)
Batch 11400/18276: Loss = 1.6629 (C: 1.6629, R: 0.0000)
Batch 11500/18276: Loss = 1.5544 (C: 1.5544, R: 0.0000)
Batch 11600/18276: Loss = 1.0253 (C: 1.0253, R: 0.0000)
Batch 11700/18276: Loss = 1.4080 (C: 1.4080, R: 0.0000)
Batch 11800/18276: Loss = 0.9674 (C: 0.9674, R: 0.0000)
Batch 11900/18276: Loss = 1.4074 (C: 1.4074, R: 0.0000)
Batch 12000/18276: Loss = 1.2128 (C: 1.2128, R: 0.0000)
Batch 12100/18276: Loss = 1.2965 (C: 1.2965, R: 0.0000)
Batch 12200/18276: Loss = 1.2377 (C: 1.2377, R: 0.0000)
Batch 12300/18276: Loss = 1.5710 (C: 1.5710, R: 0.0000)
Batch 12400/18276: Loss = 1.1720 (C: 1.1720, R: 0.0000)
Batch 12500/18276: Loss = 1.3989 (C: 1.3989, R: 0.0000)
Batch 12600/18276: Loss = 1.8135 (C: 1.8135, R: 0.0000)
Batch 12700/18276: Loss = 1.2441 (C: 1.2441, R: 0.0000)
Batch 12800/18276: Loss = 1.5584 (C: 1.5584, R: 0.0000)
Batch 12900/18276: Loss = 1.0887 (C: 1.0887, R: 0.0000)
Batch 13000/18276: Loss = 1.0562 (C: 1.0562, R: 0.0000)
Batch 13100/18276: Loss = 1.5786 (C: 1.5786, R: 0.0000)
Batch 13200/18276: Loss = 1.5689 (C: 1.5689, R: 0.0000)
Batch 13300/18276: Loss = 1.3780 (C: 1.3780, R: 0.0000)
Batch 13400/18276: Loss = 1.5310 (C: 1.5310, R: 0.0000)
Batch 13500/18276: Loss = 1.5316 (C: 1.5316, R: 0.0000)
Batch 13600/18276: Loss = 0.9054 (C: 0.9054, R: 0.0000)
Batch 13700/18276: Loss = 1.3553 (C: 1.3553, R: 0.0000)
Batch 13800/18276: Loss = 1.4873 (C: 1.4873, R: 0.0000)
Batch 13900/18276: Loss = 1.0372 (C: 1.0372, R: 0.0000)
Batch 14000/18276: Loss = 1.7564 (C: 1.7564, R: 0.0000)
Batch 14100/18276: Loss = 1.4877 (C: 1.4877, R: 0.0000)
Batch 14200/18276: Loss = 1.1568 (C: 1.1568, R: 0.0000)
Batch 14300/18276: Loss = 1.1854 (C: 1.1854, R: 0.0000)
Batch 14400/18276: Loss = 1.5792 (C: 1.5792, R: 0.0000)
Batch 14500/18276: Loss = 1.4129 (C: 1.4129, R: 0.0000)
Batch 14600/18276: Loss = 1.3692 (C: 1.3692, R: 0.0000)
Batch 14700/18276: Loss = 1.6686 (C: 1.6686, R: 0.0000)
Batch 14800/18276: Loss = 1.5484 (C: 1.5484, R: 0.0000)
Batch 14900/18276: Loss = 1.4138 (C: 1.4138, R: 0.0000)
Batch 15000/18276: Loss = 1.5795 (C: 1.5795, R: 0.0000)
Batch 15100/18276: Loss = 1.4032 (C: 1.4032, R: 0.0000)
Batch 15200/18276: Loss = 1.3651 (C: 1.3651, R: 0.0000)
Batch 15300/18276: Loss = 1.4018 (C: 1.4018, R: 0.0000)
Batch 15400/18276: Loss = 1.6650 (C: 1.6650, R: 0.0000)
Batch 15500/18276: Loss = 1.1439 (C: 1.1439, R: 0.0000)
Batch 15600/18276: Loss = 1.0672 (C: 1.0672, R: 0.0000)
Batch 15700/18276: Loss = 1.6356 (C: 1.6356, R: 0.0000)
Batch 15800/18276: Loss = 1.5351 (C: 1.5351, R: 0.0000)
Batch 15900/18276: Loss = 1.3947 (C: 1.3947, R: 0.0000)
Batch 16000/18276: Loss = 1.2903 (C: 1.2903, R: 0.0000)
Batch 16100/18276: Loss = 1.4236 (C: 1.4236, R: 0.0000)
Batch 16200/18276: Loss = 1.4879 (C: 1.4879, R: 0.0000)
Batch 16300/18276: Loss = 1.2040 (C: 1.2040, R: 0.0000)
Batch 16400/18276: Loss = 1.4093 (C: 1.4093, R: 0.0000)
Batch 16500/18276: Loss = 1.6654 (C: 1.6654, R: 0.0000)
Batch 16600/18276: Loss = 1.6750 (C: 1.6750, R: 0.0000)
Batch 16700/18276: Loss = 1.5351 (C: 1.5351, R: 0.0000)
Batch 16800/18276: Loss = 1.4714 (C: 1.4714, R: 0.0000)
Batch 16900/18276: Loss = 1.8302 (C: 1.8302, R: 0.0000)
Batch 17000/18276: Loss = 1.5349 (C: 1.5349, R: 0.0000)
Batch 17100/18276: Loss = 1.4890 (C: 1.4890, R: 0.0000)
Batch 17200/18276: Loss = 1.8608 (C: 1.8608, R: 0.0000)
Batch 17300/18276: Loss = 0.9799 (C: 0.9799, R: 0.0000)
Batch 17400/18276: Loss = 1.0922 (C: 1.0922, R: 0.0000)
Batch 17500/18276: Loss = 1.4009 (C: 1.4009, R: 0.0000)
Batch 17600/18276: Loss = 1.2780 (C: 1.2780, R: 0.0000)
Batch 17700/18276: Loss = 1.1517 (C: 1.1517, R: 0.0000)
Batch 17800/18276: Loss = 1.5793 (C: 1.5793, R: 0.0000)
Batch 17900/18276: Loss = 0.9086 (C: 0.9086, R: 0.0000)
Batch 18000/18276: Loss = 1.1902 (C: 1.1902, R: 0.0000)
Batch 18100/18276: Loss = 1.2772 (C: 1.2772, R: 0.0000)
Batch 18200/18276: Loss = 1.7057 (C: 1.7057, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 0.9054551124572754
  reconstruction_loss raw: 0.0
  total_loss raw: 0.9054551124572754
Epoch 10 completed in 74.39s
Train Loss: 1.4508 (C: 1.4508)
Val Loss: 1.4351 (C: 1.4351)
No improvement for 1 epochs
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/checkpoint_epoch_10.pt

Epoch 11/50
------------------------------
Batch 0/18276: Loss = 1.0292 (C: 1.0292, R: 0.0000)
Batch 100/18276: Loss = 1.2049 (C: 1.2049, R: 0.0000)
Batch 200/18276: Loss = 1.6621 (C: 1.6621, R: 0.0000)
Batch 300/18276: Loss = 1.5676 (C: 1.5676, R: 0.0000)
Batch 400/18276: Loss = 1.7919 (C: 1.7919, R: 0.0000)
Batch 500/18276: Loss = 1.7239 (C: 1.7239, R: 0.0000)
Batch 600/18276: Loss = 1.7114 (C: 1.7114, R: 0.0000)
Batch 700/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 800/18276: Loss = 1.2399 (C: 1.2399, R: 0.0000)
Batch 900/18276: Loss = 1.5530 (C: 1.5530, R: 0.0000)
Batch 1000/18276: Loss = 0.9851 (C: 0.9851, R: 0.0000)
Batch 1100/18276: Loss = 1.7068 (C: 1.7068, R: 0.0000)
Batch 1200/18276: Loss = 1.6857 (C: 1.6857, R: 0.0000)
Batch 1300/18276: Loss = 1.4939 (C: 1.4939, R: 0.0000)
Batch 1400/18276: Loss = 1.1954 (C: 1.1954, R: 0.0000)
Batch 1500/18276: Loss = 1.3675 (C: 1.3675, R: 0.0000)
Batch 1600/18276: Loss = 1.6861 (C: 1.6861, R: 0.0000)
Batch 1700/18276: Loss = 1.2377 (C: 1.2377, R: 0.0000)
Batch 1800/18276: Loss = 1.2335 (C: 1.2335, R: 0.0000)
Batch 1900/18276: Loss = 1.5832 (C: 1.5832, R: 0.0000)
Batch 2000/18276: Loss = 1.1461 (C: 1.1461, R: 0.0000)
Batch 2100/18276: Loss = 1.4918 (C: 1.4918, R: 0.0000)
Batch 2200/18276: Loss = 1.2952 (C: 1.2952, R: 0.0000)
Batch 2300/18276: Loss = 1.5776 (C: 1.5776, R: 0.0000)
Batch 2400/18276: Loss = 1.6145 (C: 1.6145, R: 0.0000)
Batch 2500/18276: Loss = 1.4196 (C: 1.4196, R: 0.0000)
Batch 2600/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 2700/18276: Loss = 1.4194 (C: 1.4194, R: 0.0000)
Batch 2800/18276: Loss = 1.7190 (C: 1.7190, R: 0.0000)
Batch 2900/18276: Loss = 1.0909 (C: 1.0909, R: 0.0000)
Batch 3000/18276: Loss = 1.5098 (C: 1.5098, R: 0.0000)
Batch 3100/18276: Loss = 1.6978 (C: 1.6978, R: 0.0000)
Batch 3200/18276: Loss = 1.2047 (C: 1.2047, R: 0.0000)
Batch 3300/18276: Loss = 0.9781 (C: 0.9781, R: 0.0000)
Batch 3400/18276: Loss = 1.4010 (C: 1.4010, R: 0.0000)
Batch 3500/18276: Loss = 1.7059 (C: 1.7059, R: 0.0000)
Batch 3600/18276: Loss = 1.0744 (C: 1.0744, R: 0.0000)
Batch 3700/18276: Loss = 1.2352 (C: 1.2352, R: 0.0000)
Batch 3800/18276: Loss = 1.5526 (C: 1.5526, R: 0.0000)
Batch 3900/18276: Loss = 1.2375 (C: 1.2375, R: 0.0000)
Batch 4000/18276: Loss = 1.1437 (C: 1.1437, R: 0.0000)
Batch 4100/18276: Loss = 1.5349 (C: 1.5349, R: 0.0000)
Batch 4200/18276: Loss = 1.9348 (C: 1.9348, R: 0.0000)
Batch 4300/18276: Loss = 1.2913 (C: 1.2913, R: 0.0000)
Batch 4400/18276: Loss = 1.2069 (C: 1.2069, R: 0.0000)
Batch 4500/18276: Loss = 1.3545 (C: 1.3545, R: 0.0000)
Batch 4600/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 4700/18276: Loss = 1.7289 (C: 1.7289, R: 0.0000)
Batch 4800/18276: Loss = 0.8010 (C: 0.8010, R: 0.0000)
Batch 4900/18276: Loss = 1.2569 (C: 1.2569, R: 0.0000)
Batch 5000/18276: Loss = 1.5834 (C: 1.5834, R: 0.0000)
Batch 5100/18276: Loss = 1.0105 (C: 1.0105, R: 0.0000)
Batch 5200/18276: Loss = 1.5349 (C: 1.5349, R: 0.0000)
Batch 5300/18276: Loss = 1.3551 (C: 1.3551, R: 0.0000)
Batch 5400/18276: Loss = 1.3716 (C: 1.3716, R: 0.0000)
Batch 5500/18276: Loss = 1.5788 (C: 1.5788, R: 0.0000)
Batch 5600/18276: Loss = 1.5348 (C: 1.5348, R: 0.0000)
Batch 5700/18276: Loss = 1.2771 (C: 1.2771, R: 0.0000)
Batch 5800/18276: Loss = 1.4736 (C: 1.4736, R: 0.0000)
Batch 5900/18276: Loss = 1.7023 (C: 1.7023, R: 0.0000)
Batch 6000/18276: Loss = 1.2773 (C: 1.2773, R: 0.0000)
Batch 6100/18276: Loss = 1.6821 (C: 1.6821, R: 0.0000)
Batch 6200/18276: Loss = 1.6545 (C: 1.6545, R: 0.0000)
Batch 6300/18276: Loss = 1.0224 (C: 1.0224, R: 0.0000)
Batch 6400/18276: Loss = 1.8828 (C: 1.8828, R: 0.0000)
Batch 6500/18276: Loss = 1.4951 (C: 1.4951, R: 0.0000)
Batch 6600/18276: Loss = 1.2185 (C: 1.2185, R: 0.0000)
Batch 6700/18276: Loss = 1.6663 (C: 1.6663, R: 0.0000)
Batch 6800/18276: Loss = 1.4193 (C: 1.4193, R: 0.0000)
Batch 6900/18276: Loss = 1.4224 (C: 1.4224, R: 0.0000)
Batch 7000/18276: Loss = 1.0055 (C: 1.0055, R: 0.0000)
Batch 7100/18276: Loss = 1.7220 (C: 1.7220, R: 0.0000)
Batch 7200/18276: Loss = 1.5753 (C: 1.5753, R: 0.0000)
Batch 7300/18276: Loss = 1.4027 (C: 1.4027, R: 0.0000)
Batch 7400/18276: Loss = 1.2500 (C: 1.2500, R: 0.0000)
Batch 7500/18276: Loss = 1.5027 (C: 1.5027, R: 0.0000)
Batch 7600/18276: Loss = 1.4114 (C: 1.4114, R: 0.0000)
Batch 7700/18276: Loss = 1.4910 (C: 1.4910, R: 0.0000)
Batch 7800/18276: Loss = 1.2365 (C: 1.2365, R: 0.0000)
Batch 7900/18276: Loss = 1.5678 (C: 1.5678, R: 0.0000)
Batch 8000/18276: Loss = 1.8060 (C: 1.8060, R: 0.0000)
Batch 8100/18276: Loss = 1.4877 (C: 1.4877, R: 0.0000)
Batch 8200/18276: Loss = 1.5487 (C: 1.5487, R: 0.0000)
Batch 8300/18276: Loss = 1.7202 (C: 1.7202, R: 0.0000)
Batch 8400/18276: Loss = 1.3662 (C: 1.3662, R: 0.0000)
Batch 8500/18276: Loss = 1.5183 (C: 1.5183, R: 0.0000)
Batch 8600/18276: Loss = 1.4713 (C: 1.4713, R: 0.0000)
Batch 8700/18276: Loss = 1.2092 (C: 1.2092, R: 0.0000)
Batch 8800/18276: Loss = 1.0663 (C: 1.0663, R: 0.0000)
Batch 8900/18276: Loss = 1.4915 (C: 1.4915, R: 0.0000)
Batch 9000/18276: Loss = 1.5483 (C: 1.5483, R: 0.0000)
Batch 9100/18276: Loss = 1.0224 (C: 1.0224, R: 0.0000)
Batch 9200/18276: Loss = 1.7999 (C: 1.7999, R: 0.0000)
Batch 9300/18276: Loss = 1.3728 (C: 1.3728, R: 0.0000)
Batch 9400/18276: Loss = 1.0381 (C: 1.0381, R: 0.0000)
Batch 9500/18276: Loss = 1.6624 (C: 1.6624, R: 0.0000)
Batch 9600/18276: Loss = 1.3543 (C: 1.3543, R: 0.0000)
Batch 9700/18276: Loss = 1.3645 (C: 1.3645, R: 0.0000)
Batch 9800/18276: Loss = 1.5691 (C: 1.5691, R: 0.0000)
Batch 9900/18276: Loss = 1.1522 (C: 1.1522, R: 0.0000)
Batch 10000/18276: Loss = 1.8101 (C: 1.8101, R: 0.0000)
Batch 10100/18276: Loss = 1.4069 (C: 1.4069, R: 0.0000)
Batch 10200/18276: Loss = 1.1513 (C: 1.1513, R: 0.0000)
Batch 10300/18276: Loss = 1.3181 (C: 1.3181, R: 0.0000)
Batch 10400/18276: Loss = 1.6979 (C: 1.6979, R: 0.0000)
Batch 10500/18276: Loss = 1.6637 (C: 1.6637, R: 0.0000)
Batch 10600/18276: Loss = 1.5349 (C: 1.5349, R: 0.0000)
Batch 10700/18276: Loss = 1.1442 (C: 1.1442, R: 0.0000)
Batch 10800/18276: Loss = 1.2966 (C: 1.2966, R: 0.0000)
Batch 10900/18276: Loss = 0.9125 (C: 0.9125, R: 0.0000)
Batch 11000/18276: Loss = 1.3656 (C: 1.3656, R: 0.0000)
Batch 11100/18276: Loss = 1.5910 (C: 1.5910, R: 0.0000)
Batch 11200/18276: Loss = 1.4081 (C: 1.4081, R: 0.0000)
Batch 11300/18276: Loss = 1.2389 (C: 1.2389, R: 0.0000)
Batch 11400/18276: Loss = 1.4229 (C: 1.4229, R: 0.0000)
Batch 11500/18276: Loss = 1.5338 (C: 1.5338, R: 0.0000)
Batch 11600/18276: Loss = 1.4870 (C: 1.4870, R: 0.0000)
Batch 11700/18276: Loss = 1.5518 (C: 1.5518, R: 0.0000)
Batch 11800/18276: Loss = 1.4233 (C: 1.4233, R: 0.0000)
Batch 11900/18276: Loss = 1.5995 (C: 1.5995, R: 0.0000)
Batch 12000/18276: Loss = 1.6595 (C: 1.6595, R: 0.0000)
Batch 12100/18276: Loss = 1.5778 (C: 1.5778, R: 0.0000)
Batch 12200/18276: Loss = 1.4932 (C: 1.4932, R: 0.0000)
Batch 12300/18276: Loss = 1.4075 (C: 1.4075, R: 0.0000)
Batch 12400/18276: Loss = 1.1575 (C: 1.1575, R: 0.0000)
Batch 12500/18276: Loss = 1.7030 (C: 1.7030, R: 0.0000)
Batch 12600/18276: Loss = 1.3671 (C: 1.3671, R: 0.0000)
Batch 12700/18276: Loss = 1.5798 (C: 1.5798, R: 0.0000)
Batch 12800/18276: Loss = 1.5691 (C: 1.5691, R: 0.0000)
Batch 12900/18276: Loss = 1.6850 (C: 1.6850, R: 0.0000)
Batch 13000/18276: Loss = 1.0744 (C: 1.0744, R: 0.0000)
Batch 13100/18276: Loss = 1.2375 (C: 1.2375, R: 0.0000)
Batch 13200/18276: Loss = 1.3585 (C: 1.3585, R: 0.0000)
Batch 13300/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 13400/18276: Loss = 1.4710 (C: 1.4710, R: 0.0000)
Batch 13500/18276: Loss = 1.5476 (C: 1.5476, R: 0.0000)
Batch 13600/18276: Loss = 1.2347 (C: 1.2347, R: 0.0000)
Batch 13700/18276: Loss = 1.4879 (C: 1.4879, R: 0.0000)
Batch 13800/18276: Loss = 1.6527 (C: 1.6527, R: 0.0000)
Batch 13900/18276: Loss = 1.7925 (C: 1.7925, R: 0.0000)
Batch 14000/18276: Loss = 1.9188 (C: 1.9188, R: 0.0000)
Batch 14100/18276: Loss = 1.6922 (C: 1.6922, R: 0.0000)
Batch 14200/18276: Loss = 1.4715 (C: 1.4715, R: 0.0000)
Batch 14300/18276: Loss = 0.9808 (C: 0.9808, R: 0.0000)
Batch 14400/18276: Loss = 1.3779 (C: 1.3779, R: 0.0000)
Batch 14500/18276: Loss = 1.2064 (C: 1.2064, R: 0.0000)
Batch 14600/18276: Loss = 1.2049 (C: 1.2049, R: 0.0000)
Batch 14700/18276: Loss = 1.0300 (C: 1.0300, R: 0.0000)
Batch 14800/18276: Loss = 1.5713 (C: 1.5713, R: 0.0000)
Batch 14900/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 15000/18276: Loss = 1.3972 (C: 1.3972, R: 0.0000)
Batch 15100/18276: Loss = 1.0149 (C: 1.0149, R: 0.0000)
Batch 15200/18276: Loss = 1.5690 (C: 1.5690, R: 0.0000)
Batch 15300/18276: Loss = 1.5729 (C: 1.5729, R: 0.0000)
Batch 15400/18276: Loss = 1.6801 (C: 1.6801, R: 0.0000)
Batch 15500/18276: Loss = 1.5785 (C: 1.5785, R: 0.0000)
Batch 15600/18276: Loss = 1.5508 (C: 1.5508, R: 0.0000)
Batch 15700/18276: Loss = 1.4717 (C: 1.4717, R: 0.0000)
Batch 15800/18276: Loss = 1.6979 (C: 1.6979, R: 0.0000)
Batch 15900/18276: Loss = 1.2908 (C: 1.2908, R: 0.0000)
Batch 16000/18276: Loss = 1.5708 (C: 1.5708, R: 0.0000)
Batch 16100/18276: Loss = 1.8148 (C: 1.8148, R: 0.0000)
Batch 16200/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 16300/18276: Loss = 1.7098 (C: 1.7098, R: 0.0000)
Batch 16400/18276: Loss = 1.2372 (C: 1.2372, R: 0.0000)
Batch 16500/18276: Loss = 1.2097 (C: 1.2097, R: 0.0000)
Batch 16600/18276: Loss = 1.6973 (C: 1.6973, R: 0.0000)
Batch 16700/18276: Loss = 1.5528 (C: 1.5528, R: 0.0000)
Batch 16800/18276: Loss = 1.1513 (C: 1.1513, R: 0.0000)
Batch 16900/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 17000/18276: Loss = 1.4937 (C: 1.4937, R: 0.0000)
Batch 17100/18276: Loss = 1.3648 (C: 1.3648, R: 0.0000)
Batch 17200/18276: Loss = 1.6667 (C: 1.6667, R: 0.0000)
Batch 17300/18276: Loss = 1.2905 (C: 1.2905, R: 0.0000)
Batch 17400/18276: Loss = 1.5521 (C: 1.5521, R: 0.0000)
Batch 17500/18276: Loss = 1.3672 (C: 1.3672, R: 0.0000)
Batch 17600/18276: Loss = 1.2380 (C: 1.2380, R: 0.0000)
Batch 17700/18276: Loss = 1.2141 (C: 1.2141, R: 0.0000)
Batch 17800/18276: Loss = 1.6030 (C: 1.6030, R: 0.0000)
Batch 17900/18276: Loss = 1.6567 (C: 1.6567, R: 0.0000)
Batch 18000/18276: Loss = 1.5691 (C: 1.5691, R: 0.0000)
Batch 18100/18276: Loss = 1.7328 (C: 1.7328, R: 0.0000)
Batch 18200/18276: Loss = 1.2378 (C: 1.2378, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.6598519086837769
  reconstruction_loss raw: 0.0
  total_loss raw: 1.6598519086837769
Epoch 11 completed in 71.61s
Train Loss: 1.4452 (C: 1.4452)
Val Loss: 1.4206 (C: 1.4206)
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/best_model.pt
New best model saved (Val Loss: 1.4206)

Epoch 12/50
------------------------------
Batch 0/18276: Loss = 1.4890 (C: 1.4890, R: 0.0000)
Batch 100/18276: Loss = 1.0416 (C: 1.0416, R: 0.0000)
Batch 200/18276: Loss = 1.3551 (C: 1.3551, R: 0.0000)
Batch 300/18276: Loss = 1.4099 (C: 1.4099, R: 0.0000)
Batch 400/18276: Loss = 1.3756 (C: 1.3756, R: 0.0000)
Batch 500/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 600/18276: Loss = 1.5481 (C: 1.5481, R: 0.0000)
Batch 700/18276: Loss = 1.3640 (C: 1.3640, R: 0.0000)
Batch 800/18276: Loss = 1.1513 (C: 1.1513, R: 0.0000)
Batch 900/18276: Loss = 1.4074 (C: 1.4074, R: 0.0000)
Batch 1000/18276: Loss = 1.2373 (C: 1.2373, R: 0.0000)
Batch 1100/18276: Loss = 1.8371 (C: 1.8371, R: 0.0000)
Batch 1200/18276: Loss = 1.5809 (C: 1.5809, R: 0.0000)
Batch 1300/18276: Loss = 1.5438 (C: 1.5438, R: 0.0000)
Batch 1400/18276: Loss = 1.0231 (C: 1.0231, R: 0.0000)
Batch 1500/18276: Loss = 1.7508 (C: 1.7508, R: 0.0000)
Batch 1600/18276: Loss = 1.5779 (C: 1.5779, R: 0.0000)
Batch 1700/18276: Loss = 1.4987 (C: 1.4987, R: 0.0000)
Batch 1800/18276: Loss = 1.3649 (C: 1.3649, R: 0.0000)
Batch 1900/18276: Loss = 1.9338 (C: 1.9338, R: 0.0000)
Batch 2000/18276: Loss = 1.3546 (C: 1.3546, R: 0.0000)
Batch 2100/18276: Loss = 1.5536 (C: 1.5536, R: 0.0000)
Batch 2200/18276: Loss = 1.5965 (C: 1.5965, R: 0.0000)
Batch 2300/18276: Loss = 1.7083 (C: 1.7083, R: 0.0000)
Batch 2400/18276: Loss = 1.5484 (C: 1.5484, R: 0.0000)
Batch 2500/18276: Loss = 1.4213 (C: 1.4213, R: 0.0000)
Batch 2600/18276: Loss = 1.5794 (C: 1.5794, R: 0.0000)
Batch 2700/18276: Loss = 1.6641 (C: 1.6641, R: 0.0000)
Batch 2800/18276: Loss = 1.4935 (C: 1.4935, R: 0.0000)
Batch 2900/18276: Loss = 1.1453 (C: 1.1453, R: 0.0000)
Batch 3000/18276: Loss = 1.7024 (C: 1.7024, R: 0.0000)
Batch 3100/18276: Loss = 1.4071 (C: 1.4071, R: 0.0000)
Batch 3200/18276: Loss = 1.7060 (C: 1.7060, R: 0.0000)
Batch 3300/18276: Loss = 1.7198 (C: 1.7198, R: 0.0000)
Batch 3400/18276: Loss = 1.7024 (C: 1.7024, R: 0.0000)
Batch 3500/18276: Loss = 1.7552 (C: 1.7552, R: 0.0000)
Batch 3600/18276: Loss = 1.1957 (C: 1.1957, R: 0.0000)
Batch 3700/18276: Loss = 1.3724 (C: 1.3724, R: 0.0000)
Batch 3800/18276: Loss = 1.7499 (C: 1.7499, R: 0.0000)
Batch 3900/18276: Loss = 1.2048 (C: 1.2048, R: 0.0000)
Batch 4000/18276: Loss = 1.4082 (C: 1.4082, R: 0.0000)
Batch 4100/18276: Loss = 1.1512 (C: 1.1512, R: 0.0000)
Batch 4200/18276: Loss = 1.5503 (C: 1.5503, R: 0.0000)
Batch 4300/18276: Loss = 1.7017 (C: 1.7017, R: 0.0000)
Batch 4400/18276: Loss = 1.5806 (C: 1.5806, R: 0.0000)
Batch 4500/18276: Loss = 1.4902 (C: 1.4902, R: 0.0000)
Batch 4600/18276: Loss = 1.2375 (C: 1.2375, R: 0.0000)
Batch 4700/18276: Loss = 1.8067 (C: 1.8067, R: 0.0000)
Batch 4800/18276: Loss = 1.3146 (C: 1.3146, R: 0.0000)
Batch 4900/18276: Loss = 1.8056 (C: 1.8056, R: 0.0000)
Batch 5000/18276: Loss = 1.9312 (C: 1.9312, R: 0.0000)
Batch 5100/18276: Loss = 1.4873 (C: 1.4873, R: 0.0000)
Batch 5200/18276: Loss = 1.7008 (C: 1.7008, R: 0.0000)
Batch 5300/18276: Loss = 1.8075 (C: 1.8075, R: 0.0000)
Batch 5400/18276: Loss = 1.5597 (C: 1.5597, R: 0.0000)
Batch 5500/18276: Loss = 1.0226 (C: 1.0226, R: 0.0000)
Batch 5600/18276: Loss = 1.1546 (C: 1.1546, R: 0.0000)
Batch 5700/18276: Loss = 1.6614 (C: 1.6614, R: 0.0000)
Batch 5800/18276: Loss = 1.3660 (C: 1.3660, R: 0.0000)
Batch 5900/18276: Loss = 1.5807 (C: 1.5807, R: 0.0000)
Batch 6000/18276: Loss = 1.5534 (C: 1.5534, R: 0.0000)
Batch 6100/18276: Loss = 1.3009 (C: 1.3009, R: 0.0000)
Batch 6200/18276: Loss = 1.0380 (C: 1.0380, R: 0.0000)
Batch 6300/18276: Loss = 1.7525 (C: 1.7525, R: 0.0000)
Batch 6400/18276: Loss = 1.2363 (C: 1.2363, R: 0.0000)
Batch 6500/18276: Loss = 1.4154 (C: 1.4154, R: 0.0000)
Batch 6600/18276: Loss = 1.5738 (C: 1.5738, R: 0.0000)
Batch 6700/18276: Loss = 1.3962 (C: 1.3962, R: 0.0000)
Batch 6800/18276: Loss = 1.0373 (C: 1.0373, R: 0.0000)
Batch 6900/18276: Loss = 1.2397 (C: 1.2397, R: 0.0000)
Batch 7000/18276: Loss = 1.5528 (C: 1.5528, R: 0.0000)
Batch 7100/18276: Loss = 1.1464 (C: 1.1464, R: 0.0000)
Batch 7200/18276: Loss = 1.5711 (C: 1.5711, R: 0.0000)
Batch 7300/18276: Loss = 1.6015 (C: 1.6015, R: 0.0000)
Batch 7400/18276: Loss = 1.5736 (C: 1.5736, R: 0.0000)
Batch 7500/18276: Loss = 1.4020 (C: 1.4020, R: 0.0000)
Batch 7600/18276: Loss = 1.4026 (C: 1.4026, R: 0.0000)
Batch 7700/18276: Loss = 1.0235 (C: 1.0235, R: 0.0000)
Batch 7800/18276: Loss = 1.2067 (C: 1.2067, R: 0.0000)
Batch 7900/18276: Loss = 1.4078 (C: 1.4078, R: 0.0000)
Batch 8000/18276: Loss = 1.7934 (C: 1.7934, R: 0.0000)
Batch 8100/18276: Loss = 1.7083 (C: 1.7083, R: 0.0000)
Batch 8200/18276: Loss = 1.4969 (C: 1.4969, R: 0.0000)
Batch 8300/18276: Loss = 1.0379 (C: 1.0379, R: 0.0000)
Batch 8400/18276: Loss = 1.4893 (C: 1.4893, R: 0.0000)
Batch 8500/18276: Loss = 1.0493 (C: 1.0493, R: 0.0000)
Batch 8600/18276: Loss = 1.4876 (C: 1.4876, R: 0.0000)
Batch 8700/18276: Loss = 1.6501 (C: 1.6501, R: 0.0000)
Batch 8800/18276: Loss = 1.5683 (C: 1.5683, R: 0.0000)
Batch 8900/18276: Loss = 1.3737 (C: 1.3737, R: 0.0000)
Batch 9000/18276: Loss = 1.0639 (C: 1.0639, R: 0.0000)
Batch 9100/18276: Loss = 1.4052 (C: 1.4052, R: 0.0000)
Batch 9200/18276: Loss = 1.6539 (C: 1.6539, R: 0.0000)
Batch 9300/18276: Loss = 1.0349 (C: 1.0349, R: 0.0000)
Batch 9400/18276: Loss = 1.5832 (C: 1.5832, R: 0.0000)
Batch 9500/18276: Loss = 1.4015 (C: 1.4015, R: 0.0000)
Batch 9600/18276: Loss = 1.2053 (C: 1.2053, R: 0.0000)
Batch 9700/18276: Loss = 1.5734 (C: 1.5734, R: 0.0000)
Batch 9800/18276: Loss = 1.3682 (C: 1.3682, R: 0.0000)
Batch 9900/18276: Loss = 1.8374 (C: 1.8374, R: 0.0000)
Batch 10000/18276: Loss = 1.4014 (C: 1.4014, R: 0.0000)
Batch 10100/18276: Loss = 1.4056 (C: 1.4056, R: 0.0000)
Batch 10200/18276: Loss = 1.6977 (C: 1.6977, R: 0.0000)
Batch 10300/18276: Loss = 1.2775 (C: 1.2775, R: 0.0000)
Batch 10400/18276: Loss = 1.2046 (C: 1.2046, R: 0.0000)
Batch 10500/18276: Loss = 1.5810 (C: 1.5810, R: 0.0000)
Batch 10600/18276: Loss = 1.8388 (C: 1.8388, R: 0.0000)
Batch 10700/18276: Loss = 1.5541 (C: 1.5541, R: 0.0000)
Batch 10800/18276: Loss = 1.5805 (C: 1.5805, R: 0.0000)
Batch 10900/18276: Loss = 1.8794 (C: 1.8794, R: 0.0000)
Batch 11000/18276: Loss = 1.7868 (C: 1.7868, R: 0.0000)
Batch 11100/18276: Loss = 1.7930 (C: 1.7930, R: 0.0000)
Batch 11200/18276: Loss = 1.5691 (C: 1.5691, R: 0.0000)
Batch 11300/18276: Loss = 1.2117 (C: 1.2117, R: 0.0000)
Batch 11400/18276: Loss = 1.4018 (C: 1.4018, R: 0.0000)
Batch 11500/18276: Loss = 1.6659 (C: 1.6659, R: 0.0000)
Batch 11600/18276: Loss = 1.1452 (C: 1.1452, R: 0.0000)
Batch 11700/18276: Loss = 1.4349 (C: 1.4349, R: 0.0000)
Batch 11800/18276: Loss = 1.4717 (C: 1.4717, R: 0.0000)
Batch 11900/18276: Loss = 1.7633 (C: 1.7633, R: 0.0000)
Batch 12000/18276: Loss = 1.5525 (C: 1.5525, R: 0.0000)
Batch 12100/18276: Loss = 1.1555 (C: 1.1555, R: 0.0000)
Batch 12200/18276: Loss = 1.5527 (C: 1.5527, R: 0.0000)
Batch 12300/18276: Loss = 1.3252 (C: 1.3252, R: 0.0000)
Batch 12400/18276: Loss = 1.5534 (C: 1.5534, R: 0.0000)
Batch 12500/18276: Loss = 1.0530 (C: 1.0530, R: 0.0000)
Batch 12600/18276: Loss = 1.3781 (C: 1.3781, R: 0.0000)
Batch 12700/18276: Loss = 1.2094 (C: 1.2094, R: 0.0000)
Batch 12800/18276: Loss = 1.2374 (C: 1.2374, R: 0.0000)
Batch 12900/18276: Loss = 1.2049 (C: 1.2049, R: 0.0000)
Batch 13000/18276: Loss = 1.4046 (C: 1.4046, R: 0.0000)
Batch 13100/18276: Loss = 1.5909 (C: 1.5909, R: 0.0000)
Batch 13200/18276: Loss = 1.6506 (C: 1.6506, R: 0.0000)
Batch 13300/18276: Loss = 1.5746 (C: 1.5746, R: 0.0000)
Batch 13400/18276: Loss = 1.5348 (C: 1.5348, R: 0.0000)
Batch 13500/18276: Loss = 1.2360 (C: 1.2360, R: 0.0000)
Batch 13600/18276: Loss = 1.4707 (C: 1.4707, R: 0.0000)
Batch 13700/18276: Loss = 1.7070 (C: 1.7070, R: 0.0000)
Batch 13800/18276: Loss = 1.4469 (C: 1.4469, R: 0.0000)
Batch 13900/18276: Loss = 1.2042 (C: 1.2042, R: 0.0000)
Batch 14000/18276: Loss = 1.7198 (C: 1.7198, R: 0.0000)
Batch 14100/18276: Loss = 1.2914 (C: 1.2914, R: 0.0000)
Batch 14200/18276: Loss = 1.7199 (C: 1.7199, R: 0.0000)
Batch 14300/18276: Loss = 1.3650 (C: 1.3650, R: 0.0000)
Batch 14400/18276: Loss = 1.2427 (C: 1.2427, R: 0.0000)
Batch 14500/18276: Loss = 1.2123 (C: 1.2123, R: 0.0000)
Batch 14600/18276: Loss = 1.7061 (C: 1.7061, R: 0.0000)
Batch 14700/18276: Loss = 1.3648 (C: 1.3648, R: 0.0000)
Batch 14800/18276: Loss = 1.4240 (C: 1.4240, R: 0.0000)
Batch 14900/18276: Loss = 1.7040 (C: 1.7040, R: 0.0000)
Batch 15000/18276: Loss = 1.6354 (C: 1.6354, R: 0.0000)
Batch 15100/18276: Loss = 1.0535 (C: 1.0535, R: 0.0000)
Batch 15200/18276: Loss = 1.4264 (C: 1.4264, R: 0.0000)
Batch 15300/18276: Loss = 1.4875 (C: 1.4875, R: 0.0000)
Batch 15400/18276: Loss = 1.6547 (C: 1.6547, R: 0.0000)
Batch 15500/18276: Loss = 1.5690 (C: 1.5690, R: 0.0000)
Batch 15600/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 15700/18276: Loss = 1.9156 (C: 1.9156, R: 0.0000)
Batch 15800/18276: Loss = 1.4088 (C: 1.4088, R: 0.0000)
Batch 15900/18276: Loss = 1.5932 (C: 1.5932, R: 0.0000)
Batch 16000/18276: Loss = 1.5095 (C: 1.5095, R: 0.0000)
Batch 16100/18276: Loss = 1.2951 (C: 1.2951, R: 0.0000)
Batch 16200/18276: Loss = 1.3802 (C: 1.3802, R: 0.0000)
Batch 16300/18276: Loss = 1.2051 (C: 1.2051, R: 0.0000)
Batch 16400/18276: Loss = 1.2904 (C: 1.2904, R: 0.0000)
Batch 16500/18276: Loss = 1.2096 (C: 1.2096, R: 0.0000)
Batch 16600/18276: Loss = 1.5806 (C: 1.5806, R: 0.0000)
Batch 16700/18276: Loss = 1.4015 (C: 1.4015, R: 0.0000)
Batch 16800/18276: Loss = 1.4752 (C: 1.4752, R: 0.0000)
Batch 16900/18276: Loss = 1.7241 (C: 1.7241, R: 0.0000)
Batch 17000/18276: Loss = 1.4195 (C: 1.4195, R: 0.0000)
Batch 17100/18276: Loss = 0.9478 (C: 0.9478, R: 0.0000)
Batch 17200/18276: Loss = 1.2843 (C: 1.2843, R: 0.0000)
Batch 17300/18276: Loss = 1.2354 (C: 1.2354, R: 0.0000)
Batch 17400/18276: Loss = 1.6422 (C: 1.6422, R: 0.0000)
Batch 17500/18276: Loss = 0.9481 (C: 0.9481, R: 0.0000)
Batch 17600/18276: Loss = 1.5802 (C: 1.5802, R: 0.0000)
Batch 17700/18276: Loss = 1.6834 (C: 1.6834, R: 0.0000)
Batch 17800/18276: Loss = 1.4702 (C: 1.4702, R: 0.0000)
Batch 17900/18276: Loss = 1.4882 (C: 1.4882, R: 0.0000)
Batch 18000/18276: Loss = 1.5569 (C: 1.5569, R: 0.0000)
Batch 18100/18276: Loss = 1.6593 (C: 1.6593, R: 0.0000)
Batch 18200/18276: Loss = 1.5353 (C: 1.5353, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.8807485103607178
  reconstruction_loss raw: 0.0
  total_loss raw: 1.8807485103607178
Epoch 12 completed in 74.69s
Train Loss: 1.4457 (C: 1.4457)
Val Loss: 1.4217 (C: 1.4217)
No improvement for 1 epochs

Epoch 13/50
------------------------------
Batch 0/18276: Loss = 1.5730 (C: 1.5730, R: 0.0000)
Batch 100/18276: Loss = 1.3532 (C: 1.3532, R: 0.0000)
Batch 200/18276: Loss = 1.2370 (C: 1.2370, R: 0.0000)
Batch 300/18276: Loss = 1.4143 (C: 1.4143, R: 0.0000)
Batch 400/18276: Loss = 1.0539 (C: 1.0539, R: 0.0000)
Batch 500/18276: Loss = 1.5929 (C: 1.5929, R: 0.0000)
Batch 600/18276: Loss = 1.7211 (C: 1.7211, R: 0.0000)
Batch 700/18276: Loss = 1.3784 (C: 1.3784, R: 0.0000)
Batch 800/18276: Loss = 0.9791 (C: 0.9791, R: 0.0000)
Batch 900/18276: Loss = 1.4015 (C: 1.4015, R: 0.0000)
Batch 1000/18276: Loss = 1.5695 (C: 1.5695, R: 0.0000)
Batch 1100/18276: Loss = 1.6592 (C: 1.6592, R: 0.0000)
Batch 1200/18276: Loss = 1.7700 (C: 1.7700, R: 0.0000)
Batch 1300/18276: Loss = 1.5798 (C: 1.5798, R: 0.0000)
Batch 1400/18276: Loss = 1.7020 (C: 1.7020, R: 0.0000)
Batch 1500/18276: Loss = 1.5843 (C: 1.5843, R: 0.0000)
Batch 1600/18276: Loss = 1.3545 (C: 1.3545, R: 0.0000)
Batch 1700/18276: Loss = 1.8293 (C: 1.8293, R: 0.0000)
Batch 1800/18276: Loss = 1.1516 (C: 1.1516, R: 0.0000)
Batch 1900/18276: Loss = 1.6657 (C: 1.6657, R: 0.0000)
Batch 2000/18276: Loss = 1.5483 (C: 1.5483, R: 0.0000)
Batch 2100/18276: Loss = 1.5525 (C: 1.5525, R: 0.0000)
Batch 2200/18276: Loss = 1.4877 (C: 1.4877, R: 0.0000)
Batch 2300/18276: Loss = 1.5684 (C: 1.5684, R: 0.0000)
Batch 2400/18276: Loss = 1.2357 (C: 1.2357, R: 0.0000)
Batch 2500/18276: Loss = 1.4198 (C: 1.4198, R: 0.0000)
Batch 2600/18276: Loss = 1.5442 (C: 1.5442, R: 0.0000)
Batch 2700/18276: Loss = 1.6611 (C: 1.6611, R: 0.0000)
Batch 2800/18276: Loss = 1.5813 (C: 1.5813, R: 0.0000)
Batch 2900/18276: Loss = 1.5808 (C: 1.5808, R: 0.0000)
Batch 3000/18276: Loss = 1.3923 (C: 1.3923, R: 0.0000)
Batch 3100/18276: Loss = 1.5527 (C: 1.5527, R: 0.0000)
Batch 3200/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 3300/18276: Loss = 1.3922 (C: 1.3922, R: 0.0000)
Batch 3400/18276: Loss = 1.5481 (C: 1.5481, R: 0.0000)
Batch 3500/18276: Loss = 1.5695 (C: 1.5695, R: 0.0000)
Batch 3600/18276: Loss = 1.3742 (C: 1.3742, R: 0.0000)
Batch 3700/18276: Loss = 1.4103 (C: 1.4103, R: 0.0000)
Batch 3800/18276: Loss = 1.2092 (C: 1.2092, R: 0.0000)
Batch 3900/18276: Loss = 1.0230 (C: 1.0230, R: 0.0000)
Batch 4000/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 4100/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 4200/18276: Loss = 1.3655 (C: 1.3655, R: 0.0000)
Batch 4300/18276: Loss = 1.4076 (C: 1.4076, R: 0.0000)
Batch 4400/18276: Loss = 1.3541 (C: 1.3541, R: 0.0000)
Batch 4500/18276: Loss = 1.4242 (C: 1.4242, R: 0.0000)
Batch 4600/18276: Loss = 1.5528 (C: 1.5528, R: 0.0000)
Batch 4700/18276: Loss = 1.6653 (C: 1.6653, R: 0.0000)
Batch 4800/18276: Loss = 0.9781 (C: 0.9781, R: 0.0000)
Batch 4900/18276: Loss = 0.9346 (C: 0.9346, R: 0.0000)
Batch 5000/18276: Loss = 1.2387 (C: 1.2387, R: 0.0000)
Batch 5100/18276: Loss = 1.0225 (C: 1.0225, R: 0.0000)
Batch 5200/18276: Loss = 1.3555 (C: 1.3555, R: 0.0000)
Batch 5300/18276: Loss = 1.4088 (C: 1.4088, R: 0.0000)
Batch 5400/18276: Loss = 1.2356 (C: 1.2356, R: 0.0000)
Batch 5500/18276: Loss = 1.0380 (C: 1.0380, R: 0.0000)
Batch 5600/18276: Loss = 1.5785 (C: 1.5785, R: 0.0000)
Batch 5700/18276: Loss = 1.8087 (C: 1.8087, R: 0.0000)
Batch 5800/18276: Loss = 1.3994 (C: 1.3994, R: 0.0000)
Batch 5900/18276: Loss = 1.4105 (C: 1.4105, R: 0.0000)
Batch 6000/18276: Loss = 1.7161 (C: 1.7161, R: 0.0000)
Batch 6100/18276: Loss = 1.2071 (C: 1.2071, R: 0.0000)
Batch 6200/18276: Loss = 1.2365 (C: 1.2365, R: 0.0000)
Batch 6300/18276: Loss = 1.3742 (C: 1.3742, R: 0.0000)
Batch 6400/18276: Loss = 1.4005 (C: 1.4005, R: 0.0000)
Batch 6500/18276: Loss = 1.2837 (C: 1.2837, R: 0.0000)
Batch 6600/18276: Loss = 1.2961 (C: 1.2961, R: 0.0000)
Batch 6700/18276: Loss = 1.1522 (C: 1.1522, R: 0.0000)
Batch 6800/18276: Loss = 1.5576 (C: 1.5576, R: 0.0000)
Batch 6900/18276: Loss = 1.0471 (C: 1.0471, R: 0.0000)
Batch 7000/18276: Loss = 1.6026 (C: 1.6026, R: 0.0000)
Batch 7100/18276: Loss = 1.6582 (C: 1.6582, R: 0.0000)
Batch 7200/18276: Loss = 1.2288 (C: 1.2288, R: 0.0000)
Batch 7300/18276: Loss = 1.0200 (C: 1.0200, R: 0.0000)
Batch 7400/18276: Loss = 0.9056 (C: 0.9056, R: 0.0000)
Batch 7500/18276: Loss = 1.5917 (C: 1.5917, R: 0.0000)
Batch 7600/18276: Loss = 1.0532 (C: 1.0532, R: 0.0000)
Batch 7700/18276: Loss = 1.0227 (C: 1.0227, R: 0.0000)
Batch 7800/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 7900/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 8000/18276: Loss = 1.2366 (C: 1.2366, R: 0.0000)
Batch 8100/18276: Loss = 1.2773 (C: 1.2773, R: 0.0000)
Batch 8200/18276: Loss = 1.7168 (C: 1.7168, R: 0.0000)
Batch 8300/18276: Loss = 1.2068 (C: 1.2068, R: 0.0000)
Batch 8400/18276: Loss = 1.4108 (C: 1.4108, R: 0.0000)
Batch 8500/18276: Loss = 1.3545 (C: 1.3545, R: 0.0000)
Batch 8600/18276: Loss = 1.1492 (C: 1.1492, R: 0.0000)
Batch 8700/18276: Loss = 1.2360 (C: 1.2360, R: 0.0000)
Batch 8800/18276: Loss = 0.9746 (C: 0.9746, R: 0.0000)
Batch 8900/18276: Loss = 1.7197 (C: 1.7197, R: 0.0000)
Batch 9000/18276: Loss = 1.2081 (C: 1.2081, R: 0.0000)
Batch 9100/18276: Loss = 1.7937 (C: 1.7937, R: 0.0000)
Batch 9200/18276: Loss = 1.4917 (C: 1.4917, R: 0.0000)
Batch 9300/18276: Loss = 1.4917 (C: 1.4917, R: 0.0000)
Batch 9400/18276: Loss = 1.5814 (C: 1.5814, R: 0.0000)
Batch 9500/18276: Loss = 1.4174 (C: 1.4174, R: 0.0000)
Batch 9600/18276: Loss = 1.0295 (C: 1.0295, R: 0.0000)
Batch 9700/18276: Loss = 1.5757 (C: 1.5757, R: 0.0000)
Batch 9800/18276: Loss = 1.5810 (C: 1.5810, R: 0.0000)
Batch 9900/18276: Loss = 1.3542 (C: 1.3542, R: 0.0000)
Batch 10000/18276: Loss = 1.6961 (C: 1.6961, R: 0.0000)
Batch 10100/18276: Loss = 0.9052 (C: 0.9052, R: 0.0000)
Batch 10200/18276: Loss = 1.5777 (C: 1.5777, R: 0.0000)
Batch 10300/18276: Loss = 1.5722 (C: 1.5722, R: 0.0000)
Batch 10400/18276: Loss = 1.8380 (C: 1.8380, R: 0.0000)
Batch 10500/18276: Loss = 1.2373 (C: 1.2373, R: 0.0000)
Batch 10600/18276: Loss = 1.4814 (C: 1.4814, R: 0.0000)
Batch 10700/18276: Loss = 1.4902 (C: 1.4902, R: 0.0000)
Batch 10800/18276: Loss = 1.2938 (C: 1.2938, R: 0.0000)
Batch 10900/18276: Loss = 1.4079 (C: 1.4079, R: 0.0000)
Batch 11000/18276: Loss = 2.0515 (C: 2.0515, R: 0.0000)
Batch 11100/18276: Loss = 1.9127 (C: 1.9127, R: 0.0000)
Batch 11200/18276: Loss = 1.1521 (C: 1.1521, R: 0.0000)
Batch 11300/18276: Loss = 1.1529 (C: 1.1529, R: 0.0000)
Batch 11400/18276: Loss = 1.2812 (C: 1.2812, R: 0.0000)
Batch 11500/18276: Loss = 1.4235 (C: 1.4235, R: 0.0000)
Batch 11600/18276: Loss = 1.0542 (C: 1.0542, R: 0.0000)
Batch 11700/18276: Loss = 1.2755 (C: 1.2755, R: 0.0000)
Batch 11800/18276: Loss = 0.8879 (C: 0.8879, R: 0.0000)
Batch 11900/18276: Loss = 1.2840 (C: 1.2840, R: 0.0000)
Batch 12000/18276: Loss = 1.2111 (C: 1.2111, R: 0.0000)
Batch 12100/18276: Loss = 1.6861 (C: 1.6861, R: 0.0000)
Batch 12200/18276: Loss = 1.0609 (C: 1.0609, R: 0.0000)
Batch 12300/18276: Loss = 1.3625 (C: 1.3625, R: 0.0000)
Batch 12400/18276: Loss = 1.5736 (C: 1.5736, R: 0.0000)
Batch 12500/18276: Loss = 1.0378 (C: 1.0378, R: 0.0000)
Batch 12600/18276: Loss = 1.5779 (C: 1.5779, R: 0.0000)
Batch 12700/18276: Loss = 1.1443 (C: 1.1443, R: 0.0000)
Batch 12800/18276: Loss = 1.6652 (C: 1.6652, R: 0.0000)
Batch 12900/18276: Loss = 1.6550 (C: 1.6550, R: 0.0000)
Batch 13000/18276: Loss = 1.2910 (C: 1.2910, R: 0.0000)
Batch 13100/18276: Loss = 1.4025 (C: 1.4025, R: 0.0000)
Batch 13200/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 13300/18276: Loss = 1.2382 (C: 1.2382, R: 0.0000)
Batch 13400/18276: Loss = 1.3544 (C: 1.3544, R: 0.0000)
Batch 13500/18276: Loss = 1.6982 (C: 1.6982, R: 0.0000)
Batch 13600/18276: Loss = 1.9861 (C: 1.9861, R: 0.0000)
Batch 13700/18276: Loss = 1.1447 (C: 1.1447, R: 0.0000)
Batch 13800/18276: Loss = 1.8385 (C: 1.8385, R: 0.0000)
Batch 13900/18276: Loss = 1.7200 (C: 1.7200, R: 0.0000)
Batch 14000/18276: Loss = 1.5421 (C: 1.5421, R: 0.0000)
Batch 14100/18276: Loss = 1.2372 (C: 1.2372, R: 0.0000)
Batch 14200/18276: Loss = 0.8003 (C: 0.8003, R: 0.0000)
Batch 14300/18276: Loss = 1.6016 (C: 1.6016, R: 0.0000)
Batch 14400/18276: Loss = 1.2772 (C: 1.2772, R: 0.0000)
Batch 14500/18276: Loss = 1.4324 (C: 1.4324, R: 0.0000)
Batch 14600/18276: Loss = 1.6549 (C: 1.6549, R: 0.0000)
Batch 14700/18276: Loss = 1.5703 (C: 1.5703, R: 0.0000)
Batch 14800/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 14900/18276: Loss = 1.8055 (C: 1.8055, R: 0.0000)
Batch 15000/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 15100/18276: Loss = 1.0380 (C: 1.0380, R: 0.0000)
Batch 15200/18276: Loss = 1.2048 (C: 1.2048, R: 0.0000)
Batch 15300/18276: Loss = 0.9058 (C: 0.9058, R: 0.0000)
Batch 15400/18276: Loss = 1.3097 (C: 1.3097, R: 0.0000)
Batch 15500/18276: Loss = 0.9778 (C: 0.9778, R: 0.0000)
Batch 15600/18276: Loss = 1.1977 (C: 1.1977, R: 0.0000)
Batch 15700/18276: Loss = 1.2337 (C: 1.2337, R: 0.0000)
Batch 15800/18276: Loss = 1.4242 (C: 1.4242, R: 0.0000)
Batch 15900/18276: Loss = 1.1441 (C: 1.1441, R: 0.0000)
Batch 16000/18276: Loss = 1.4713 (C: 1.4713, R: 0.0000)
Batch 16100/18276: Loss = 1.4092 (C: 1.4092, R: 0.0000)
Batch 16200/18276: Loss = 1.2091 (C: 1.2091, R: 0.0000)
Batch 16300/18276: Loss = 1.2091 (C: 1.2091, R: 0.0000)
Batch 16400/18276: Loss = 1.4224 (C: 1.4224, R: 0.0000)
Batch 16500/18276: Loss = 1.4102 (C: 1.4102, R: 0.0000)
Batch 16600/18276: Loss = 1.5786 (C: 1.5786, R: 0.0000)
Batch 16700/18276: Loss = 1.2955 (C: 1.2955, R: 0.0000)
Batch 16800/18276: Loss = 1.6639 (C: 1.6639, R: 0.0000)
Batch 16900/18276: Loss = 1.4087 (C: 1.4087, R: 0.0000)
Batch 17000/18276: Loss = 1.7000 (C: 1.7000, R: 0.0000)
Batch 17100/18276: Loss = 1.0230 (C: 1.0230, R: 0.0000)
Batch 17200/18276: Loss = 1.0560 (C: 1.0560, R: 0.0000)
Batch 17300/18276: Loss = 1.5477 (C: 1.5477, R: 0.0000)
Batch 17400/18276: Loss = 1.2405 (C: 1.2405, R: 0.0000)
Batch 17500/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 17600/18276: Loss = 1.5795 (C: 1.5795, R: 0.0000)
Batch 17700/18276: Loss = 1.6711 (C: 1.6711, R: 0.0000)
Batch 17800/18276: Loss = 1.4142 (C: 1.4142, R: 0.0000)
Batch 17900/18276: Loss = 1.4248 (C: 1.4248, R: 0.0000)
Batch 18000/18276: Loss = 1.5171 (C: 1.5171, R: 0.0000)
Batch 18100/18276: Loss = 1.4071 (C: 1.4071, R: 0.0000)
Batch 18200/18276: Loss = 1.8305 (C: 1.8305, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.6075806617736816
  reconstruction_loss raw: 0.0
  total_loss raw: 1.6075806617736816
Epoch 13 completed in 72.64s
Train Loss: 1.4416 (C: 1.4416)
Val Loss: 1.4388 (C: 1.4388)
No improvement for 2 epochs

Epoch 14/50
------------------------------
Batch 0/18276: Loss = 1.5284 (C: 1.5284, R: 0.0000)
Batch 100/18276: Loss = 1.6548 (C: 1.6548, R: 0.0000)
Batch 200/18276: Loss = 0.9449 (C: 0.9449, R: 0.0000)
Batch 300/18276: Loss = 1.3988 (C: 1.3988, R: 0.0000)
Batch 400/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 500/18276: Loss = 1.3542 (C: 1.3542, R: 0.0000)
Batch 600/18276: Loss = 1.6328 (C: 1.6328, R: 0.0000)
Batch 700/18276: Loss = 1.2043 (C: 1.2043, R: 0.0000)
Batch 800/18276: Loss = 1.4228 (C: 1.4228, R: 0.0000)
Batch 900/18276: Loss = 1.4132 (C: 1.4132, R: 0.0000)
Batch 1000/18276: Loss = 1.1882 (C: 1.1882, R: 0.0000)
Batch 1100/18276: Loss = 1.7084 (C: 1.7084, R: 0.0000)
Batch 1200/18276: Loss = 1.5522 (C: 1.5522, R: 0.0000)
Batch 1300/18276: Loss = 1.3660 (C: 1.3660, R: 0.0000)
Batch 1400/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 1500/18276: Loss = 1.2075 (C: 1.2075, R: 0.0000)
Batch 1600/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 1700/18276: Loss = 1.4094 (C: 1.4094, R: 0.0000)
Batch 1800/18276: Loss = 1.1865 (C: 1.1865, R: 0.0000)
Batch 1900/18276: Loss = 1.5429 (C: 1.5429, R: 0.0000)
Batch 2000/18276: Loss = 1.2091 (C: 1.2091, R: 0.0000)
Batch 2100/18276: Loss = 1.3547 (C: 1.3547, R: 0.0000)
Batch 2200/18276: Loss = 1.3797 (C: 1.3797, R: 0.0000)
Batch 2300/18276: Loss = 1.5346 (C: 1.5346, R: 0.0000)
Batch 2400/18276: Loss = 1.5740 (C: 1.5740, R: 0.0000)
Batch 2500/18276: Loss = 1.4074 (C: 1.4074, R: 0.0000)
Batch 2600/18276: Loss = 1.9119 (C: 1.9119, R: 0.0000)
Batch 2700/18276: Loss = 1.5303 (C: 1.5303, R: 0.0000)
Batch 2800/18276: Loss = 1.6839 (C: 1.6839, R: 0.0000)
Batch 2900/18276: Loss = 1.7200 (C: 1.7200, R: 0.0000)
Batch 3000/18276: Loss = 1.6548 (C: 1.6548, R: 0.0000)
Batch 3100/18276: Loss = 1.0559 (C: 1.0559, R: 0.0000)
Batch 3200/18276: Loss = 1.2058 (C: 1.2058, R: 0.0000)
Batch 3300/18276: Loss = 1.7045 (C: 1.7045, R: 0.0000)
Batch 3400/18276: Loss = 1.7291 (C: 1.7291, R: 0.0000)
Batch 3500/18276: Loss = 1.5858 (C: 1.5858, R: 0.0000)
Batch 3600/18276: Loss = 1.7069 (C: 1.7069, R: 0.0000)
Batch 3700/18276: Loss = 1.9711 (C: 1.9711, R: 0.0000)
Batch 3800/18276: Loss = 1.1987 (C: 1.1987, R: 0.0000)
Batch 3900/18276: Loss = 1.3648 (C: 1.3648, R: 0.0000)
Batch 4000/18276: Loss = 1.4070 (C: 1.4070, R: 0.0000)
Batch 4100/18276: Loss = 1.2093 (C: 1.2093, R: 0.0000)
Batch 4200/18276: Loss = 1.2904 (C: 1.2904, R: 0.0000)
Batch 4300/18276: Loss = 1.1663 (C: 1.1663, R: 0.0000)
Batch 4400/18276: Loss = 1.0653 (C: 1.0653, R: 0.0000)
Batch 4500/18276: Loss = 1.4022 (C: 1.4022, R: 0.0000)
Batch 4600/18276: Loss = 0.9786 (C: 0.9786, R: 0.0000)
Batch 4700/18276: Loss = 1.0240 (C: 1.0240, R: 0.0000)
Batch 4800/18276: Loss = 1.5352 (C: 1.5352, R: 0.0000)
Batch 4900/18276: Loss = 1.5753 (C: 1.5753, R: 0.0000)
Batch 5000/18276: Loss = 1.5815 (C: 1.5815, R: 0.0000)
Batch 5100/18276: Loss = 0.9795 (C: 0.9795, R: 0.0000)
Batch 5200/18276: Loss = 1.1524 (C: 1.1524, R: 0.0000)
Batch 5300/18276: Loss = 1.4081 (C: 1.4081, R: 0.0000)
Batch 5400/18276: Loss = 1.6652 (C: 1.6652, R: 0.0000)
Batch 5500/18276: Loss = 1.6652 (C: 1.6652, R: 0.0000)
Batch 5600/18276: Loss = 1.4190 (C: 1.4190, R: 0.0000)
Batch 5700/18276: Loss = 1.5481 (C: 1.5481, R: 0.0000)
Batch 5800/18276: Loss = 1.3646 (C: 1.3646, R: 0.0000)
Batch 5900/18276: Loss = 1.2288 (C: 1.2288, R: 0.0000)
Batch 6000/18276: Loss = 1.7953 (C: 1.7953, R: 0.0000)
Batch 6100/18276: Loss = 1.5882 (C: 1.5882, R: 0.0000)
Batch 6200/18276: Loss = 1.9243 (C: 1.9243, R: 0.0000)
Batch 6300/18276: Loss = 1.2268 (C: 1.2268, R: 0.0000)
Batch 6400/18276: Loss = 1.6641 (C: 1.6641, R: 0.0000)
Batch 6500/18276: Loss = 1.3528 (C: 1.3528, R: 0.0000)
Batch 6600/18276: Loss = 1.7243 (C: 1.7243, R: 0.0000)
Batch 6700/18276: Loss = 0.9053 (C: 0.9053, R: 0.0000)
Batch 6800/18276: Loss = 1.3173 (C: 1.3173, R: 0.0000)
Batch 6900/18276: Loss = 1.4089 (C: 1.4089, R: 0.0000)
Batch 7000/18276: Loss = 1.5798 (C: 1.5798, R: 0.0000)
Batch 7100/18276: Loss = 1.3651 (C: 1.3651, R: 0.0000)
Batch 7200/18276: Loss = 1.0537 (C: 1.0537, R: 0.0000)
Batch 7300/18276: Loss = 1.5796 (C: 1.5796, R: 0.0000)
Batch 7400/18276: Loss = 1.2049 (C: 1.2049, R: 0.0000)
Batch 7500/18276: Loss = 1.5808 (C: 1.5808, R: 0.0000)
Batch 7600/18276: Loss = 1.3910 (C: 1.3910, R: 0.0000)
Batch 7700/18276: Loss = 1.0384 (C: 1.0384, R: 0.0000)
Batch 7800/18276: Loss = 1.6978 (C: 1.6978, R: 0.0000)
Batch 7900/18276: Loss = 1.2103 (C: 1.2103, R: 0.0000)
Batch 8000/18276: Loss = 1.4200 (C: 1.4200, R: 0.0000)
Batch 8100/18276: Loss = 1.7097 (C: 1.7097, R: 0.0000)
Batch 8200/18276: Loss = 1.4715 (C: 1.4715, R: 0.0000)
Batch 8300/18276: Loss = 1.4200 (C: 1.4200, R: 0.0000)
Batch 8400/18276: Loss = 1.6980 (C: 1.6980, R: 0.0000)
Batch 8500/18276: Loss = 1.3631 (C: 1.3631, R: 0.0000)
Batch 8600/18276: Loss = 1.5630 (C: 1.5630, R: 0.0000)
Batch 8700/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 8800/18276: Loss = 1.2049 (C: 1.2049, R: 0.0000)
Batch 8900/18276: Loss = 1.4068 (C: 1.4068, R: 0.0000)
Batch 9000/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 9100/18276: Loss = 1.2039 (C: 1.2039, R: 0.0000)
Batch 9200/18276: Loss = 1.2633 (C: 1.2633, R: 0.0000)
Batch 9300/18276: Loss = 1.5473 (C: 1.5473, R: 0.0000)
Batch 9400/18276: Loss = 1.4004 (C: 1.4004, R: 0.0000)
Batch 9500/18276: Loss = 1.2055 (C: 1.2055, R: 0.0000)
Batch 9600/18276: Loss = 1.5707 (C: 1.5707, R: 0.0000)
Batch 9700/18276: Loss = 1.3647 (C: 1.3647, R: 0.0000)
Batch 9800/18276: Loss = 1.6629 (C: 1.6629, R: 0.0000)
Batch 9900/18276: Loss = 1.5436 (C: 1.5436, R: 0.0000)
Batch 10000/18276: Loss = 1.5530 (C: 1.5530, R: 0.0000)
Batch 10100/18276: Loss = 1.5938 (C: 1.5938, R: 0.0000)
Batch 10200/18276: Loss = 1.1423 (C: 1.1423, R: 0.0000)
Batch 10300/18276: Loss = 1.3802 (C: 1.3802, R: 0.0000)
Batch 10400/18276: Loss = 1.5403 (C: 1.5403, R: 0.0000)
Batch 10500/18276: Loss = 1.6980 (C: 1.6980, R: 0.0000)
Batch 10600/18276: Loss = 1.4086 (C: 1.4086, R: 0.0000)
Batch 10700/18276: Loss = 1.5369 (C: 1.5369, R: 0.0000)
Batch 10800/18276: Loss = 1.3789 (C: 1.3789, R: 0.0000)
Batch 10900/18276: Loss = 1.4038 (C: 1.4038, R: 0.0000)
Batch 11000/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 11100/18276: Loss = 1.7074 (C: 1.7074, R: 0.0000)
Batch 11200/18276: Loss = 1.4959 (C: 1.4959, R: 0.0000)
Batch 11300/18276: Loss = 1.4236 (C: 1.4236, R: 0.0000)
Batch 11400/18276: Loss = 1.3690 (C: 1.3690, R: 0.0000)
Batch 11500/18276: Loss = 1.2362 (C: 1.2362, R: 0.0000)
Batch 11600/18276: Loss = 1.2917 (C: 1.2917, R: 0.0000)
Batch 11700/18276: Loss = 1.7259 (C: 1.7259, R: 0.0000)
Batch 11800/18276: Loss = 1.2060 (C: 1.2060, R: 0.0000)
Batch 11900/18276: Loss = 1.7202 (C: 1.7202, R: 0.0000)
Batch 12000/18276: Loss = 1.5788 (C: 1.5788, R: 0.0000)
Batch 12100/18276: Loss = 1.7200 (C: 1.7200, R: 0.0000)
Batch 12200/18276: Loss = 1.4713 (C: 1.4713, R: 0.0000)
Batch 12300/18276: Loss = 1.3720 (C: 1.3720, R: 0.0000)
Batch 12400/18276: Loss = 1.1905 (C: 1.1905, R: 0.0000)
Batch 12500/18276: Loss = 1.6711 (C: 1.6711, R: 0.0000)
Batch 12600/18276: Loss = 1.7209 (C: 1.7209, R: 0.0000)
Batch 12700/18276: Loss = 1.4026 (C: 1.4026, R: 0.0000)
Batch 12800/18276: Loss = 0.9782 (C: 0.9782, R: 0.0000)
Batch 12900/18276: Loss = 1.2841 (C: 1.2841, R: 0.0000)
Batch 13000/18276: Loss = 1.3930 (C: 1.3930, R: 0.0000)
Batch 13100/18276: Loss = 1.6590 (C: 1.6590, R: 0.0000)
Batch 13200/18276: Loss = 1.0233 (C: 1.0233, R: 0.0000)
Batch 13300/18276: Loss = 1.3650 (C: 1.3650, R: 0.0000)
Batch 13400/18276: Loss = 1.4959 (C: 1.4959, R: 0.0000)
Batch 13500/18276: Loss = 1.4052 (C: 1.4052, R: 0.0000)
Batch 13600/18276: Loss = 1.6746 (C: 1.6746, R: 0.0000)
Batch 13700/18276: Loss = 1.4202 (C: 1.4202, R: 0.0000)
Batch 13800/18276: Loss = 1.4092 (C: 1.4092, R: 0.0000)
Batch 13900/18276: Loss = 1.0548 (C: 1.0548, R: 0.0000)
Batch 14000/18276: Loss = 1.5487 (C: 1.5487, R: 0.0000)
Batch 14100/18276: Loss = 1.7034 (C: 1.7034, R: 0.0000)
Batch 14200/18276: Loss = 1.5498 (C: 1.5498, R: 0.0000)
Batch 14300/18276: Loss = 1.5692 (C: 1.5692, R: 0.0000)
Batch 14400/18276: Loss = 1.6659 (C: 1.6659, R: 0.0000)
Batch 14500/18276: Loss = 1.5793 (C: 1.5793, R: 0.0000)
Batch 14600/18276: Loss = 1.4262 (C: 1.4262, R: 0.0000)
Batch 14700/18276: Loss = 1.7099 (C: 1.7099, R: 0.0000)
Batch 14800/18276: Loss = 1.2090 (C: 1.2090, R: 0.0000)
Batch 14900/18276: Loss = 1.0565 (C: 1.0565, R: 0.0000)
Batch 15000/18276: Loss = 1.7058 (C: 1.7058, R: 0.0000)
Batch 15100/18276: Loss = 1.2275 (C: 1.2275, R: 0.0000)
Batch 15200/18276: Loss = 1.5223 (C: 1.5223, R: 0.0000)
Batch 15300/18276: Loss = 1.5545 (C: 1.5545, R: 0.0000)
Batch 15400/18276: Loss = 1.5727 (C: 1.5727, R: 0.0000)
Batch 15500/18276: Loss = 1.6653 (C: 1.6653, R: 0.0000)
Batch 15600/18276: Loss = 1.6978 (C: 1.6978, R: 0.0000)
Batch 15700/18276: Loss = 1.3922 (C: 1.3922, R: 0.0000)
Batch 15800/18276: Loss = 1.2046 (C: 1.2046, R: 0.0000)
Batch 15900/18276: Loss = 1.3124 (C: 1.3124, R: 0.0000)
Batch 16000/18276: Loss = 1.4097 (C: 1.4097, R: 0.0000)
Batch 16100/18276: Loss = 1.2091 (C: 1.2091, R: 0.0000)
Batch 16200/18276: Loss = 1.8383 (C: 1.8383, R: 0.0000)
Batch 16300/18276: Loss = 1.4087 (C: 1.4087, R: 0.0000)
Batch 16400/18276: Loss = 1.5913 (C: 1.5913, R: 0.0000)
Batch 16500/18276: Loss = 1.7076 (C: 1.7076, R: 0.0000)
Batch 16600/18276: Loss = 1.3598 (C: 1.3598, R: 0.0000)
Batch 16700/18276: Loss = 1.2093 (C: 1.2093, R: 0.0000)
Batch 16800/18276: Loss = 1.0675 (C: 1.0675, R: 0.0000)
Batch 16900/18276: Loss = 1.2469 (C: 1.2469, R: 0.0000)
Batch 17000/18276: Loss = 1.0385 (C: 1.0385, R: 0.0000)
Batch 17100/18276: Loss = 1.4014 (C: 1.4014, R: 0.0000)
Batch 17200/18276: Loss = 1.7411 (C: 1.7411, R: 0.0000)
Batch 17300/18276: Loss = 1.7068 (C: 1.7068, R: 0.0000)
Batch 17400/18276: Loss = 1.5435 (C: 1.5435, R: 0.0000)
Batch 17500/18276: Loss = 1.2373 (C: 1.2373, R: 0.0000)
Batch 17600/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 17700/18276: Loss = 1.2050 (C: 1.2050, R: 0.0000)
Batch 17800/18276: Loss = 1.4959 (C: 1.4959, R: 0.0000)
Batch 17900/18276: Loss = 1.0245 (C: 1.0245, R: 0.0000)
Batch 18000/18276: Loss = 1.4084 (C: 1.4084, R: 0.0000)
Batch 18100/18276: Loss = 1.4021 (C: 1.4021, R: 0.0000)
Batch 18200/18276: Loss = 1.5780 (C: 1.5780, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.0233397483825684
  reconstruction_loss raw: 0.0
  total_loss raw: 1.0233397483825684
Epoch 14 completed in 71.56s
Train Loss: 1.4426 (C: 1.4426)
Val Loss: 1.4160 (C: 1.4160)
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/best_model.pt
New best model saved (Val Loss: 1.4160)

Epoch 15/50
------------------------------
Batch 0/18276: Loss = 1.6927 (C: 1.6927, R: 0.0000)
Batch 100/18276: Loss = 1.6982 (C: 1.6982, R: 0.0000)
Batch 200/18276: Loss = 1.7062 (C: 1.7062, R: 0.0000)
Batch 300/18276: Loss = 1.3708 (C: 1.3708, R: 0.0000)
Batch 400/18276: Loss = 1.5780 (C: 1.5780, R: 0.0000)
Batch 500/18276: Loss = 1.9103 (C: 1.9103, R: 0.0000)
Batch 600/18276: Loss = 1.5771 (C: 1.5771, R: 0.0000)
Batch 700/18276: Loss = 1.2800 (C: 1.2800, R: 0.0000)
Batch 800/18276: Loss = 0.8042 (C: 0.8042, R: 0.0000)
Batch 900/18276: Loss = 1.0792 (C: 1.0792, R: 0.0000)
Batch 1000/18276: Loss = 1.5736 (C: 1.5736, R: 0.0000)
Batch 1100/18276: Loss = 1.1443 (C: 1.1443, R: 0.0000)
Batch 1200/18276: Loss = 1.7091 (C: 1.7091, R: 0.0000)
Batch 1300/18276: Loss = 1.5596 (C: 1.5596, R: 0.0000)
Batch 1400/18276: Loss = 1.8104 (C: 1.8104, R: 0.0000)
Batch 1500/18276: Loss = 1.7891 (C: 1.7891, R: 0.0000)
Batch 1600/18276: Loss = 1.1531 (C: 1.1531, R: 0.0000)
Batch 1700/18276: Loss = 0.9787 (C: 0.9787, R: 0.0000)
Batch 1800/18276: Loss = 1.0387 (C: 1.0387, R: 0.0000)
Batch 1900/18276: Loss = 1.8059 (C: 1.8059, R: 0.0000)
Batch 2000/18276: Loss = 1.5793 (C: 1.5793, R: 0.0000)
Batch 2100/18276: Loss = 1.5808 (C: 1.5808, R: 0.0000)
Batch 2200/18276: Loss = 1.4096 (C: 1.4096, R: 0.0000)
Batch 2300/18276: Loss = 1.5483 (C: 1.5483, R: 0.0000)
Batch 2400/18276: Loss = 1.3658 (C: 1.3658, R: 0.0000)
Batch 2500/18276: Loss = 1.3661 (C: 1.3661, R: 0.0000)
Batch 2600/18276: Loss = 1.8735 (C: 1.8735, R: 0.0000)
Batch 2700/18276: Loss = 1.2352 (C: 1.2352, R: 0.0000)
Batch 2800/18276: Loss = 1.1519 (C: 1.1519, R: 0.0000)
Batch 2900/18276: Loss = 1.2965 (C: 1.2965, R: 0.0000)
Batch 3000/18276: Loss = 1.4097 (C: 1.4097, R: 0.0000)
Batch 3100/18276: Loss = 1.4206 (C: 1.4206, R: 0.0000)
Batch 3200/18276: Loss = 1.3470 (C: 1.3470, R: 0.0000)
Batch 3300/18276: Loss = 1.5487 (C: 1.5487, R: 0.0000)
Batch 3400/18276: Loss = 1.5732 (C: 1.5732, R: 0.0000)
Batch 3500/18276: Loss = 1.4951 (C: 1.4951, R: 0.0000)
Batch 3600/18276: Loss = 1.5929 (C: 1.5929, R: 0.0000)
Batch 3700/18276: Loss = 1.5691 (C: 1.5691, R: 0.0000)
Batch 3800/18276: Loss = 1.5531 (C: 1.5531, R: 0.0000)
Batch 3900/18276: Loss = 1.3661 (C: 1.3661, R: 0.0000)
Batch 4000/18276: Loss = 1.4713 (C: 1.4713, R: 0.0000)
Batch 4100/18276: Loss = 1.2092 (C: 1.2092, R: 0.0000)
Batch 4200/18276: Loss = 1.6594 (C: 1.6594, R: 0.0000)
Batch 4300/18276: Loss = 1.5523 (C: 1.5523, R: 0.0000)
Batch 4400/18276: Loss = 1.5761 (C: 1.5761, R: 0.0000)
Batch 4500/18276: Loss = 1.2777 (C: 1.2777, R: 0.0000)
Batch 4600/18276: Loss = 1.2221 (C: 1.2221, R: 0.0000)
Batch 4700/18276: Loss = 1.5809 (C: 1.5809, R: 0.0000)
Batch 4800/18276: Loss = 1.1949 (C: 1.1949, R: 0.0000)
Batch 4900/18276: Loss = 1.6754 (C: 1.6754, R: 0.0000)
Batch 5000/18276: Loss = 1.2074 (C: 1.2074, R: 0.0000)
Batch 5100/18276: Loss = 1.7051 (C: 1.7051, R: 0.0000)
Batch 5200/18276: Loss = 1.5314 (C: 1.5314, R: 0.0000)
Batch 5300/18276: Loss = 1.5980 (C: 1.5980, R: 0.0000)
Batch 5400/18276: Loss = 1.4194 (C: 1.4194, R: 0.0000)
Batch 5500/18276: Loss = 1.5518 (C: 1.5518, R: 0.0000)
Batch 5600/18276: Loss = 1.4084 (C: 1.4084, R: 0.0000)
Batch 5700/18276: Loss = 1.2298 (C: 1.2298, R: 0.0000)
Batch 5800/18276: Loss = 1.8256 (C: 1.8256, R: 0.0000)
Batch 5900/18276: Loss = 1.5685 (C: 1.5685, R: 0.0000)
Batch 6000/18276: Loss = 1.6980 (C: 1.6980, R: 0.0000)
Batch 6100/18276: Loss = 1.6995 (C: 1.6995, R: 0.0000)
Batch 6200/18276: Loss = 1.3519 (C: 1.3519, R: 0.0000)
Batch 6300/18276: Loss = 1.4019 (C: 1.4019, R: 0.0000)
Batch 6400/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 6500/18276: Loss = 1.8384 (C: 1.8384, R: 0.0000)
Batch 6600/18276: Loss = 1.1465 (C: 1.1465, R: 0.0000)
Batch 6700/18276: Loss = 1.2467 (C: 1.2467, R: 0.0000)
Batch 6800/18276: Loss = 0.8747 (C: 0.8747, R: 0.0000)
Batch 6900/18276: Loss = 1.4954 (C: 1.4954, R: 0.0000)
Batch 7000/18276: Loss = 1.9167 (C: 1.9167, R: 0.0000)
Batch 7100/18276: Loss = 1.5428 (C: 1.5428, R: 0.0000)
Batch 7200/18276: Loss = 1.7934 (C: 1.7934, R: 0.0000)
Batch 7300/18276: Loss = 1.5345 (C: 1.5345, R: 0.0000)
Batch 7400/18276: Loss = 1.4010 (C: 1.4010, R: 0.0000)
Batch 7500/18276: Loss = 1.5349 (C: 1.5349, R: 0.0000)
Batch 7600/18276: Loss = 1.7933 (C: 1.7933, R: 0.0000)
Batch 7700/18276: Loss = 1.4097 (C: 1.4097, R: 0.0000)
Batch 7800/18276: Loss = 1.4538 (C: 1.4538, R: 0.0000)
Batch 7900/18276: Loss = 1.5737 (C: 1.5737, R: 0.0000)
Batch 8000/18276: Loss = 1.4768 (C: 1.4768, R: 0.0000)
Batch 8100/18276: Loss = 1.5688 (C: 1.5688, R: 0.0000)
Batch 8200/18276: Loss = 1.3588 (C: 1.3588, R: 0.0000)
Batch 8300/18276: Loss = 1.2138 (C: 1.2138, R: 0.0000)
Batch 8400/18276: Loss = 1.8205 (C: 1.8205, R: 0.0000)
Batch 8500/18276: Loss = 1.5693 (C: 1.5693, R: 0.0000)
Batch 8600/18276: Loss = 1.3527 (C: 1.3527, R: 0.0000)
Batch 8700/18276: Loss = 1.5686 (C: 1.5686, R: 0.0000)
Batch 8800/18276: Loss = 1.4993 (C: 1.4993, R: 0.0000)
Batch 8900/18276: Loss = 1.3650 (C: 1.3650, R: 0.0000)
Batch 9000/18276: Loss = 1.4008 (C: 1.4008, R: 0.0000)
Batch 9100/18276: Loss = 1.0216 (C: 1.0216, R: 0.0000)
Batch 9200/18276: Loss = 1.5875 (C: 1.5875, R: 0.0000)
Batch 9300/18276: Loss = 1.3212 (C: 1.3212, R: 0.0000)
Batch 9400/18276: Loss = 1.5457 (C: 1.5457, R: 0.0000)
Batch 9500/18276: Loss = 1.4222 (C: 1.4222, R: 0.0000)
Batch 9600/18276: Loss = 1.2677 (C: 1.2677, R: 0.0000)
Batch 9700/18276: Loss = 1.4078 (C: 1.4078, R: 0.0000)
Batch 9800/18276: Loss = 1.2773 (C: 1.2773, R: 0.0000)
Batch 9900/18276: Loss = 1.5489 (C: 1.5489, R: 0.0000)
Batch 10000/18276: Loss = 1.2055 (C: 1.2055, R: 0.0000)
Batch 10100/18276: Loss = 1.4025 (C: 1.4025, R: 0.0000)
Batch 10200/18276: Loss = 1.4171 (C: 1.4171, R: 0.0000)
Batch 10300/18276: Loss = 1.1440 (C: 1.1440, R: 0.0000)
Batch 10400/18276: Loss = 1.2036 (C: 1.2036, R: 0.0000)
Batch 10500/18276: Loss = 1.5914 (C: 1.5914, R: 0.0000)
Batch 10600/18276: Loss = 1.8312 (C: 1.8312, R: 0.0000)
Batch 10700/18276: Loss = 1.4875 (C: 1.4875, R: 0.0000)
Batch 10800/18276: Loss = 1.0555 (C: 1.0555, R: 0.0000)
Batch 10900/18276: Loss = 1.2050 (C: 1.2050, R: 0.0000)
Batch 11000/18276: Loss = 1.3545 (C: 1.3545, R: 0.0000)
Batch 11100/18276: Loss = 1.9169 (C: 1.9169, R: 0.0000)
Batch 11200/18276: Loss = 1.8308 (C: 1.8308, R: 0.0000)
Batch 11300/18276: Loss = 1.4191 (C: 1.4191, R: 0.0000)
Batch 11400/18276: Loss = 1.8935 (C: 1.8935, R: 0.0000)
Batch 11500/18276: Loss = 1.5690 (C: 1.5690, R: 0.0000)
Batch 11600/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 11700/18276: Loss = 1.3447 (C: 1.3447, R: 0.0000)
Batch 11800/18276: Loss = 1.4193 (C: 1.4193, R: 0.0000)
Batch 11900/18276: Loss = 1.3958 (C: 1.3958, R: 0.0000)
Batch 12000/18276: Loss = 1.4188 (C: 1.4188, R: 0.0000)
Batch 12100/18276: Loss = 1.4293 (C: 1.4293, R: 0.0000)
Batch 12200/18276: Loss = 1.8812 (C: 1.8812, R: 0.0000)
Batch 12300/18276: Loss = 1.5794 (C: 1.5794, R: 0.0000)
Batch 12400/18276: Loss = 1.1626 (C: 1.1626, R: 0.0000)
Batch 12500/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 12600/18276: Loss = 1.4914 (C: 1.4914, R: 0.0000)
Batch 12700/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 12800/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 12900/18276: Loss = 1.0230 (C: 1.0230, R: 0.0000)
Batch 13000/18276: Loss = 1.4194 (C: 1.4194, R: 0.0000)
Batch 13100/18276: Loss = 1.3779 (C: 1.3779, R: 0.0000)
Batch 13200/18276: Loss = 1.1444 (C: 1.1444, R: 0.0000)
Batch 13300/18276: Loss = 1.4746 (C: 1.4746, R: 0.0000)
Batch 13400/18276: Loss = 1.7928 (C: 1.7928, R: 0.0000)
Batch 13500/18276: Loss = 1.8072 (C: 1.8072, R: 0.0000)
Batch 13600/18276: Loss = 1.7201 (C: 1.7201, R: 0.0000)
Batch 13700/18276: Loss = 1.5531 (C: 1.5531, R: 0.0000)
Batch 13800/18276: Loss = 0.9367 (C: 0.9367, R: 0.0000)
Batch 13900/18276: Loss = 1.4025 (C: 1.4025, R: 0.0000)
Batch 14000/18276: Loss = 1.8060 (C: 1.8060, R: 0.0000)
Batch 14100/18276: Loss = 1.4018 (C: 1.4018, R: 0.0000)
Batch 14200/18276: Loss = 1.3672 (C: 1.3672, R: 0.0000)
Batch 14300/18276: Loss = 1.6964 (C: 1.6964, R: 0.0000)
Batch 14400/18276: Loss = 1.5889 (C: 1.5889, R: 0.0000)
Batch 14500/18276: Loss = 0.9039 (C: 0.9039, R: 0.0000)
Batch 14600/18276: Loss = 1.0224 (C: 1.0224, R: 0.0000)
Batch 14700/18276: Loss = 1.2382 (C: 1.2382, R: 0.0000)
Batch 14800/18276: Loss = 1.4241 (C: 1.4241, R: 0.0000)
Batch 14900/18276: Loss = 1.6904 (C: 1.6904, R: 0.0000)
Batch 15000/18276: Loss = 1.3641 (C: 1.3641, R: 0.0000)
Batch 15100/18276: Loss = 1.5791 (C: 1.5791, R: 0.0000)
Batch 15200/18276: Loss = 1.5484 (C: 1.5484, R: 0.0000)
Batch 15300/18276: Loss = 1.4949 (C: 1.4949, R: 0.0000)
Batch 15400/18276: Loss = 1.0537 (C: 1.0537, R: 0.0000)
Batch 15500/18276: Loss = 1.2906 (C: 1.2906, R: 0.0000)
Batch 15600/18276: Loss = 1.4019 (C: 1.4019, R: 0.0000)
Batch 15700/18276: Loss = 1.1453 (C: 1.1453, R: 0.0000)
Batch 15800/18276: Loss = 0.9068 (C: 0.9068, R: 0.0000)
Batch 15900/18276: Loss = 1.8070 (C: 1.8070, R: 0.0000)
Batch 16000/18276: Loss = 1.7024 (C: 1.7024, R: 0.0000)
Batch 16100/18276: Loss = 1.7060 (C: 1.7060, R: 0.0000)
Batch 16200/18276: Loss = 1.4872 (C: 1.4872, R: 0.0000)
Batch 16300/18276: Loss = 1.7075 (C: 1.7075, R: 0.0000)
Batch 16400/18276: Loss = 1.5527 (C: 1.5527, R: 0.0000)
Batch 16500/18276: Loss = 1.4180 (C: 1.4180, R: 0.0000)
Batch 16600/18276: Loss = 1.5912 (C: 1.5912, R: 0.0000)
Batch 16700/18276: Loss = 1.3602 (C: 1.3602, R: 0.0000)
Batch 16800/18276: Loss = 1.7698 (C: 1.7698, R: 0.0000)
Batch 16900/18276: Loss = 1.1901 (C: 1.1901, R: 0.0000)
Batch 17000/18276: Loss = 1.0233 (C: 1.0233, R: 0.0000)
Batch 17100/18276: Loss = 1.5540 (C: 1.5540, R: 0.0000)
Batch 17200/18276: Loss = 1.4237 (C: 1.4237, R: 0.0000)
Batch 17300/18276: Loss = 1.4085 (C: 1.4085, R: 0.0000)
Batch 17400/18276: Loss = 1.8065 (C: 1.8065, R: 0.0000)
Batch 17500/18276: Loss = 1.4004 (C: 1.4004, R: 0.0000)
Batch 17600/18276: Loss = 1.2366 (C: 1.2366, R: 0.0000)
Batch 17700/18276: Loss = 1.5197 (C: 1.5197, R: 0.0000)
Batch 17800/18276: Loss = 1.4099 (C: 1.4099, R: 0.0000)
Batch 17900/18276: Loss = 1.3540 (C: 1.3540, R: 0.0000)
Batch 18000/18276: Loss = 1.1981 (C: 1.1981, R: 0.0000)
Batch 18100/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 18200/18276: Loss = 1.2949 (C: 1.2949, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.2368240356445312
  reconstruction_loss raw: 0.0
  total_loss raw: 1.2368240356445312
Epoch 15 completed in 70.17s
Train Loss: 1.4466 (C: 1.4466)
Val Loss: 1.4196 (C: 1.4196)
No improvement for 1 epochs
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/checkpoint_epoch_15.pt

Epoch 16/50
------------------------------
Batch 0/18276: Loss = 1.2049 (C: 1.2049, R: 0.0000)
Batch 100/18276: Loss = 1.4196 (C: 1.4196, R: 0.0000)
Batch 200/18276: Loss = 1.4639 (C: 1.4639, R: 0.0000)
Batch 300/18276: Loss = 1.7220 (C: 1.7220, R: 0.0000)
Batch 400/18276: Loss = 1.1440 (C: 1.1440, R: 0.0000)
Batch 500/18276: Loss = 1.5670 (C: 1.5670, R: 0.0000)
Batch 600/18276: Loss = 1.4409 (C: 1.4409, R: 0.0000)
Batch 700/18276: Loss = 1.4088 (C: 1.4088, R: 0.0000)
Batch 800/18276: Loss = 1.0763 (C: 1.0763, R: 0.0000)
Batch 900/18276: Loss = 1.4098 (C: 1.4098, R: 0.0000)
Batch 1000/18276: Loss = 1.4020 (C: 1.4020, R: 0.0000)
Batch 1100/18276: Loss = 1.4869 (C: 1.4869, R: 0.0000)
Batch 1200/18276: Loss = 1.7127 (C: 1.7127, R: 0.0000)
Batch 1300/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 1400/18276: Loss = 1.2082 (C: 1.2082, R: 0.0000)
Batch 1500/18276: Loss = 1.2110 (C: 1.2110, R: 0.0000)
Batch 1600/18276: Loss = 1.5352 (C: 1.5352, R: 0.0000)
Batch 1700/18276: Loss = 1.7095 (C: 1.7095, R: 0.0000)
Batch 1800/18276: Loss = 1.7407 (C: 1.7407, R: 0.0000)
Batch 1900/18276: Loss = 1.4604 (C: 1.4604, R: 0.0000)
Batch 2000/18276: Loss = 1.6977 (C: 1.6977, R: 0.0000)
Batch 2100/18276: Loss = 1.9209 (C: 1.9209, R: 0.0000)
Batch 2200/18276: Loss = 1.8266 (C: 1.8266, R: 0.0000)
Batch 2300/18276: Loss = 1.0225 (C: 1.0225, R: 0.0000)
Batch 2400/18276: Loss = 1.6647 (C: 1.6647, R: 0.0000)
Batch 2500/18276: Loss = 1.4078 (C: 1.4078, R: 0.0000)
Batch 2600/18276: Loss = 1.5387 (C: 1.5387, R: 0.0000)
Batch 2700/18276: Loss = 1.1518 (C: 1.1518, R: 0.0000)
Batch 2800/18276: Loss = 1.4097 (C: 1.4097, R: 0.0000)
Batch 2900/18276: Loss = 1.4013 (C: 1.4013, R: 0.0000)
Batch 3000/18276: Loss = 1.2921 (C: 1.2921, R: 0.0000)
Batch 3100/18276: Loss = 1.5077 (C: 1.5077, R: 0.0000)
Batch 3200/18276: Loss = 1.4875 (C: 1.4875, R: 0.0000)
Batch 3300/18276: Loss = 1.7082 (C: 1.7082, R: 0.0000)
Batch 3400/18276: Loss = 1.6923 (C: 1.6923, R: 0.0000)
Batch 3500/18276: Loss = 1.2058 (C: 1.2058, R: 0.0000)
Batch 3600/18276: Loss = 1.2099 (C: 1.2099, R: 0.0000)
Batch 3700/18276: Loss = 1.1444 (C: 1.1444, R: 0.0000)
Batch 3800/18276: Loss = 1.7231 (C: 1.7231, R: 0.0000)
Batch 3900/18276: Loss = 1.3975 (C: 1.3975, R: 0.0000)
Batch 4000/18276: Loss = 1.0243 (C: 1.0243, R: 0.0000)
Batch 4100/18276: Loss = 1.7196 (C: 1.7196, R: 0.0000)
Batch 4200/18276: Loss = 1.3978 (C: 1.3978, R: 0.0000)
Batch 4300/18276: Loss = 1.4072 (C: 1.4072, R: 0.0000)
Batch 4400/18276: Loss = 1.0377 (C: 1.0377, R: 0.0000)
Batch 4500/18276: Loss = 1.5729 (C: 1.5729, R: 0.0000)
Batch 4600/18276: Loss = 1.4875 (C: 1.4875, R: 0.0000)
Batch 4700/18276: Loss = 1.2515 (C: 1.2515, R: 0.0000)
Batch 4800/18276: Loss = 1.4022 (C: 1.4022, R: 0.0000)
Batch 4900/18276: Loss = 1.5973 (C: 1.5973, R: 0.0000)
Batch 5000/18276: Loss = 0.9780 (C: 0.9780, R: 0.0000)
Batch 5100/18276: Loss = 1.4194 (C: 1.4194, R: 0.0000)
Batch 5200/18276: Loss = 1.4239 (C: 1.4239, R: 0.0000)
Batch 5300/18276: Loss = 1.3974 (C: 1.3974, R: 0.0000)
Batch 5400/18276: Loss = 1.3547 (C: 1.3547, R: 0.0000)
Batch 5500/18276: Loss = 1.6640 (C: 1.6640, R: 0.0000)
Batch 5600/18276: Loss = 1.0018 (C: 1.0018, R: 0.0000)
Batch 5700/18276: Loss = 1.3646 (C: 1.3646, R: 0.0000)
Batch 5800/18276: Loss = 1.4208 (C: 1.4208, R: 0.0000)
Batch 5900/18276: Loss = 1.0372 (C: 1.0372, R: 0.0000)
Batch 6000/18276: Loss = 1.2359 (C: 1.2359, R: 0.0000)
Batch 6100/18276: Loss = 1.5481 (C: 1.5481, R: 0.0000)
Batch 6200/18276: Loss = 1.5809 (C: 1.5809, R: 0.0000)
Batch 6300/18276: Loss = 1.5767 (C: 1.5767, R: 0.0000)
Batch 6400/18276: Loss = 1.5474 (C: 1.5474, R: 0.0000)
Batch 6500/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 6600/18276: Loss = 1.7202 (C: 1.7202, R: 0.0000)
Batch 6700/18276: Loss = 1.7073 (C: 1.7073, R: 0.0000)
Batch 6800/18276: Loss = 1.7023 (C: 1.7023, R: 0.0000)
Batch 6900/18276: Loss = 1.1433 (C: 1.1433, R: 0.0000)
Batch 7000/18276: Loss = 1.2059 (C: 1.2059, R: 0.0000)
Batch 7100/18276: Loss = 1.7909 (C: 1.7909, R: 0.0000)
Batch 7200/18276: Loss = 1.3792 (C: 1.3792, R: 0.0000)
Batch 7300/18276: Loss = 1.0540 (C: 1.0540, R: 0.0000)
Batch 7400/18276: Loss = 1.9011 (C: 1.9011, R: 0.0000)
Batch 7500/18276: Loss = 1.4713 (C: 1.4713, R: 0.0000)
Batch 7600/18276: Loss = 1.5545 (C: 1.5545, R: 0.0000)
Batch 7700/18276: Loss = 0.9776 (C: 0.9776, R: 0.0000)
Batch 7800/18276: Loss = 1.4020 (C: 1.4020, R: 0.0000)
Batch 7900/18276: Loss = 1.4876 (C: 1.4876, R: 0.0000)
Batch 8000/18276: Loss = 1.3612 (C: 1.3612, R: 0.0000)
Batch 8100/18276: Loss = 1.9984 (C: 1.9984, R: 0.0000)
Batch 8200/18276: Loss = 1.4090 (C: 1.4090, R: 0.0000)
Batch 8300/18276: Loss = 1.9001 (C: 1.9001, R: 0.0000)
Batch 8400/18276: Loss = 1.5810 (C: 1.5810, R: 0.0000)
Batch 8500/18276: Loss = 1.5483 (C: 1.5483, R: 0.0000)
Batch 8600/18276: Loss = 1.4198 (C: 1.4198, R: 0.0000)
Batch 8700/18276: Loss = 1.4161 (C: 1.4161, R: 0.0000)
Batch 8800/18276: Loss = 1.3650 (C: 1.3650, R: 0.0000)
Batch 8900/18276: Loss = 1.5444 (C: 1.5444, R: 0.0000)
Batch 9000/18276: Loss = 1.0513 (C: 1.0513, R: 0.0000)
Batch 9100/18276: Loss = 0.9201 (C: 0.9201, R: 0.0000)
Batch 9200/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 9300/18276: Loss = 1.2043 (C: 1.2043, R: 0.0000)
Batch 9400/18276: Loss = 1.7085 (C: 1.7085, R: 0.0000)
Batch 9500/18276: Loss = 1.3543 (C: 1.3543, R: 0.0000)
Batch 9600/18276: Loss = 1.6654 (C: 1.6654, R: 0.0000)
Batch 9700/18276: Loss = 1.4237 (C: 1.4237, R: 0.0000)
Batch 9800/18276: Loss = 1.2079 (C: 1.2079, R: 0.0000)
Batch 9900/18276: Loss = 1.6713 (C: 1.6713, R: 0.0000)
Batch 10000/18276: Loss = 1.5579 (C: 1.5579, R: 0.0000)
Batch 10100/18276: Loss = 1.4106 (C: 1.4106, R: 0.0000)
Batch 10200/18276: Loss = 1.0643 (C: 1.0643, R: 0.0000)
Batch 10300/18276: Loss = 1.4713 (C: 1.4713, R: 0.0000)
Batch 10400/18276: Loss = 1.3627 (C: 1.3627, R: 0.0000)
Batch 10500/18276: Loss = 1.2095 (C: 1.2095, R: 0.0000)
Batch 10600/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 10700/18276: Loss = 1.5736 (C: 1.5736, R: 0.0000)
Batch 10800/18276: Loss = 1.2905 (C: 1.2905, R: 0.0000)
Batch 10900/18276: Loss = 1.2990 (C: 1.2990, R: 0.0000)
Batch 11000/18276: Loss = 1.4133 (C: 1.4133, R: 0.0000)
Batch 11100/18276: Loss = 1.7010 (C: 1.7010, R: 0.0000)
Batch 11200/18276: Loss = 1.2097 (C: 1.2097, R: 0.0000)
Batch 11300/18276: Loss = 1.4076 (C: 1.4076, R: 0.0000)
Batch 11400/18276: Loss = 1.4174 (C: 1.4174, R: 0.0000)
Batch 11500/18276: Loss = 1.4951 (C: 1.4951, R: 0.0000)
Batch 11600/18276: Loss = 1.8386 (C: 1.8386, R: 0.0000)
Batch 11700/18276: Loss = 1.5841 (C: 1.5841, R: 0.0000)
Batch 11800/18276: Loss = 1.8373 (C: 1.8373, R: 0.0000)
Batch 11900/18276: Loss = 1.1514 (C: 1.1514, R: 0.0000)
Batch 12000/18276: Loss = 1.5734 (C: 1.5734, R: 0.0000)
Batch 12100/18276: Loss = 1.8364 (C: 1.8364, R: 0.0000)
Batch 12200/18276: Loss = 1.4189 (C: 1.4189, R: 0.0000)
Batch 12300/18276: Loss = 1.5693 (C: 1.5693, R: 0.0000)
Batch 12400/18276: Loss = 1.2950 (C: 1.2950, R: 0.0000)
Batch 12500/18276: Loss = 1.4144 (C: 1.4144, R: 0.0000)
Batch 12600/18276: Loss = 1.0183 (C: 1.0183, R: 0.0000)
Batch 12700/18276: Loss = 1.5490 (C: 1.5490, R: 0.0000)
Batch 12800/18276: Loss = 1.4189 (C: 1.4189, R: 0.0000)
Batch 12900/18276: Loss = 1.4954 (C: 1.4954, R: 0.0000)
Batch 13000/18276: Loss = 1.4950 (C: 1.4950, R: 0.0000)
Batch 13100/18276: Loss = 1.7061 (C: 1.7061, R: 0.0000)
Batch 13200/18276: Loss = 1.7016 (C: 1.7016, R: 0.0000)
Batch 13300/18276: Loss = 1.6540 (C: 1.6540, R: 0.0000)
Batch 13400/18276: Loss = 1.5949 (C: 1.5949, R: 0.0000)
Batch 13500/18276: Loss = 1.4924 (C: 1.4924, R: 0.0000)
Batch 13600/18276: Loss = 1.5261 (C: 1.5261, R: 0.0000)
Batch 13700/18276: Loss = 1.7038 (C: 1.7038, R: 0.0000)
Batch 13800/18276: Loss = 1.6992 (C: 1.6992, R: 0.0000)
Batch 13900/18276: Loss = 1.2095 (C: 1.2095, R: 0.0000)
Batch 14000/18276: Loss = 1.0251 (C: 1.0251, R: 0.0000)
Batch 14100/18276: Loss = 1.5355 (C: 1.5355, R: 0.0000)
Batch 14200/18276: Loss = 1.4889 (C: 1.4889, R: 0.0000)
Batch 14300/18276: Loss = 1.5749 (C: 1.5749, R: 0.0000)
Batch 14400/18276: Loss = 1.0650 (C: 1.0650, R: 0.0000)
Batch 14500/18276: Loss = 1.1406 (C: 1.1406, R: 0.0000)
Batch 14600/18276: Loss = 1.7093 (C: 1.7093, R: 0.0000)
Batch 14700/18276: Loss = 1.2377 (C: 1.2377, R: 0.0000)
Batch 14800/18276: Loss = 1.7190 (C: 1.7190, R: 0.0000)
Batch 14900/18276: Loss = 1.4073 (C: 1.4073, R: 0.0000)
Batch 15000/18276: Loss = 1.3695 (C: 1.3695, R: 0.0000)
Batch 15100/18276: Loss = 1.5820 (C: 1.5820, R: 0.0000)
Batch 15200/18276: Loss = 1.1516 (C: 1.1516, R: 0.0000)
Batch 15300/18276: Loss = 1.5806 (C: 1.5806, R: 0.0000)
Batch 15400/18276: Loss = 1.3945 (C: 1.3945, R: 0.0000)
Batch 15500/18276: Loss = 1.1951 (C: 1.1951, R: 0.0000)
Batch 15600/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 15700/18276: Loss = 1.5994 (C: 1.5994, R: 0.0000)
Batch 15800/18276: Loss = 1.4413 (C: 1.4413, R: 0.0000)
Batch 15900/18276: Loss = 1.3639 (C: 1.3639, R: 0.0000)
Batch 16000/18276: Loss = 1.7097 (C: 1.7097, R: 0.0000)
Batch 16100/18276: Loss = 1.6979 (C: 1.6979, R: 0.0000)
Batch 16200/18276: Loss = 1.4073 (C: 1.4073, R: 0.0000)
Batch 16300/18276: Loss = 1.5523 (C: 1.5523, R: 0.0000)
Batch 16400/18276: Loss = 1.9552 (C: 1.9552, R: 0.0000)
Batch 16500/18276: Loss = 1.2483 (C: 1.2483, R: 0.0000)
Batch 16600/18276: Loss = 1.3385 (C: 1.3385, R: 0.0000)
Batch 16700/18276: Loss = 1.5812 (C: 1.5812, R: 0.0000)
Batch 16800/18276: Loss = 1.4009 (C: 1.4009, R: 0.0000)
Batch 16900/18276: Loss = 1.4203 (C: 1.4203, R: 0.0000)
Batch 17000/18276: Loss = 1.4239 (C: 1.4239, R: 0.0000)
Batch 17100/18276: Loss = 1.6087 (C: 1.6087, R: 0.0000)
Batch 17200/18276: Loss = 1.4098 (C: 1.4098, R: 0.0000)
Batch 17300/18276: Loss = 1.5788 (C: 1.5788, R: 0.0000)
Batch 17400/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 17500/18276: Loss = 1.0272 (C: 1.0272, R: 0.0000)
Batch 17600/18276: Loss = 1.6701 (C: 1.6701, R: 0.0000)
Batch 17700/18276: Loss = 1.9310 (C: 1.9310, R: 0.0000)
Batch 17800/18276: Loss = 1.7316 (C: 1.7316, R: 0.0000)
Batch 17900/18276: Loss = 1.5792 (C: 1.5792, R: 0.0000)
Batch 18000/18276: Loss = 1.4016 (C: 1.4016, R: 0.0000)
Batch 18100/18276: Loss = 1.2904 (C: 1.2904, R: 0.0000)
Batch 18200/18276: Loss = 1.5807 (C: 1.5807, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.622484564781189
  reconstruction_loss raw: 0.0
  total_loss raw: 1.622484564781189
Epoch 16 completed in 71.00s
Train Loss: 1.4433 (C: 1.4433)
Val Loss: 1.4228 (C: 1.4228)
No improvement for 2 epochs

Epoch 17/50
------------------------------
Batch 0/18276: Loss = 1.1440 (C: 1.1440, R: 0.0000)
Batch 100/18276: Loss = 1.4241 (C: 1.4241, R: 0.0000)
Batch 200/18276: Loss = 1.4235 (C: 1.4235, R: 0.0000)
Batch 300/18276: Loss = 1.7100 (C: 1.7100, R: 0.0000)
Batch 400/18276: Loss = 1.2359 (C: 1.2359, R: 0.0000)
Batch 500/18276: Loss = 0.8026 (C: 0.8026, R: 0.0000)
Batch 600/18276: Loss = 1.0380 (C: 1.0380, R: 0.0000)
Batch 700/18276: Loss = 1.8380 (C: 1.8380, R: 0.0000)
Batch 800/18276: Loss = 1.5412 (C: 1.5412, R: 0.0000)
Batch 900/18276: Loss = 1.4100 (C: 1.4100, R: 0.0000)
Batch 1000/18276: Loss = 1.4006 (C: 1.4006, R: 0.0000)
Batch 1100/18276: Loss = 1.2084 (C: 1.2084, R: 0.0000)
Batch 1200/18276: Loss = 1.6542 (C: 1.6542, R: 0.0000)
Batch 1300/18276: Loss = 0.9836 (C: 0.9836, R: 0.0000)
Batch 1400/18276: Loss = 1.4092 (C: 1.4092, R: 0.0000)
Batch 1500/18276: Loss = 1.4075 (C: 1.4075, R: 0.0000)
Batch 1600/18276: Loss = 1.7006 (C: 1.7006, R: 0.0000)
Batch 1700/18276: Loss = 1.0658 (C: 1.0658, R: 0.0000)
Batch 1800/18276: Loss = 1.1487 (C: 1.1487, R: 0.0000)
Batch 1900/18276: Loss = 1.7260 (C: 1.7260, R: 0.0000)
Batch 2000/18276: Loss = 1.5881 (C: 1.5881, R: 0.0000)
Batch 2100/18276: Loss = 1.6667 (C: 1.6667, R: 0.0000)
Batch 2200/18276: Loss = 1.3995 (C: 1.3995, R: 0.0000)
Batch 2300/18276: Loss = 1.7914 (C: 1.7914, R: 0.0000)
Batch 2400/18276: Loss = 1.7240 (C: 1.7240, R: 0.0000)
Batch 2500/18276: Loss = 1.2378 (C: 1.2378, R: 0.0000)
Batch 2600/18276: Loss = 1.5793 (C: 1.5793, R: 0.0000)
Batch 2700/18276: Loss = 1.1852 (C: 1.1852, R: 0.0000)
Batch 2800/18276: Loss = 1.3662 (C: 1.3662, R: 0.0000)
Batch 2900/18276: Loss = 1.0225 (C: 1.0225, R: 0.0000)
Batch 3000/18276: Loss = 1.5794 (C: 1.5794, R: 0.0000)
Batch 3100/18276: Loss = 1.6652 (C: 1.6652, R: 0.0000)
Batch 3200/18276: Loss = 1.4235 (C: 1.4235, R: 0.0000)
Batch 3300/18276: Loss = 1.7444 (C: 1.7444, R: 0.0000)
Batch 3400/18276: Loss = 1.7931 (C: 1.7931, R: 0.0000)
Batch 3500/18276: Loss = 1.8048 (C: 1.8048, R: 0.0000)
Batch 3600/18276: Loss = 1.7087 (C: 1.7087, R: 0.0000)
Batch 3700/18276: Loss = 1.3541 (C: 1.3541, R: 0.0000)
Batch 3800/18276: Loss = 0.9815 (C: 0.9815, R: 0.0000)
Batch 3900/18276: Loss = 1.2954 (C: 1.2954, R: 0.0000)
Batch 4000/18276: Loss = 1.2363 (C: 1.2363, R: 0.0000)
Batch 4100/18276: Loss = 0.9774 (C: 0.9774, R: 0.0000)
Batch 4200/18276: Loss = 1.2357 (C: 1.2357, R: 0.0000)
Batch 4300/18276: Loss = 1.5795 (C: 1.5795, R: 0.0000)
Batch 4400/18276: Loss = 1.4018 (C: 1.4018, R: 0.0000)
Batch 4500/18276: Loss = 1.7191 (C: 1.7191, R: 0.0000)
Batch 4600/18276: Loss = 1.5831 (C: 1.5831, R: 0.0000)
Batch 4700/18276: Loss = 1.2962 (C: 1.2962, R: 0.0000)
Batch 4800/18276: Loss = 1.1944 (C: 1.1944, R: 0.0000)
Batch 4900/18276: Loss = 1.5725 (C: 1.5725, R: 0.0000)
Batch 5000/18276: Loss = 1.2051 (C: 1.2051, R: 0.0000)
Batch 5100/18276: Loss = 1.7023 (C: 1.7023, R: 0.0000)
Batch 5200/18276: Loss = 1.6982 (C: 1.6982, R: 0.0000)
Batch 5300/18276: Loss = 1.6812 (C: 1.6812, R: 0.0000)
Batch 5400/18276: Loss = 1.6643 (C: 1.6643, R: 0.0000)
Batch 5500/18276: Loss = 1.3547 (C: 1.3547, R: 0.0000)
Batch 5600/18276: Loss = 1.5698 (C: 1.5698, R: 0.0000)
Batch 5700/18276: Loss = 1.7098 (C: 1.7098, R: 0.0000)
Batch 5800/18276: Loss = 1.4073 (C: 1.4073, R: 0.0000)
Batch 5900/18276: Loss = 1.1446 (C: 1.1446, R: 0.0000)
Batch 6000/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 6100/18276: Loss = 1.4906 (C: 1.4906, R: 0.0000)
Batch 6200/18276: Loss = 1.7178 (C: 1.7178, R: 0.0000)
Batch 6300/18276: Loss = 1.0903 (C: 1.0903, R: 0.0000)
Batch 6400/18276: Loss = 1.6652 (C: 1.6652, R: 0.0000)
Batch 6500/18276: Loss = 1.6858 (C: 1.6858, R: 0.0000)
Batch 6600/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 6700/18276: Loss = 1.6954 (C: 1.6954, R: 0.0000)
Batch 6800/18276: Loss = 1.3010 (C: 1.3010, R: 0.0000)
Batch 6900/18276: Loss = 1.5801 (C: 1.5801, R: 0.0000)
Batch 7000/18276: Loss = 0.9045 (C: 0.9045, R: 0.0000)
Batch 7100/18276: Loss = 1.5734 (C: 1.5734, R: 0.0000)
Batch 7200/18276: Loss = 1.9872 (C: 1.9872, R: 0.0000)
Batch 7300/18276: Loss = 1.4027 (C: 1.4027, R: 0.0000)
Batch 7400/18276: Loss = 1.3641 (C: 1.3641, R: 0.0000)
Batch 7500/18276: Loss = 1.6215 (C: 1.6215, R: 0.0000)
Batch 7600/18276: Loss = 1.7063 (C: 1.7063, R: 0.0000)
Batch 7700/18276: Loss = 1.3867 (C: 1.3867, R: 0.0000)
Batch 7800/18276: Loss = 1.4078 (C: 1.4078, R: 0.0000)
Batch 7900/18276: Loss = 1.2775 (C: 1.2775, R: 0.0000)
Batch 8000/18276: Loss = 1.3543 (C: 1.3543, R: 0.0000)
Batch 8100/18276: Loss = 1.5691 (C: 1.5691, R: 0.0000)
Batch 8200/18276: Loss = 1.7512 (C: 1.7512, R: 0.0000)
Batch 8300/18276: Loss = 1.4015 (C: 1.4015, R: 0.0000)
Batch 8400/18276: Loss = 1.4090 (C: 1.4090, R: 0.0000)
Batch 8500/18276: Loss = 1.4163 (C: 1.4163, R: 0.0000)
Batch 8600/18276: Loss = 1.5915 (C: 1.5915, R: 0.0000)
Batch 8700/18276: Loss = 1.2772 (C: 1.2772, R: 0.0000)
Batch 8800/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 8900/18276: Loss = 0.9073 (C: 0.9073, R: 0.0000)
Batch 9000/18276: Loss = 0.9782 (C: 0.9782, R: 0.0000)
Batch 9100/18276: Loss = 1.8060 (C: 1.8060, R: 0.0000)
Batch 9200/18276: Loss = 1.3664 (C: 1.3664, R: 0.0000)
Batch 9300/18276: Loss = 1.8103 (C: 1.8103, R: 0.0000)
Batch 9400/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 9500/18276: Loss = 1.0235 (C: 1.0235, R: 0.0000)
Batch 9600/18276: Loss = 1.6169 (C: 1.6169, R: 0.0000)
Batch 9700/18276: Loss = 1.2047 (C: 1.2047, R: 0.0000)
Batch 9800/18276: Loss = 2.0091 (C: 2.0091, R: 0.0000)
Batch 9900/18276: Loss = 1.3661 (C: 1.3661, R: 0.0000)
Batch 10000/18276: Loss = 1.7110 (C: 1.7110, R: 0.0000)
Batch 10100/18276: Loss = 1.4193 (C: 1.4193, R: 0.0000)
Batch 10200/18276: Loss = 1.5731 (C: 1.5731, R: 0.0000)
Batch 10300/18276: Loss = 1.7066 (C: 1.7066, R: 0.0000)
Batch 10400/18276: Loss = 1.6591 (C: 1.6591, R: 0.0000)
Batch 10500/18276: Loss = 1.1547 (C: 1.1547, R: 0.0000)
Batch 10600/18276: Loss = 1.5496 (C: 1.5496, R: 0.0000)
Batch 10700/18276: Loss = 1.3543 (C: 1.3543, R: 0.0000)
Batch 10800/18276: Loss = 1.0330 (C: 1.0330, R: 0.0000)
Batch 10900/18276: Loss = 1.4095 (C: 1.4095, R: 0.0000)
Batch 11000/18276: Loss = 1.7014 (C: 1.7014, R: 0.0000)
Batch 11100/18276: Loss = 0.9470 (C: 0.9470, R: 0.0000)
Batch 11200/18276: Loss = 1.5761 (C: 1.5761, R: 0.0000)
Batch 11300/18276: Loss = 1.4274 (C: 1.4274, R: 0.0000)
Batch 11400/18276: Loss = 1.3652 (C: 1.3652, R: 0.0000)
Batch 11500/18276: Loss = 1.3889 (C: 1.3889, R: 0.0000)
Batch 11600/18276: Loss = 1.7096 (C: 1.7096, R: 0.0000)
Batch 11700/18276: Loss = 1.6978 (C: 1.6978, R: 0.0000)
Batch 11800/18276: Loss = 1.5532 (C: 1.5532, R: 0.0000)
Batch 11900/18276: Loss = 1.4191 (C: 1.4191, R: 0.0000)
Batch 12000/18276: Loss = 1.5734 (C: 1.5734, R: 0.0000)
Batch 12100/18276: Loss = 1.2632 (C: 1.2632, R: 0.0000)
Batch 12200/18276: Loss = 0.9775 (C: 0.9775, R: 0.0000)
Batch 12300/18276: Loss = 1.4880 (C: 1.4880, R: 0.0000)
Batch 12400/18276: Loss = 1.0240 (C: 1.0240, R: 0.0000)
Batch 12500/18276: Loss = 1.7238 (C: 1.7238, R: 0.0000)
Batch 12600/18276: Loss = 1.3644 (C: 1.3644, R: 0.0000)
Batch 12700/18276: Loss = 1.3551 (C: 1.3551, R: 0.0000)
Batch 12800/18276: Loss = 1.4211 (C: 1.4211, R: 0.0000)
Batch 12900/18276: Loss = 1.2087 (C: 1.2087, R: 0.0000)
Batch 13000/18276: Loss = 1.2374 (C: 1.2374, R: 0.0000)
Batch 13100/18276: Loss = 1.1535 (C: 1.1535, R: 0.0000)
Batch 13200/18276: Loss = 1.2360 (C: 1.2360, R: 0.0000)
Batch 13300/18276: Loss = 1.5814 (C: 1.5814, R: 0.0000)
Batch 13400/18276: Loss = 1.2374 (C: 1.2374, R: 0.0000)
Batch 13500/18276: Loss = 1.5023 (C: 1.5023, R: 0.0000)
Batch 13600/18276: Loss = 1.4266 (C: 1.4266, R: 0.0000)
Batch 13700/18276: Loss = 1.9776 (C: 1.9776, R: 0.0000)
Batch 13800/18276: Loss = 1.5526 (C: 1.5526, R: 0.0000)
Batch 13900/18276: Loss = 1.7023 (C: 1.7023, R: 0.0000)
Batch 14000/18276: Loss = 1.5523 (C: 1.5523, R: 0.0000)
Batch 14100/18276: Loss = 1.5696 (C: 1.5696, R: 0.0000)
Batch 14200/18276: Loss = 1.5688 (C: 1.5688, R: 0.0000)
Batch 14300/18276: Loss = 1.7771 (C: 1.7771, R: 0.0000)
Batch 14400/18276: Loss = 1.7923 (C: 1.7923, R: 0.0000)
Batch 14500/18276: Loss = 1.7081 (C: 1.7081, R: 0.0000)
Batch 14600/18276: Loss = 1.5763 (C: 1.5763, R: 0.0000)
Batch 14700/18276: Loss = 1.8042 (C: 1.8042, R: 0.0000)
Batch 14800/18276: Loss = 1.3984 (C: 1.3984, R: 0.0000)
Batch 14900/18276: Loss = 1.4102 (C: 1.4102, R: 0.0000)
Batch 15000/18276: Loss = 1.4116 (C: 1.4116, R: 0.0000)
Batch 15100/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 15200/18276: Loss = 1.3780 (C: 1.3780, R: 0.0000)
Batch 15300/18276: Loss = 1.7926 (C: 1.7926, R: 0.0000)
Batch 15400/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 15500/18276: Loss = 1.4048 (C: 1.4048, R: 0.0000)
Batch 15600/18276: Loss = 1.5535 (C: 1.5535, R: 0.0000)
Batch 15700/18276: Loss = 1.6548 (C: 1.6548, R: 0.0000)
Batch 15800/18276: Loss = 1.5690 (C: 1.5690, R: 0.0000)
Batch 15900/18276: Loss = 0.9480 (C: 0.9480, R: 0.0000)
Batch 16000/18276: Loss = 0.9338 (C: 0.9338, R: 0.0000)
Batch 16100/18276: Loss = 1.7111 (C: 1.7111, R: 0.0000)
Batch 16200/18276: Loss = 1.1395 (C: 1.1395, R: 0.0000)
Batch 16300/18276: Loss = 1.2923 (C: 1.2923, R: 0.0000)
Batch 16400/18276: Loss = 1.5807 (C: 1.5807, R: 0.0000)
Batch 16500/18276: Loss = 1.0236 (C: 1.0236, R: 0.0000)
Batch 16600/18276: Loss = 0.8158 (C: 0.8158, R: 0.0000)
Batch 16700/18276: Loss = 1.4303 (C: 1.4303, R: 0.0000)
Batch 16800/18276: Loss = 1.7704 (C: 1.7704, R: 0.0000)
Batch 16900/18276: Loss = 1.8309 (C: 1.8309, R: 0.0000)
Batch 17000/18276: Loss = 1.6167 (C: 1.6167, R: 0.0000)
Batch 17100/18276: Loss = 1.3537 (C: 1.3537, R: 0.0000)
Batch 17200/18276: Loss = 1.4334 (C: 1.4334, R: 0.0000)
Batch 17300/18276: Loss = 1.3547 (C: 1.3547, R: 0.0000)
Batch 17400/18276: Loss = 2.0086 (C: 2.0086, R: 0.0000)
Batch 17500/18276: Loss = 1.4214 (C: 1.4214, R: 0.0000)
Batch 17600/18276: Loss = 1.4736 (C: 1.4736, R: 0.0000)
Batch 17700/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 17800/18276: Loss = 1.2091 (C: 1.2091, R: 0.0000)
Batch 17900/18276: Loss = 1.4172 (C: 1.4172, R: 0.0000)
Batch 18000/18276: Loss = 1.5809 (C: 1.5809, R: 0.0000)
Batch 18100/18276: Loss = 1.1532 (C: 1.1532, R: 0.0000)
Batch 18200/18276: Loss = 1.8786 (C: 1.8786, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.5012977123260498
  reconstruction_loss raw: 0.0
  total_loss raw: 1.5012977123260498
Epoch 17 completed in 72.67s
Train Loss: 1.4417 (C: 1.4417)
Val Loss: 1.4286 (C: 1.4286)
No improvement for 3 epochs

Epoch 18/50
------------------------------
Batch 0/18276: Loss = 1.1520 (C: 1.1520, R: 0.0000)
Batch 100/18276: Loss = 1.9747 (C: 1.9747, R: 0.0000)
Batch 200/18276: Loss = 1.4920 (C: 1.4920, R: 0.0000)
Batch 300/18276: Loss = 1.5736 (C: 1.5736, R: 0.0000)
Batch 400/18276: Loss = 1.6987 (C: 1.6987, R: 0.0000)
Batch 500/18276: Loss = 0.9125 (C: 0.9125, R: 0.0000)
Batch 600/18276: Loss = 1.3502 (C: 1.3502, R: 0.0000)
Batch 700/18276: Loss = 1.5590 (C: 1.5590, R: 0.0000)
Batch 800/18276: Loss = 1.5640 (C: 1.5640, R: 0.0000)
Batch 900/18276: Loss = 1.4888 (C: 1.4888, R: 0.0000)
Batch 1000/18276: Loss = 1.4010 (C: 1.4010, R: 0.0000)
Batch 1100/18276: Loss = 1.1516 (C: 1.1516, R: 0.0000)
Batch 1200/18276: Loss = 0.9787 (C: 0.9787, R: 0.0000)
Batch 1300/18276: Loss = 1.8066 (C: 1.8066, R: 0.0000)
Batch 1400/18276: Loss = 1.2908 (C: 1.2908, R: 0.0000)
Batch 1500/18276: Loss = 1.3543 (C: 1.3543, R: 0.0000)
Batch 1600/18276: Loss = 1.9009 (C: 1.9009, R: 0.0000)
Batch 1700/18276: Loss = 1.4716 (C: 1.4716, R: 0.0000)
Batch 1800/18276: Loss = 1.7089 (C: 1.7089, R: 0.0000)
Batch 1900/18276: Loss = 1.2593 (C: 1.2593, R: 0.0000)
Batch 2000/18276: Loss = 0.9072 (C: 0.9072, R: 0.0000)
Batch 2100/18276: Loss = 1.7416 (C: 1.7416, R: 0.0000)
Batch 2200/18276: Loss = 1.4089 (C: 1.4089, R: 0.0000)
Batch 2300/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 2400/18276: Loss = 1.5689 (C: 1.5689, R: 0.0000)
Batch 2500/18276: Loss = 1.0536 (C: 1.0536, R: 0.0000)
Batch 2600/18276: Loss = 1.5690 (C: 1.5690, R: 0.0000)
Batch 2700/18276: Loss = 1.4076 (C: 1.4076, R: 0.0000)
Batch 2800/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 2900/18276: Loss = 1.7025 (C: 1.7025, R: 0.0000)
Batch 3000/18276: Loss = 1.2373 (C: 1.2373, R: 0.0000)
Batch 3100/18276: Loss = 1.5708 (C: 1.5708, R: 0.0000)
Batch 3200/18276: Loss = 1.2907 (C: 1.2907, R: 0.0000)
Batch 3300/18276: Loss = 1.2046 (C: 1.2046, R: 0.0000)
Batch 3400/18276: Loss = 0.9781 (C: 0.9781, R: 0.0000)
Batch 3500/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 3600/18276: Loss = 1.6356 (C: 1.6356, R: 0.0000)
Batch 3700/18276: Loss = 1.3541 (C: 1.3541, R: 0.0000)
Batch 3800/18276: Loss = 1.4727 (C: 1.4727, R: 0.0000)
Batch 3900/18276: Loss = 1.4934 (C: 1.4934, R: 0.0000)
Batch 4000/18276: Loss = 1.5686 (C: 1.5686, R: 0.0000)
Batch 4100/18276: Loss = 1.5491 (C: 1.5491, R: 0.0000)
Batch 4200/18276: Loss = 1.0640 (C: 1.0640, R: 0.0000)
Batch 4300/18276: Loss = 1.4184 (C: 1.4184, R: 0.0000)
Batch 4400/18276: Loss = 1.5512 (C: 1.5512, R: 0.0000)
Batch 4500/18276: Loss = 1.4215 (C: 1.4215, R: 0.0000)
Batch 4600/18276: Loss = 1.4089 (C: 1.4089, R: 0.0000)
Batch 4700/18276: Loss = 1.2054 (C: 1.2054, R: 0.0000)
Batch 4800/18276: Loss = 1.4269 (C: 1.4269, R: 0.0000)
Batch 4900/18276: Loss = 1.8146 (C: 1.8146, R: 0.0000)
Batch 5000/18276: Loss = 1.7089 (C: 1.7089, R: 0.0000)
Batch 5100/18276: Loss = 0.9358 (C: 0.9358, R: 0.0000)
Batch 5200/18276: Loss = 1.4588 (C: 1.4588, R: 0.0000)
Batch 5300/18276: Loss = 1.4881 (C: 1.4881, R: 0.0000)
Batch 5400/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 5500/18276: Loss = 1.2373 (C: 1.2373, R: 0.0000)
Batch 5600/18276: Loss = 1.7777 (C: 1.7777, R: 0.0000)
Batch 5700/18276: Loss = 1.5624 (C: 1.5624, R: 0.0000)
Batch 5800/18276: Loss = 1.1196 (C: 1.1196, R: 0.0000)
Batch 5900/18276: Loss = 1.7166 (C: 1.7166, R: 0.0000)
Batch 6000/18276: Loss = 1.3636 (C: 1.3636, R: 0.0000)
Batch 6100/18276: Loss = 1.5808 (C: 1.5808, R: 0.0000)
Batch 6200/18276: Loss = 1.5810 (C: 1.5810, R: 0.0000)
Batch 6300/18276: Loss = 1.7083 (C: 1.7083, R: 0.0000)
Batch 6400/18276: Loss = 1.4894 (C: 1.4894, R: 0.0000)
Batch 6500/18276: Loss = 0.9863 (C: 0.9863, R: 0.0000)
Batch 6600/18276: Loss = 1.1125 (C: 1.1125, R: 0.0000)
Batch 6700/18276: Loss = 1.4004 (C: 1.4004, R: 0.0000)
Batch 6800/18276: Loss = 1.5797 (C: 1.5797, R: 0.0000)
Batch 6900/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 7000/18276: Loss = 1.4874 (C: 1.4874, R: 0.0000)
Batch 7100/18276: Loss = 0.9790 (C: 0.9790, R: 0.0000)
Batch 7200/18276: Loss = 1.5734 (C: 1.5734, R: 0.0000)
Batch 7300/18276: Loss = 1.2044 (C: 1.2044, R: 0.0000)
Batch 7400/18276: Loss = 1.3665 (C: 1.3665, R: 0.0000)
Batch 7500/18276: Loss = 1.5493 (C: 1.5493, R: 0.0000)
Batch 7600/18276: Loss = 1.4197 (C: 1.4197, R: 0.0000)
Batch 7700/18276: Loss = 1.4210 (C: 1.4210, R: 0.0000)
Batch 7800/18276: Loss = 1.4331 (C: 1.4331, R: 0.0000)
Batch 7900/18276: Loss = 1.3647 (C: 1.3647, R: 0.0000)
Batch 8000/18276: Loss = 1.8365 (C: 1.8365, R: 0.0000)
Batch 8100/18276: Loss = 0.9601 (C: 0.9601, R: 0.0000)
Batch 8200/18276: Loss = 1.7168 (C: 1.7168, R: 0.0000)
Batch 8300/18276: Loss = 1.7416 (C: 1.7416, R: 0.0000)
Batch 8400/18276: Loss = 1.2055 (C: 1.2055, R: 0.0000)
Batch 8500/18276: Loss = 1.5791 (C: 1.5791, R: 0.0000)
Batch 8600/18276: Loss = 1.3656 (C: 1.3656, R: 0.0000)
Batch 8700/18276: Loss = 1.2670 (C: 1.2670, R: 0.0000)
Batch 8800/18276: Loss = 1.8259 (C: 1.8259, R: 0.0000)
Batch 8900/18276: Loss = 1.4719 (C: 1.4719, R: 0.0000)
Batch 9000/18276: Loss = 1.4946 (C: 1.4946, R: 0.0000)
Batch 9100/18276: Loss = 1.4934 (C: 1.4934, R: 0.0000)
Batch 9200/18276: Loss = 1.7066 (C: 1.7066, R: 0.0000)
Batch 9300/18276: Loss = 1.4123 (C: 1.4123, R: 0.0000)
Batch 9400/18276: Loss = 1.7027 (C: 1.7027, R: 0.0000)
Batch 9500/18276: Loss = 1.5960 (C: 1.5960, R: 0.0000)
Batch 9600/18276: Loss = 1.4862 (C: 1.4862, R: 0.0000)
Batch 9700/18276: Loss = 1.5785 (C: 1.5785, R: 0.0000)
Batch 9800/18276: Loss = 0.9341 (C: 0.9341, R: 0.0000)
Batch 9900/18276: Loss = 1.6910 (C: 1.6910, R: 0.0000)
Batch 10000/18276: Loss = 1.3556 (C: 1.3556, R: 0.0000)
Batch 10100/18276: Loss = 1.5533 (C: 1.5533, R: 0.0000)
Batch 10200/18276: Loss = 1.2856 (C: 1.2856, R: 0.0000)
Batch 10300/18276: Loss = 1.5490 (C: 1.5490, R: 0.0000)
Batch 10400/18276: Loss = 1.7378 (C: 1.7378, R: 0.0000)
Batch 10500/18276: Loss = 1.3552 (C: 1.3552, R: 0.0000)
Batch 10600/18276: Loss = 1.2538 (C: 1.2538, R: 0.0000)
Batch 10700/18276: Loss = 1.2908 (C: 1.2908, R: 0.0000)
Batch 10800/18276: Loss = 1.2949 (C: 1.2949, R: 0.0000)
Batch 10900/18276: Loss = 1.4940 (C: 1.4940, R: 0.0000)
Batch 11000/18276: Loss = 1.4020 (C: 1.4020, R: 0.0000)
Batch 11100/18276: Loss = 1.2385 (C: 1.2385, R: 0.0000)
Batch 11200/18276: Loss = 1.2227 (C: 1.2227, R: 0.0000)
Batch 11300/18276: Loss = 1.7122 (C: 1.7122, R: 0.0000)
Batch 11400/18276: Loss = 1.2356 (C: 1.2356, R: 0.0000)
Batch 11500/18276: Loss = 1.7098 (C: 1.7098, R: 0.0000)
Batch 11600/18276: Loss = 1.1948 (C: 1.1948, R: 0.0000)
Batch 11700/18276: Loss = 1.4252 (C: 1.4252, R: 0.0000)
Batch 11800/18276: Loss = 1.5528 (C: 1.5528, R: 0.0000)
Batch 11900/18276: Loss = 1.1514 (C: 1.1514, R: 0.0000)
Batch 12000/18276: Loss = 1.2061 (C: 1.2061, R: 0.0000)
Batch 12100/18276: Loss = 0.8006 (C: 0.8006, R: 0.0000)
Batch 12200/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 12300/18276: Loss = 1.6644 (C: 1.6644, R: 0.0000)
Batch 12400/18276: Loss = 1.5496 (C: 1.5496, R: 0.0000)
Batch 12500/18276: Loss = 1.5731 (C: 1.5731, R: 0.0000)
Batch 12600/18276: Loss = 1.0644 (C: 1.0644, R: 0.0000)
Batch 12700/18276: Loss = 1.3740 (C: 1.3740, R: 0.0000)
Batch 12800/18276: Loss = 1.0418 (C: 1.0418, R: 0.0000)
Batch 12900/18276: Loss = 0.9802 (C: 0.9802, R: 0.0000)
Batch 13000/18276: Loss = 1.4875 (C: 1.4875, R: 0.0000)
Batch 13100/18276: Loss = 1.4089 (C: 1.4089, R: 0.0000)
Batch 13200/18276: Loss = 1.4930 (C: 1.4930, R: 0.0000)
Batch 13300/18276: Loss = 1.7034 (C: 1.7034, R: 0.0000)
Batch 13400/18276: Loss = 1.6089 (C: 1.6089, R: 0.0000)
Batch 13500/18276: Loss = 1.8824 (C: 1.8824, R: 0.0000)
Batch 13600/18276: Loss = 1.0235 (C: 1.0235, R: 0.0000)
Batch 13700/18276: Loss = 1.5857 (C: 1.5857, R: 0.0000)
Batch 13800/18276: Loss = 1.2103 (C: 1.2103, R: 0.0000)
Batch 13900/18276: Loss = 1.1920 (C: 1.1920, R: 0.0000)
Batch 14000/18276: Loss = 1.7926 (C: 1.7926, R: 0.0000)
Batch 14100/18276: Loss = 1.5686 (C: 1.5686, R: 0.0000)
Batch 14200/18276: Loss = 1.5824 (C: 1.5824, R: 0.0000)
Batch 14300/18276: Loss = 1.3673 (C: 1.3673, R: 0.0000)
Batch 14400/18276: Loss = 1.4076 (C: 1.4076, R: 0.0000)
Batch 14500/18276: Loss = 1.8348 (C: 1.8348, R: 0.0000)
Batch 14600/18276: Loss = 1.2016 (C: 1.2016, R: 0.0000)
Batch 14700/18276: Loss = 1.7109 (C: 1.7109, R: 0.0000)
Batch 14800/18276: Loss = 1.2423 (C: 1.2423, R: 0.0000)
Batch 14900/18276: Loss = 1.8196 (C: 1.8196, R: 0.0000)
Batch 15000/18276: Loss = 1.5713 (C: 1.5713, R: 0.0000)
Batch 15100/18276: Loss = 1.1457 (C: 1.1457, R: 0.0000)
Batch 15200/18276: Loss = 1.5811 (C: 1.5811, R: 0.0000)
Batch 15300/18276: Loss = 1.5764 (C: 1.5764, R: 0.0000)
Batch 15400/18276: Loss = 1.4309 (C: 1.4309, R: 0.0000)
Batch 15500/18276: Loss = 1.6960 (C: 1.6960, R: 0.0000)
Batch 15600/18276: Loss = 1.4213 (C: 1.4213, R: 0.0000)
Batch 15700/18276: Loss = 1.1727 (C: 1.1727, R: 0.0000)
Batch 15800/18276: Loss = 1.0228 (C: 1.0228, R: 0.0000)
Batch 15900/18276: Loss = 1.7198 (C: 1.7198, R: 0.0000)
Batch 16000/18276: Loss = 1.8062 (C: 1.8062, R: 0.0000)
Batch 16100/18276: Loss = 1.7067 (C: 1.7067, R: 0.0000)
Batch 16200/18276: Loss = 1.6861 (C: 1.6861, R: 0.0000)
Batch 16300/18276: Loss = 1.4723 (C: 1.4723, R: 0.0000)
Batch 16400/18276: Loss = 1.5810 (C: 1.5810, R: 0.0000)
Batch 16500/18276: Loss = 1.7075 (C: 1.7075, R: 0.0000)
Batch 16600/18276: Loss = 1.5475 (C: 1.5475, R: 0.0000)
Batch 16700/18276: Loss = 1.5740 (C: 1.5740, R: 0.0000)
Batch 16800/18276: Loss = 1.4065 (C: 1.4065, R: 0.0000)
Batch 16900/18276: Loss = 1.4194 (C: 1.4194, R: 0.0000)
Batch 17000/18276: Loss = 1.5626 (C: 1.5626, R: 0.0000)
Batch 17100/18276: Loss = 1.6591 (C: 1.6591, R: 0.0000)
Batch 17200/18276: Loss = 1.4583 (C: 1.4583, R: 0.0000)
Batch 17300/18276: Loss = 1.2094 (C: 1.2094, R: 0.0000)
Batch 17400/18276: Loss = 1.5633 (C: 1.5633, R: 0.0000)
Batch 17500/18276: Loss = 1.3374 (C: 1.3374, R: 0.0000)
Batch 17600/18276: Loss = 1.7018 (C: 1.7018, R: 0.0000)
Batch 17700/18276: Loss = 1.2384 (C: 1.2384, R: 0.0000)
Batch 17800/18276: Loss = 1.6587 (C: 1.6587, R: 0.0000)
Batch 17900/18276: Loss = 1.4193 (C: 1.4193, R: 0.0000)
Batch 18000/18276: Loss = 1.4825 (C: 1.4825, R: 0.0000)
Batch 18100/18276: Loss = 1.3652 (C: 1.3652, R: 0.0000)
Batch 18200/18276: Loss = 1.0698 (C: 1.0698, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.552614450454712
  reconstruction_loss raw: 0.0
  total_loss raw: 1.552614450454712
Epoch 18 completed in 72.42s
Train Loss: 1.4440 (C: 1.4440)
Val Loss: 1.4443 (C: 1.4443)
No improvement for 4 epochs

Epoch 19/50
------------------------------
Batch 0/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 100/18276: Loss = 1.5731 (C: 1.5731, R: 0.0000)
Batch 200/18276: Loss = 1.2381 (C: 1.2381, R: 0.0000)
Batch 300/18276: Loss = 1.7928 (C: 1.7928, R: 0.0000)
Batch 400/18276: Loss = 1.2956 (C: 1.2956, R: 0.0000)
Batch 500/18276: Loss = 1.5353 (C: 1.5353, R: 0.0000)
Batch 600/18276: Loss = 1.5485 (C: 1.5485, R: 0.0000)
Batch 700/18276: Loss = 1.2036 (C: 1.2036, R: 0.0000)
Batch 800/18276: Loss = 1.7193 (C: 1.7193, R: 0.0000)
Batch 900/18276: Loss = 1.7145 (C: 1.7145, R: 0.0000)
Batch 1000/18276: Loss = 1.4951 (C: 1.4951, R: 0.0000)
Batch 1100/18276: Loss = 1.7082 (C: 1.7082, R: 0.0000)
Batch 1200/18276: Loss = 1.1530 (C: 1.1530, R: 0.0000)
Batch 1300/18276: Loss = 1.6998 (C: 1.6998, R: 0.0000)
Batch 1400/18276: Loss = 1.3375 (C: 1.3375, R: 0.0000)
Batch 1500/18276: Loss = 0.9398 (C: 0.9398, R: 0.0000)
Batch 1600/18276: Loss = 1.2424 (C: 1.2424, R: 0.0000)
Batch 1700/18276: Loss = 1.5436 (C: 1.5436, R: 0.0000)
Batch 1800/18276: Loss = 1.4280 (C: 1.4280, R: 0.0000)
Batch 1900/18276: Loss = 1.2059 (C: 1.2059, R: 0.0000)
Batch 2000/18276: Loss = 0.9650 (C: 0.9650, R: 0.0000)
Batch 2100/18276: Loss = 1.2362 (C: 1.2362, R: 0.0000)
Batch 2200/18276: Loss = 1.0642 (C: 1.0642, R: 0.0000)
Batch 2300/18276: Loss = 1.5788 (C: 1.5788, R: 0.0000)
Batch 2400/18276: Loss = 1.2048 (C: 1.2048, R: 0.0000)
Batch 2500/18276: Loss = 1.2378 (C: 1.2378, R: 0.0000)
Batch 2600/18276: Loss = 1.5426 (C: 1.5426, R: 0.0000)
Batch 2700/18276: Loss = 1.3651 (C: 1.3651, R: 0.0000)
Batch 2800/18276: Loss = 1.5633 (C: 1.5633, R: 0.0000)
Batch 2900/18276: Loss = 1.3657 (C: 1.3657, R: 0.0000)
Batch 3000/18276: Loss = 1.5792 (C: 1.5792, R: 0.0000)
Batch 3100/18276: Loss = 1.5969 (C: 1.5969, R: 0.0000)
Batch 3200/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 3300/18276: Loss = 1.5803 (C: 1.5803, R: 0.0000)
Batch 3400/18276: Loss = 1.2923 (C: 1.2923, R: 0.0000)
Batch 3500/18276: Loss = 1.5778 (C: 1.5778, R: 0.0000)
Batch 3600/18276: Loss = 1.4016 (C: 1.4016, R: 0.0000)
Batch 3700/18276: Loss = 1.4076 (C: 1.4076, R: 0.0000)
Batch 3800/18276: Loss = 1.4223 (C: 1.4223, R: 0.0000)
Batch 3900/18276: Loss = 1.4238 (C: 1.4238, R: 0.0000)
Batch 4000/18276: Loss = 1.6272 (C: 1.6272, R: 0.0000)
Batch 4100/18276: Loss = 1.4012 (C: 1.4012, R: 0.0000)
Batch 4200/18276: Loss = 1.5873 (C: 1.5873, R: 0.0000)
Batch 4300/18276: Loss = 1.2374 (C: 1.2374, R: 0.0000)
Batch 4400/18276: Loss = 1.5651 (C: 1.5651, R: 0.0000)
Batch 4500/18276: Loss = 1.4027 (C: 1.4027, R: 0.0000)
Batch 4600/18276: Loss = 1.2162 (C: 1.2162, R: 0.0000)
Batch 4700/18276: Loss = 1.5468 (C: 1.5468, R: 0.0000)
Batch 4800/18276: Loss = 1.6590 (C: 1.6590, R: 0.0000)
Batch 4900/18276: Loss = 1.3670 (C: 1.3670, R: 0.0000)
Batch 5000/18276: Loss = 1.4090 (C: 1.4090, R: 0.0000)
Batch 5100/18276: Loss = 1.5686 (C: 1.5686, R: 0.0000)
Batch 5200/18276: Loss = 1.2366 (C: 1.2366, R: 0.0000)
Batch 5300/18276: Loss = 1.5843 (C: 1.5843, R: 0.0000)
Batch 5400/18276: Loss = 1.6968 (C: 1.6968, R: 0.0000)
Batch 5500/18276: Loss = 1.2370 (C: 1.2370, R: 0.0000)
Batch 5600/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 5700/18276: Loss = 1.9205 (C: 1.9205, R: 0.0000)
Batch 5800/18276: Loss = 1.2100 (C: 1.2100, R: 0.0000)
Batch 5900/18276: Loss = 1.5605 (C: 1.5605, R: 0.0000)
Batch 6000/18276: Loss = 1.5478 (C: 1.5478, R: 0.0000)
Batch 6100/18276: Loss = 0.9335 (C: 0.9335, R: 0.0000)
Batch 6200/18276: Loss = 0.9047 (C: 0.9047, R: 0.0000)
Batch 6300/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 6400/18276: Loss = 1.6978 (C: 1.6978, R: 0.0000)
Batch 6500/18276: Loss = 1.7201 (C: 1.7201, R: 0.0000)
Batch 6600/18276: Loss = 1.5692 (C: 1.5692, R: 0.0000)
Batch 6700/18276: Loss = 1.3959 (C: 1.3959, R: 0.0000)
Batch 6800/18276: Loss = 1.2096 (C: 1.2096, R: 0.0000)
Batch 6900/18276: Loss = 1.6983 (C: 1.6983, R: 0.0000)
Batch 7000/18276: Loss = 1.1454 (C: 1.1454, R: 0.0000)
Batch 7100/18276: Loss = 1.6598 (C: 1.6598, R: 0.0000)
Batch 7200/18276: Loss = 1.3618 (C: 1.3618, R: 0.0000)
Batch 7300/18276: Loss = 1.5692 (C: 1.5692, R: 0.0000)
Batch 7400/18276: Loss = 1.3001 (C: 1.3001, R: 0.0000)
Batch 7500/18276: Loss = 1.4684 (C: 1.4684, R: 0.0000)
Batch 7600/18276: Loss = 1.8267 (C: 1.8267, R: 0.0000)
Batch 7700/18276: Loss = 1.6552 (C: 1.6552, R: 0.0000)
Batch 7800/18276: Loss = 1.7067 (C: 1.7067, R: 0.0000)
Batch 7900/18276: Loss = 1.2347 (C: 1.2347, R: 0.0000)
Batch 8000/18276: Loss = 1.2377 (C: 1.2377, R: 0.0000)
Batch 8100/18276: Loss = 1.4934 (C: 1.4934, R: 0.0000)
Batch 8200/18276: Loss = 0.9729 (C: 0.9729, R: 0.0000)
Batch 8300/18276: Loss = 1.6639 (C: 1.6639, R: 0.0000)
Batch 8400/18276: Loss = 1.0223 (C: 1.0223, R: 0.0000)
Batch 8500/18276: Loss = 1.5564 (C: 1.5564, R: 0.0000)
Batch 8600/18276: Loss = 1.1942 (C: 1.1942, R: 0.0000)
Batch 8700/18276: Loss = 1.4127 (C: 1.4127, R: 0.0000)
Batch 8800/18276: Loss = 2.0090 (C: 2.0090, R: 0.0000)
Batch 8900/18276: Loss = 1.5481 (C: 1.5481, R: 0.0000)
Batch 9000/18276: Loss = 1.4199 (C: 1.4199, R: 0.0000)
Batch 9100/18276: Loss = 1.4704 (C: 1.4704, R: 0.0000)
Batch 9200/18276: Loss = 1.5528 (C: 1.5528, R: 0.0000)
Batch 9300/18276: Loss = 1.1035 (C: 1.1035, R: 0.0000)
Batch 9400/18276: Loss = 1.4065 (C: 1.4065, R: 0.0000)
Batch 9500/18276: Loss = 1.8378 (C: 1.8378, R: 0.0000)
Batch 9600/18276: Loss = 1.2789 (C: 1.2789, R: 0.0000)
Batch 9700/18276: Loss = 1.5694 (C: 1.5694, R: 0.0000)
Batch 9800/18276: Loss = 1.5814 (C: 1.5814, R: 0.0000)
Batch 9900/18276: Loss = 1.5488 (C: 1.5488, R: 0.0000)
Batch 10000/18276: Loss = 1.4094 (C: 1.4094, R: 0.0000)
Batch 10100/18276: Loss = 1.2048 (C: 1.2048, R: 0.0000)
Batch 10200/18276: Loss = 1.8758 (C: 1.8758, R: 0.0000)
Batch 10300/18276: Loss = 1.1977 (C: 1.1977, R: 0.0000)
Batch 10400/18276: Loss = 1.4058 (C: 1.4058, R: 0.0000)
Batch 10500/18276: Loss = 1.4971 (C: 1.4971, R: 0.0000)
Batch 10600/18276: Loss = 1.4196 (C: 1.4196, R: 0.0000)
Batch 10700/18276: Loss = 1.4890 (C: 1.4890, R: 0.0000)
Batch 10800/18276: Loss = 1.2198 (C: 1.2198, R: 0.0000)
Batch 10900/18276: Loss = 1.4248 (C: 1.4248, R: 0.0000)
Batch 11000/18276: Loss = 1.5697 (C: 1.5697, R: 0.0000)
Batch 11100/18276: Loss = 1.2052 (C: 1.2052, R: 0.0000)
Batch 11200/18276: Loss = 1.1511 (C: 1.1511, R: 0.0000)
Batch 11300/18276: Loss = 1.8029 (C: 1.8029, R: 0.0000)
Batch 11400/18276: Loss = 1.0245 (C: 1.0245, R: 0.0000)
Batch 11500/18276: Loss = 1.7252 (C: 1.7252, R: 0.0000)
Batch 11600/18276: Loss = 1.4971 (C: 1.4971, R: 0.0000)
Batch 11700/18276: Loss = 1.2357 (C: 1.2357, R: 0.0000)
Batch 11800/18276: Loss = 1.2034 (C: 1.2034, R: 0.0000)
Batch 11900/18276: Loss = 1.9204 (C: 1.9204, R: 0.0000)
Batch 12000/18276: Loss = 1.4238 (C: 1.4238, R: 0.0000)
Batch 12100/18276: Loss = 1.3634 (C: 1.3634, R: 0.0000)
Batch 12200/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 12300/18276: Loss = 1.5363 (C: 1.5363, R: 0.0000)
Batch 12400/18276: Loss = 1.2047 (C: 1.2047, R: 0.0000)
Batch 12500/18276: Loss = 1.6550 (C: 1.6550, R: 0.0000)
Batch 12600/18276: Loss = 1.8060 (C: 1.8060, R: 0.0000)
Batch 12700/18276: Loss = 1.4195 (C: 1.4195, R: 0.0000)
Batch 12800/18276: Loss = 1.5485 (C: 1.5485, R: 0.0000)
Batch 12900/18276: Loss = 1.4720 (C: 1.4720, R: 0.0000)
Batch 13000/18276: Loss = 1.5349 (C: 1.5349, R: 0.0000)
Batch 13100/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 13200/18276: Loss = 1.5802 (C: 1.5802, R: 0.0000)
Batch 13300/18276: Loss = 1.4970 (C: 1.4970, R: 0.0000)
Batch 13400/18276: Loss = 1.4075 (C: 1.4075, R: 0.0000)
Batch 13500/18276: Loss = 1.4074 (C: 1.4074, R: 0.0000)
Batch 13600/18276: Loss = 1.9005 (C: 1.9005, R: 0.0000)
Batch 13700/18276: Loss = 1.2047 (C: 1.2047, R: 0.0000)
Batch 13800/18276: Loss = 0.8006 (C: 0.8006, R: 0.0000)
Batch 13900/18276: Loss = 1.4956 (C: 1.4956, R: 0.0000)
Batch 14000/18276: Loss = 1.8781 (C: 1.8781, R: 0.0000)
Batch 14100/18276: Loss = 1.2056 (C: 1.2056, R: 0.0000)
Batch 14200/18276: Loss = 1.4168 (C: 1.4168, R: 0.0000)
Batch 14300/18276: Loss = 0.9800 (C: 0.9800, R: 0.0000)
Batch 14400/18276: Loss = 1.3542 (C: 1.3542, R: 0.0000)
Batch 14500/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 14600/18276: Loss = 1.8104 (C: 1.8104, R: 0.0000)
Batch 14700/18276: Loss = 1.4262 (C: 1.4262, R: 0.0000)
Batch 14800/18276: Loss = 1.0537 (C: 1.0537, R: 0.0000)
Batch 14900/18276: Loss = 1.4303 (C: 1.4303, R: 0.0000)
Batch 15000/18276: Loss = 0.9832 (C: 0.9832, R: 0.0000)
Batch 15100/18276: Loss = 1.2908 (C: 1.2908, R: 0.0000)
Batch 15200/18276: Loss = 1.6193 (C: 1.6193, R: 0.0000)
Batch 15300/18276: Loss = 1.5795 (C: 1.5795, R: 0.0000)
Batch 15400/18276: Loss = 1.5873 (C: 1.5873, R: 0.0000)
Batch 15500/18276: Loss = 1.1743 (C: 1.1743, R: 0.0000)
Batch 15600/18276: Loss = 1.5495 (C: 1.5495, R: 0.0000)
Batch 15700/18276: Loss = 1.4201 (C: 1.4201, R: 0.0000)
Batch 15800/18276: Loss = 1.6982 (C: 1.6982, R: 0.0000)
Batch 15900/18276: Loss = 1.0363 (C: 1.0363, R: 0.0000)
Batch 16000/18276: Loss = 1.4081 (C: 1.4081, R: 0.0000)
Batch 16100/18276: Loss = 0.9690 (C: 0.9690, R: 0.0000)
Batch 16200/18276: Loss = 1.6027 (C: 1.6027, R: 0.0000)
Batch 16300/18276: Loss = 1.0543 (C: 1.0543, R: 0.0000)
Batch 16400/18276: Loss = 1.4095 (C: 1.4095, R: 0.0000)
Batch 16500/18276: Loss = 1.4638 (C: 1.4638, R: 0.0000)
Batch 16600/18276: Loss = 1.5806 (C: 1.5806, R: 0.0000)
Batch 16700/18276: Loss = 1.2356 (C: 1.2356, R: 0.0000)
Batch 16800/18276: Loss = 1.7164 (C: 1.7164, R: 0.0000)
Batch 16900/18276: Loss = 1.5689 (C: 1.5689, R: 0.0000)
Batch 17000/18276: Loss = 1.3545 (C: 1.3545, R: 0.0000)
Batch 17100/18276: Loss = 1.4943 (C: 1.4943, R: 0.0000)
Batch 17200/18276: Loss = 1.0226 (C: 1.0226, R: 0.0000)
Batch 17300/18276: Loss = 1.5631 (C: 1.5631, R: 0.0000)
Batch 17400/18276: Loss = 1.8978 (C: 1.8978, R: 0.0000)
Batch 17500/18276: Loss = 1.4013 (C: 1.4013, R: 0.0000)
Batch 17600/18276: Loss = 1.9153 (C: 1.9153, R: 0.0000)
Batch 17700/18276: Loss = 1.4849 (C: 1.4849, R: 0.0000)
Batch 17800/18276: Loss = 1.5488 (C: 1.5488, R: 0.0000)
Batch 17900/18276: Loss = 1.1931 (C: 1.1931, R: 0.0000)
Batch 18000/18276: Loss = 1.4081 (C: 1.4081, R: 0.0000)
Batch 18100/18276: Loss = 1.8267 (C: 1.8267, R: 0.0000)
Batch 18200/18276: Loss = 1.3725 (C: 1.3725, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.2046666145324707
  reconstruction_loss raw: 0.0
  total_loss raw: 1.2046666145324707
Epoch 19 completed in 72.27s
Train Loss: 1.4412 (C: 1.4412)
Val Loss: 1.4403 (C: 1.4403)
No improvement for 5 epochs

Epoch 20/50
------------------------------
Batch 0/18276: Loss = 1.4022 (C: 1.4022, R: 0.0000)
Batch 100/18276: Loss = 1.8801 (C: 1.8801, R: 0.0000)
Batch 200/18276: Loss = 1.4220 (C: 1.4220, R: 0.0000)
Batch 300/18276: Loss = 0.9896 (C: 0.9896, R: 0.0000)
Batch 400/18276: Loss = 1.5639 (C: 1.5639, R: 0.0000)
Batch 500/18276: Loss = 1.3587 (C: 1.3587, R: 0.0000)
Batch 600/18276: Loss = 1.2091 (C: 1.2091, R: 0.0000)
Batch 700/18276: Loss = 1.0374 (C: 1.0374, R: 0.0000)
Batch 800/18276: Loss = 1.1871 (C: 1.1871, R: 0.0000)
Batch 900/18276: Loss = 1.2089 (C: 1.2089, R: 0.0000)
Batch 1000/18276: Loss = 1.5792 (C: 1.5792, R: 0.0000)
Batch 1100/18276: Loss = 1.5793 (C: 1.5793, R: 0.0000)
Batch 1200/18276: Loss = 1.4241 (C: 1.4241, R: 0.0000)
Batch 1300/18276: Loss = 1.0235 (C: 1.0235, R: 0.0000)
Batch 1400/18276: Loss = 1.5800 (C: 1.5800, R: 0.0000)
Batch 1500/18276: Loss = 1.4171 (C: 1.4171, R: 0.0000)
Batch 1600/18276: Loss = 1.2045 (C: 1.2045, R: 0.0000)
Batch 1700/18276: Loss = 1.4190 (C: 1.4190, R: 0.0000)
Batch 1800/18276: Loss = 1.4190 (C: 1.4190, R: 0.0000)
Batch 1900/18276: Loss = 1.4874 (C: 1.4874, R: 0.0000)
Batch 2000/18276: Loss = 1.4223 (C: 1.4223, R: 0.0000)
Batch 2100/18276: Loss = 1.2357 (C: 1.2357, R: 0.0000)
Batch 2200/18276: Loss = 1.2956 (C: 1.2956, R: 0.0000)
Batch 2300/18276: Loss = 1.2048 (C: 1.2048, R: 0.0000)
Batch 2400/18276: Loss = 1.2354 (C: 1.2354, R: 0.0000)
Batch 2500/18276: Loss = 1.5788 (C: 1.5788, R: 0.0000)
Batch 2600/18276: Loss = 1.3542 (C: 1.3542, R: 0.0000)
Batch 2700/18276: Loss = 1.5697 (C: 1.5697, R: 0.0000)
Batch 2800/18276: Loss = 0.9783 (C: 0.9783, R: 0.0000)
Batch 2900/18276: Loss = 1.2372 (C: 1.2372, R: 0.0000)
Batch 3000/18276: Loss = 1.4961 (C: 1.4961, R: 0.0000)
Batch 3100/18276: Loss = 1.5720 (C: 1.5720, R: 0.0000)
Batch 3200/18276: Loss = 1.5404 (C: 1.5404, R: 0.0000)
Batch 3300/18276: Loss = 1.4018 (C: 1.4018, R: 0.0000)
Batch 3400/18276: Loss = 0.9250 (C: 0.9250, R: 0.0000)
Batch 3500/18276: Loss = 1.3648 (C: 1.3648, R: 0.0000)
Batch 3600/18276: Loss = 1.9140 (C: 1.9140, R: 0.0000)
Batch 3700/18276: Loss = 1.8323 (C: 1.8323, R: 0.0000)
Batch 3800/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 3900/18276: Loss = 1.7081 (C: 1.7081, R: 0.0000)
Batch 4000/18276: Loss = 1.8318 (C: 1.8318, R: 0.0000)
Batch 4100/18276: Loss = 1.3661 (C: 1.3661, R: 0.0000)
Batch 4200/18276: Loss = 1.2357 (C: 1.2357, R: 0.0000)
Batch 4300/18276: Loss = 1.5907 (C: 1.5907, R: 0.0000)
Batch 4400/18276: Loss = 1.2863 (C: 1.2863, R: 0.0000)
Batch 4500/18276: Loss = 1.7096 (C: 1.7096, R: 0.0000)
Batch 4600/18276: Loss = 1.8026 (C: 1.8026, R: 0.0000)
Batch 4700/18276: Loss = 1.5733 (C: 1.5733, R: 0.0000)
Batch 4800/18276: Loss = 1.4193 (C: 1.4193, R: 0.0000)
Batch 4900/18276: Loss = 1.6550 (C: 1.6550, R: 0.0000)
Batch 5000/18276: Loss = 1.1446 (C: 1.1446, R: 0.0000)
Batch 5100/18276: Loss = 1.4198 (C: 1.4198, R: 0.0000)
Batch 5200/18276: Loss = 1.4092 (C: 1.4092, R: 0.0000)
Batch 5300/18276: Loss = 1.4926 (C: 1.4926, R: 0.0000)
Batch 5400/18276: Loss = 1.4188 (C: 1.4188, R: 0.0000)
Batch 5500/18276: Loss = 1.3613 (C: 1.3613, R: 0.0000)
Batch 5600/18276: Loss = 1.2363 (C: 1.2363, R: 0.0000)
Batch 5700/18276: Loss = 1.7327 (C: 1.7327, R: 0.0000)
Batch 5800/18276: Loss = 1.4231 (C: 1.4231, R: 0.0000)
Batch 5900/18276: Loss = 1.7039 (C: 1.7039, R: 0.0000)
Batch 6000/18276: Loss = 1.5663 (C: 1.5663, R: 0.0000)
Batch 6100/18276: Loss = 1.5480 (C: 1.5480, R: 0.0000)
Batch 6200/18276: Loss = 1.5730 (C: 1.5730, R: 0.0000)
Batch 6300/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 6400/18276: Loss = 1.4092 (C: 1.4092, R: 0.0000)
Batch 6500/18276: Loss = 1.1871 (C: 1.1871, R: 0.0000)
Batch 6600/18276: Loss = 1.7725 (C: 1.7725, R: 0.0000)
Batch 6700/18276: Loss = 0.9815 (C: 0.9815, R: 0.0000)
Batch 6800/18276: Loss = 1.2362 (C: 1.2362, R: 0.0000)
Batch 6900/18276: Loss = 1.7245 (C: 1.7245, R: 0.0000)
Batch 7000/18276: Loss = 1.2910 (C: 1.2910, R: 0.0000)
Batch 7100/18276: Loss = 1.5221 (C: 1.5221, R: 0.0000)
Batch 7200/18276: Loss = 1.5847 (C: 1.5847, R: 0.0000)
Batch 7300/18276: Loss = 1.6105 (C: 1.6105, R: 0.0000)
Batch 7400/18276: Loss = 1.3540 (C: 1.3540, R: 0.0000)
Batch 7500/18276: Loss = 1.2918 (C: 1.2918, R: 0.0000)
Batch 7600/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 7700/18276: Loss = 1.4143 (C: 1.4143, R: 0.0000)
Batch 7800/18276: Loss = 1.0537 (C: 1.0537, R: 0.0000)
Batch 7900/18276: Loss = 1.5692 (C: 1.5692, R: 0.0000)
Batch 8000/18276: Loss = 1.3599 (C: 1.3599, R: 0.0000)
Batch 8100/18276: Loss = 1.5897 (C: 1.5897, R: 0.0000)
Batch 8200/18276: Loss = 1.1936 (C: 1.1936, R: 0.0000)
Batch 8300/18276: Loss = 1.5470 (C: 1.5470, R: 0.0000)
Batch 8400/18276: Loss = 1.4024 (C: 1.4024, R: 0.0000)
Batch 8500/18276: Loss = 1.5484 (C: 1.5484, R: 0.0000)
Batch 8600/18276: Loss = 1.4188 (C: 1.4188, R: 0.0000)
Batch 8700/18276: Loss = 1.5691 (C: 1.5691, R: 0.0000)
Batch 8800/18276: Loss = 1.2784 (C: 1.2784, R: 0.0000)
Batch 8900/18276: Loss = 1.0555 (C: 1.0555, R: 0.0000)
Batch 9000/18276: Loss = 1.4202 (C: 1.4202, R: 0.0000)
Batch 9100/18276: Loss = 1.4238 (C: 1.4238, R: 0.0000)
Batch 9200/18276: Loss = 1.2370 (C: 1.2370, R: 0.0000)
Batch 9300/18276: Loss = 1.3545 (C: 1.3545, R: 0.0000)
Batch 9400/18276: Loss = 1.6652 (C: 1.6652, R: 0.0000)
Batch 9500/18276: Loss = 1.7083 (C: 1.7083, R: 0.0000)
Batch 9600/18276: Loss = 1.7103 (C: 1.7103, R: 0.0000)
Batch 9700/18276: Loss = 1.4102 (C: 1.4102, R: 0.0000)
Batch 9800/18276: Loss = 1.2180 (C: 1.2180, R: 0.0000)
Batch 9900/18276: Loss = 1.6975 (C: 1.6975, R: 0.0000)
Batch 10000/18276: Loss = 1.2049 (C: 1.2049, R: 0.0000)
Batch 10100/18276: Loss = 1.2370 (C: 1.2370, R: 0.0000)
Batch 10200/18276: Loss = 1.0535 (C: 1.0535, R: 0.0000)
Batch 10300/18276: Loss = 1.3660 (C: 1.3660, R: 0.0000)
Batch 10400/18276: Loss = 1.5536 (C: 1.5536, R: 0.0000)
Batch 10500/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 10600/18276: Loss = 1.2372 (C: 1.2372, R: 0.0000)
Batch 10700/18276: Loss = 1.3664 (C: 1.3664, R: 0.0000)
Batch 10800/18276: Loss = 1.5631 (C: 1.5631, R: 0.0000)
Batch 10900/18276: Loss = 1.8266 (C: 1.8266, R: 0.0000)
Batch 11000/18276: Loss = 1.2372 (C: 1.2372, R: 0.0000)
Batch 11100/18276: Loss = 1.4917 (C: 1.4917, R: 0.0000)
Batch 11200/18276: Loss = 1.0381 (C: 1.0381, R: 0.0000)
Batch 11300/18276: Loss = 1.1885 (C: 1.1885, R: 0.0000)
Batch 11400/18276: Loss = 1.2568 (C: 1.2568, R: 0.0000)
Batch 11500/18276: Loss = 1.2154 (C: 1.2154, R: 0.0000)
Batch 11600/18276: Loss = 1.7925 (C: 1.7925, R: 0.0000)
Batch 11700/18276: Loss = 1.2069 (C: 1.2069, R: 0.0000)
Batch 11800/18276: Loss = 1.2451 (C: 1.2451, R: 0.0000)
Batch 11900/18276: Loss = 1.5773 (C: 1.5773, R: 0.0000)
Batch 12000/18276: Loss = 1.4195 (C: 1.4195, R: 0.0000)
Batch 12100/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 12200/18276: Loss = 1.2394 (C: 1.2394, R: 0.0000)
Batch 12300/18276: Loss = 1.4087 (C: 1.4087, R: 0.0000)
Batch 12400/18276: Loss = 1.4954 (C: 1.4954, R: 0.0000)
Batch 12500/18276: Loss = 1.4069 (C: 1.4069, R: 0.0000)
Batch 12600/18276: Loss = 1.4936 (C: 1.4936, R: 0.0000)
Batch 12700/18276: Loss = 1.1820 (C: 1.1820, R: 0.0000)
Batch 12800/18276: Loss = 1.4828 (C: 1.4828, R: 0.0000)
Batch 12900/18276: Loss = 1.2129 (C: 1.2129, R: 0.0000)
Batch 13000/18276: Loss = 1.3653 (C: 1.3653, R: 0.0000)
Batch 13100/18276: Loss = 1.5495 (C: 1.5495, R: 0.0000)
Batch 13200/18276: Loss = 1.2051 (C: 1.2051, R: 0.0000)
Batch 13300/18276: Loss = 1.5793 (C: 1.5793, R: 0.0000)
Batch 13400/18276: Loss = 1.6561 (C: 1.6561, R: 0.0000)
Batch 13500/18276: Loss = 1.7843 (C: 1.7843, R: 0.0000)
Batch 13600/18276: Loss = 1.5543 (C: 1.5543, R: 0.0000)
Batch 13700/18276: Loss = 1.5483 (C: 1.5483, R: 0.0000)
Batch 13800/18276: Loss = 1.5629 (C: 1.5629, R: 0.0000)
Batch 13900/18276: Loss = 1.7215 (C: 1.7215, R: 0.0000)
Batch 14000/18276: Loss = 1.4191 (C: 1.4191, R: 0.0000)
Batch 14100/18276: Loss = 0.9772 (C: 0.9772, R: 0.0000)
Batch 14200/18276: Loss = 1.7199 (C: 1.7199, R: 0.0000)
Batch 14300/18276: Loss = 1.2937 (C: 1.2937, R: 0.0000)
Batch 14400/18276: Loss = 1.2563 (C: 1.2563, R: 0.0000)
Batch 14500/18276: Loss = 1.1529 (C: 1.1529, R: 0.0000)
Batch 14600/18276: Loss = 1.5809 (C: 1.5809, R: 0.0000)
Batch 14700/18276: Loss = 1.4162 (C: 1.4162, R: 0.0000)
Batch 14800/18276: Loss = 1.2359 (C: 1.2359, R: 0.0000)
Batch 14900/18276: Loss = 1.2352 (C: 1.2352, R: 0.0000)
Batch 15000/18276: Loss = 1.8731 (C: 1.8731, R: 0.0000)
Batch 15100/18276: Loss = 1.7069 (C: 1.7069, R: 0.0000)
Batch 15200/18276: Loss = 1.4760 (C: 1.4760, R: 0.0000)
Batch 15300/18276: Loss = 1.6557 (C: 1.6557, R: 0.0000)
Batch 15400/18276: Loss = 1.3645 (C: 1.3645, R: 0.0000)
Batch 15500/18276: Loss = 0.9784 (C: 0.9784, R: 0.0000)
Batch 15600/18276: Loss = 0.9214 (C: 0.9214, R: 0.0000)
Batch 15700/18276: Loss = 1.7200 (C: 1.7200, R: 0.0000)
Batch 15800/18276: Loss = 1.3535 (C: 1.3535, R: 0.0000)
Batch 15900/18276: Loss = 1.4230 (C: 1.4230, R: 0.0000)
Batch 16000/18276: Loss = 1.4194 (C: 1.4194, R: 0.0000)
Batch 16100/18276: Loss = 1.8063 (C: 1.8063, R: 0.0000)
Batch 16200/18276: Loss = 1.4076 (C: 1.4076, R: 0.0000)
Batch 16300/18276: Loss = 1.1778 (C: 1.1778, R: 0.0000)
Batch 16400/18276: Loss = 1.4939 (C: 1.4939, R: 0.0000)
Batch 16500/18276: Loss = 1.9169 (C: 1.9169, R: 0.0000)
Batch 16600/18276: Loss = 1.1512 (C: 1.1512, R: 0.0000)
Batch 16700/18276: Loss = 1.7096 (C: 1.7096, R: 0.0000)
Batch 16800/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 16900/18276: Loss = 1.5809 (C: 1.5809, R: 0.0000)
Batch 17000/18276: Loss = 1.1512 (C: 1.1512, R: 0.0000)
Batch 17100/18276: Loss = 1.4090 (C: 1.4090, R: 0.0000)
Batch 17200/18276: Loss = 1.6548 (C: 1.6548, R: 0.0000)
Batch 17300/18276: Loss = 1.4071 (C: 1.4071, R: 0.0000)
Batch 17400/18276: Loss = 1.6181 (C: 1.6181, R: 0.0000)
Batch 17500/18276: Loss = 1.1945 (C: 1.1945, R: 0.0000)
Batch 17600/18276: Loss = 1.7082 (C: 1.7082, R: 0.0000)
Batch 17700/18276: Loss = 1.0671 (C: 1.0671, R: 0.0000)
Batch 17800/18276: Loss = 1.3665 (C: 1.3665, R: 0.0000)
Batch 17900/18276: Loss = 1.0225 (C: 1.0225, R: 0.0000)
Batch 18000/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 18100/18276: Loss = 1.2890 (C: 1.2890, R: 0.0000)
Batch 18200/18276: Loss = 1.8319 (C: 1.8319, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.5795769691467285
  reconstruction_loss raw: 0.0
  total_loss raw: 1.5795769691467285
Epoch 20 completed in 71.92s
Train Loss: 1.4425 (C: 1.4425)
Val Loss: 1.4341 (C: 1.4341)
No improvement for 6 epochs
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/checkpoint_epoch_20.pt

Epoch 21/50
------------------------------
Batch 0/18276: Loss = 1.6083 (C: 1.6083, R: 0.0000)
Batch 100/18276: Loss = 1.7989 (C: 1.7989, R: 0.0000)
Batch 200/18276: Loss = 1.2305 (C: 1.2305, R: 0.0000)
Batch 300/18276: Loss = 1.2342 (C: 1.2342, R: 0.0000)
Batch 400/18276: Loss = 1.6589 (C: 1.6589, R: 0.0000)
Batch 500/18276: Loss = 1.5512 (C: 1.5512, R: 0.0000)
Batch 600/18276: Loss = 1.6542 (C: 1.6542, R: 0.0000)
Batch 700/18276: Loss = 1.6860 (C: 1.6860, R: 0.0000)
Batch 800/18276: Loss = 1.1878 (C: 1.1878, R: 0.0000)
Batch 900/18276: Loss = 1.1513 (C: 1.1513, R: 0.0000)
Batch 1000/18276: Loss = 1.5782 (C: 1.5782, R: 0.0000)
Batch 1100/18276: Loss = 1.2359 (C: 1.2359, R: 0.0000)
Batch 1200/18276: Loss = 1.3567 (C: 1.3567, R: 0.0000)
Batch 1300/18276: Loss = 1.4877 (C: 1.4877, R: 0.0000)
Batch 1400/18276: Loss = 1.3540 (C: 1.3540, R: 0.0000)
Batch 1500/18276: Loss = 1.8102 (C: 1.8102, R: 0.0000)
Batch 1600/18276: Loss = 1.2007 (C: 1.2007, R: 0.0000)
Batch 1700/18276: Loss = 1.8436 (C: 1.8436, R: 0.0000)
Batch 1800/18276: Loss = 1.5933 (C: 1.5933, R: 0.0000)
Batch 1900/18276: Loss = 1.2092 (C: 1.2092, R: 0.0000)
Batch 2000/18276: Loss = 1.8329 (C: 1.8329, R: 0.0000)
Batch 2100/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 2200/18276: Loss = 1.2949 (C: 1.2949, R: 0.0000)
Batch 2300/18276: Loss = 1.9224 (C: 1.9224, R: 0.0000)
Batch 2400/18276: Loss = 1.9388 (C: 1.9388, R: 0.0000)
Batch 2500/18276: Loss = 1.1439 (C: 1.1439, R: 0.0000)
Batch 2600/18276: Loss = 0.9816 (C: 0.9816, R: 0.0000)
Batch 2700/18276: Loss = 1.5633 (C: 1.5633, R: 0.0000)
Batch 2800/18276: Loss = 1.3543 (C: 1.3543, R: 0.0000)
Batch 2900/18276: Loss = 1.7407 (C: 1.7407, R: 0.0000)
Batch 3000/18276: Loss = 1.5692 (C: 1.5692, R: 0.0000)
Batch 3100/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 3200/18276: Loss = 1.7558 (C: 1.7558, R: 0.0000)
Batch 3300/18276: Loss = 1.6731 (C: 1.6731, R: 0.0000)
Batch 3400/18276: Loss = 1.7194 (C: 1.7194, R: 0.0000)
Batch 3500/18276: Loss = 1.5470 (C: 1.5470, R: 0.0000)
Batch 3600/18276: Loss = 1.2384 (C: 1.2384, R: 0.0000)
Batch 3700/18276: Loss = 1.2904 (C: 1.2904, R: 0.0000)
Batch 3800/18276: Loss = 1.6574 (C: 1.6574, R: 0.0000)
Batch 3900/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 4000/18276: Loss = 1.7100 (C: 1.7100, R: 0.0000)
Batch 4100/18276: Loss = 1.2916 (C: 1.2916, R: 0.0000)
Batch 4200/18276: Loss = 1.6670 (C: 1.6670, R: 0.0000)
Batch 4300/18276: Loss = 0.8019 (C: 0.8019, R: 0.0000)
Batch 4400/18276: Loss = 1.7196 (C: 1.7196, R: 0.0000)
Batch 4500/18276: Loss = 1.6652 (C: 1.6652, R: 0.0000)
Batch 4600/18276: Loss = 1.5747 (C: 1.5747, R: 0.0000)
Batch 4700/18276: Loss = 1.8768 (C: 1.8768, R: 0.0000)
Batch 4800/18276: Loss = 1.0542 (C: 1.0542, R: 0.0000)
Batch 4900/18276: Loss = 1.3859 (C: 1.3859, R: 0.0000)
Batch 5000/18276: Loss = 1.4013 (C: 1.4013, R: 0.0000)
Batch 5100/18276: Loss = 1.5485 (C: 1.5485, R: 0.0000)
Batch 5200/18276: Loss = 0.9785 (C: 0.9785, R: 0.0000)
Batch 5300/18276: Loss = 1.4127 (C: 1.4127, R: 0.0000)
Batch 5400/18276: Loss = 1.6981 (C: 1.6981, R: 0.0000)
Batch 5500/18276: Loss = 1.2106 (C: 1.2106, R: 0.0000)
Batch 5600/18276: Loss = 1.3549 (C: 1.3549, R: 0.0000)
Batch 5700/18276: Loss = 1.5742 (C: 1.5742, R: 0.0000)
Batch 5800/18276: Loss = 1.3683 (C: 1.3683, R: 0.0000)
Batch 5900/18276: Loss = 1.0670 (C: 1.0670, R: 0.0000)
Batch 6000/18276: Loss = 1.7078 (C: 1.7078, R: 0.0000)
Batch 6100/18276: Loss = 1.0554 (C: 1.0554, R: 0.0000)
Batch 6200/18276: Loss = 1.2254 (C: 1.2254, R: 0.0000)
Batch 6300/18276: Loss = 0.8003 (C: 0.8003, R: 0.0000)
Batch 6400/18276: Loss = 1.4083 (C: 1.4083, R: 0.0000)
Batch 6500/18276: Loss = 1.7044 (C: 1.7044, R: 0.0000)
Batch 6600/18276: Loss = 1.3543 (C: 1.3543, R: 0.0000)
Batch 6700/18276: Loss = 1.8263 (C: 1.8263, R: 0.0000)
Batch 6800/18276: Loss = 1.4224 (C: 1.4224, R: 0.0000)
Batch 6900/18276: Loss = 1.4950 (C: 1.4950, R: 0.0000)
Batch 7000/18276: Loss = 1.5789 (C: 1.5789, R: 0.0000)
Batch 7100/18276: Loss = 1.2906 (C: 1.2906, R: 0.0000)
Batch 7200/18276: Loss = 1.4943 (C: 1.4943, R: 0.0000)
Batch 7300/18276: Loss = 1.6358 (C: 1.6358, R: 0.0000)
Batch 7400/18276: Loss = 1.4935 (C: 1.4935, R: 0.0000)
Batch 7500/18276: Loss = 1.8060 (C: 1.8060, R: 0.0000)
Batch 7600/18276: Loss = 1.8340 (C: 1.8340, R: 0.0000)
Batch 7700/18276: Loss = 1.5736 (C: 1.5736, R: 0.0000)
Batch 7800/18276: Loss = 1.2367 (C: 1.2367, R: 0.0000)
Batch 7900/18276: Loss = 1.6670 (C: 1.6670, R: 0.0000)
Batch 8000/18276: Loss = 1.5691 (C: 1.5691, R: 0.0000)
Batch 8100/18276: Loss = 1.2354 (C: 1.2354, R: 0.0000)
Batch 8200/18276: Loss = 1.1514 (C: 1.1514, R: 0.0000)
Batch 8300/18276: Loss = 1.3954 (C: 1.3954, R: 0.0000)
Batch 8400/18276: Loss = 1.5778 (C: 1.5778, R: 0.0000)
Batch 8500/18276: Loss = 1.4711 (C: 1.4711, R: 0.0000)
Batch 8600/18276: Loss = 1.5810 (C: 1.5810, R: 0.0000)
Batch 8700/18276: Loss = 1.7310 (C: 1.7310, R: 0.0000)
Batch 8800/18276: Loss = 1.8300 (C: 1.8300, R: 0.0000)
Batch 8900/18276: Loss = 1.5795 (C: 1.5795, R: 0.0000)
Batch 9000/18276: Loss = 1.5482 (C: 1.5482, R: 0.0000)
Batch 9100/18276: Loss = 1.2932 (C: 1.2932, R: 0.0000)
Batch 9200/18276: Loss = 1.0646 (C: 1.0646, R: 0.0000)
Batch 9300/18276: Loss = 1.4099 (C: 1.4099, R: 0.0000)
Batch 9400/18276: Loss = 1.6644 (C: 1.6644, R: 0.0000)
Batch 9500/18276: Loss = 1.2353 (C: 1.2353, R: 0.0000)
Batch 9600/18276: Loss = 1.4922 (C: 1.4922, R: 0.0000)
Batch 9700/18276: Loss = 1.7242 (C: 1.7242, R: 0.0000)
Batch 9800/18276: Loss = 1.7912 (C: 1.7912, R: 0.0000)
Batch 9900/18276: Loss = 1.5695 (C: 1.5695, R: 0.0000)
Batch 10000/18276: Loss = 1.6841 (C: 1.6841, R: 0.0000)
Batch 10100/18276: Loss = 1.2112 (C: 1.2112, R: 0.0000)
Batch 10200/18276: Loss = 1.5485 (C: 1.5485, R: 0.0000)
Batch 10300/18276: Loss = 1.4032 (C: 1.4032, R: 0.0000)
Batch 10400/18276: Loss = 1.7528 (C: 1.7528, R: 0.0000)
Batch 10500/18276: Loss = 1.2090 (C: 1.2090, R: 0.0000)
Batch 10600/18276: Loss = 1.4068 (C: 1.4068, R: 0.0000)
Batch 10700/18276: Loss = 1.8097 (C: 1.8097, R: 0.0000)
Batch 10800/18276: Loss = 1.1455 (C: 1.1455, R: 0.0000)
Batch 10900/18276: Loss = 1.4016 (C: 1.4016, R: 0.0000)
Batch 11000/18276: Loss = 1.3447 (C: 1.3447, R: 0.0000)
Batch 11100/18276: Loss = 1.5799 (C: 1.5799, R: 0.0000)
Batch 11200/18276: Loss = 1.7196 (C: 1.7196, R: 0.0000)
Batch 11300/18276: Loss = 1.1443 (C: 1.1443, R: 0.0000)
Batch 11400/18276: Loss = 1.3652 (C: 1.3652, R: 0.0000)
Batch 11500/18276: Loss = 1.5801 (C: 1.5801, R: 0.0000)
Batch 11600/18276: Loss = 1.4085 (C: 1.4085, R: 0.0000)
Batch 11700/18276: Loss = 1.2049 (C: 1.2049, R: 0.0000)
Batch 11800/18276: Loss = 1.8069 (C: 1.8069, R: 0.0000)
Batch 11900/18276: Loss = 1.7301 (C: 1.7301, R: 0.0000)
Batch 12000/18276: Loss = 1.3991 (C: 1.3991, R: 0.0000)
Batch 12100/18276: Loss = 1.2081 (C: 1.2081, R: 0.0000)
Batch 12200/18276: Loss = 1.4965 (C: 1.4965, R: 0.0000)
Batch 12300/18276: Loss = 1.1954 (C: 1.1954, R: 0.0000)
Batch 12400/18276: Loss = 1.5480 (C: 1.5480, R: 0.0000)
Batch 12500/18276: Loss = 1.2047 (C: 1.2047, R: 0.0000)
Batch 12600/18276: Loss = 1.5965 (C: 1.5965, R: 0.0000)
Batch 12700/18276: Loss = 1.8933 (C: 1.8933, R: 0.0000)
Batch 12800/18276: Loss = 1.4189 (C: 1.4189, R: 0.0000)
Batch 12900/18276: Loss = 1.2567 (C: 1.2567, R: 0.0000)
Batch 13000/18276: Loss = 1.6690 (C: 1.6690, R: 0.0000)
Batch 13100/18276: Loss = 1.5342 (C: 1.5342, R: 0.0000)
Batch 13200/18276: Loss = 1.7545 (C: 1.7545, R: 0.0000)
Batch 13300/18276: Loss = 1.9245 (C: 1.9245, R: 0.0000)
Batch 13400/18276: Loss = 1.6461 (C: 1.6461, R: 0.0000)
Batch 13500/18276: Loss = 1.7406 (C: 1.7406, R: 0.0000)
Batch 13600/18276: Loss = 1.4387 (C: 1.4387, R: 0.0000)
Batch 13700/18276: Loss = 1.3472 (C: 1.3472, R: 0.0000)
Batch 13800/18276: Loss = 1.5489 (C: 1.5489, R: 0.0000)
Batch 13900/18276: Loss = 1.5541 (C: 1.5541, R: 0.0000)
Batch 14000/18276: Loss = 1.4722 (C: 1.4722, R: 0.0000)
Batch 14100/18276: Loss = 1.9160 (C: 1.9160, R: 0.0000)
Batch 14200/18276: Loss = 1.3257 (C: 1.3257, R: 0.0000)
Batch 14300/18276: Loss = 1.7231 (C: 1.7231, R: 0.0000)
Batch 14400/18276: Loss = 1.5810 (C: 1.5810, R: 0.0000)
Batch 14500/18276: Loss = 1.5691 (C: 1.5691, R: 0.0000)
Batch 14600/18276: Loss = 0.9497 (C: 0.9497, R: 0.0000)
Batch 14700/18276: Loss = 1.1512 (C: 1.1512, R: 0.0000)
Batch 14800/18276: Loss = 0.9783 (C: 0.9783, R: 0.0000)
Batch 14900/18276: Loss = 1.4188 (C: 1.4188, R: 0.0000)
Batch 15000/18276: Loss = 1.2372 (C: 1.2372, R: 0.0000)
Batch 15100/18276: Loss = 1.5525 (C: 1.5525, R: 0.0000)
Batch 15200/18276: Loss = 1.4260 (C: 1.4260, R: 0.0000)
Batch 15300/18276: Loss = 1.5724 (C: 1.5724, R: 0.0000)
Batch 15400/18276: Loss = 1.6847 (C: 1.6847, R: 0.0000)
Batch 15500/18276: Loss = 1.4952 (C: 1.4952, R: 0.0000)
Batch 15600/18276: Loss = 1.8288 (C: 1.8288, R: 0.0000)
Batch 15700/18276: Loss = 1.4259 (C: 1.4259, R: 0.0000)
Batch 15800/18276: Loss = 1.2967 (C: 1.2967, R: 0.0000)
Batch 15900/18276: Loss = 1.0229 (C: 1.0229, R: 0.0000)
Batch 16000/18276: Loss = 1.4081 (C: 1.4081, R: 0.0000)
Batch 16100/18276: Loss = 1.2095 (C: 1.2095, R: 0.0000)
Batch 16200/18276: Loss = 1.2097 (C: 1.2097, R: 0.0000)
Batch 16300/18276: Loss = 1.4276 (C: 1.4276, R: 0.0000)
Batch 16400/18276: Loss = 1.6356 (C: 1.6356, R: 0.0000)
Batch 16500/18276: Loss = 1.1416 (C: 1.1416, R: 0.0000)
Batch 16600/18276: Loss = 1.7138 (C: 1.7138, R: 0.0000)
Batch 16700/18276: Loss = 1.2353 (C: 1.2353, R: 0.0000)
Batch 16800/18276: Loss = 1.4047 (C: 1.4047, R: 0.0000)
Batch 16900/18276: Loss = 1.5353 (C: 1.5353, R: 0.0000)
Batch 17000/18276: Loss = 1.7927 (C: 1.7927, R: 0.0000)
Batch 17100/18276: Loss = 1.5734 (C: 1.5734, R: 0.0000)
Batch 17200/18276: Loss = 1.0222 (C: 1.0222, R: 0.0000)
Batch 17300/18276: Loss = 1.4078 (C: 1.4078, R: 0.0000)
Batch 17400/18276: Loss = 1.8542 (C: 1.8542, R: 0.0000)
Batch 17500/18276: Loss = 1.4078 (C: 1.4078, R: 0.0000)
Batch 17600/18276: Loss = 1.5688 (C: 1.5688, R: 0.0000)
Batch 17700/18276: Loss = 1.9105 (C: 1.9105, R: 0.0000)
Batch 17800/18276: Loss = 1.3564 (C: 1.3564, R: 0.0000)
Batch 17900/18276: Loss = 1.4076 (C: 1.4076, R: 0.0000)
Batch 18000/18276: Loss = 1.3647 (C: 1.3647, R: 0.0000)
Batch 18100/18276: Loss = 1.5640 (C: 1.5640, R: 0.0000)
Batch 18200/18276: Loss = 1.5686 (C: 1.5686, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.1655696630477905
  reconstruction_loss raw: 0.0
  total_loss raw: 1.1655696630477905
Epoch 21 completed in 71.59s
Train Loss: 1.4425 (C: 1.4425)
Val Loss: 1.4311 (C: 1.4311)
No improvement for 7 epochs

Epoch 22/50
------------------------------
Batch 0/18276: Loss = 1.5677 (C: 1.5677, R: 0.0000)
Batch 100/18276: Loss = 1.6656 (C: 1.6656, R: 0.0000)
Batch 200/18276: Loss = 1.5613 (C: 1.5613, R: 0.0000)
Batch 300/18276: Loss = 1.6074 (C: 1.6074, R: 0.0000)
Batch 400/18276: Loss = 1.7239 (C: 1.7239, R: 0.0000)
Batch 500/18276: Loss = 1.5494 (C: 1.5494, R: 0.0000)
Batch 600/18276: Loss = 1.1426 (C: 1.1426, R: 0.0000)
Batch 700/18276: Loss = 1.2905 (C: 1.2905, R: 0.0000)
Batch 800/18276: Loss = 1.8694 (C: 1.8694, R: 0.0000)
Batch 900/18276: Loss = 1.3530 (C: 1.3530, R: 0.0000)
Batch 1000/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 1100/18276: Loss = 1.5733 (C: 1.5733, R: 0.0000)
Batch 1200/18276: Loss = 1.4090 (C: 1.4090, R: 0.0000)
Batch 1300/18276: Loss = 1.3542 (C: 1.3542, R: 0.0000)
Batch 1400/18276: Loss = 1.7222 (C: 1.7222, R: 0.0000)
Batch 1500/18276: Loss = 1.2062 (C: 1.2062, R: 0.0000)
Batch 1600/18276: Loss = 1.2376 (C: 1.2376, R: 0.0000)
Batch 1700/18276: Loss = 1.4930 (C: 1.4930, R: 0.0000)
Batch 1800/18276: Loss = 1.7997 (C: 1.7997, R: 0.0000)
Batch 1900/18276: Loss = 1.5534 (C: 1.5534, R: 0.0000)
Batch 2000/18276: Loss = 1.9964 (C: 1.9964, R: 0.0000)
Batch 2100/18276: Loss = 1.4019 (C: 1.4019, R: 0.0000)
Batch 2200/18276: Loss = 1.3078 (C: 1.3078, R: 0.0000)
Batch 2300/18276: Loss = 1.9127 (C: 1.9127, R: 0.0000)
Batch 2400/18276: Loss = 1.0566 (C: 1.0566, R: 0.0000)
Batch 2500/18276: Loss = 1.5346 (C: 1.5346, R: 0.0000)
Batch 2600/18276: Loss = 1.5650 (C: 1.5650, R: 0.0000)
Batch 2700/18276: Loss = 1.1524 (C: 1.1524, R: 0.0000)
Batch 2800/18276: Loss = 1.3639 (C: 1.3639, R: 0.0000)
Batch 2900/18276: Loss = 1.5351 (C: 1.5351, R: 0.0000)
Batch 3000/18276: Loss = 1.4817 (C: 1.4817, R: 0.0000)
Batch 3100/18276: Loss = 1.2357 (C: 1.2357, R: 0.0000)
Batch 3200/18276: Loss = 1.3650 (C: 1.3650, R: 0.0000)
Batch 3300/18276: Loss = 0.9294 (C: 0.9294, R: 0.0000)
Batch 3400/18276: Loss = 1.0544 (C: 1.0544, R: 0.0000)
Batch 3500/18276: Loss = 1.5536 (C: 1.5536, R: 0.0000)
Batch 3600/18276: Loss = 1.2350 (C: 1.2350, R: 0.0000)
Batch 3700/18276: Loss = 1.7138 (C: 1.7138, R: 0.0000)
Batch 3800/18276: Loss = 1.5333 (C: 1.5333, R: 0.0000)
Batch 3900/18276: Loss = 1.4962 (C: 1.4962, R: 0.0000)
Batch 4000/18276: Loss = 1.0386 (C: 1.0386, R: 0.0000)
Batch 4100/18276: Loss = 1.2907 (C: 1.2907, R: 0.0000)
Batch 4200/18276: Loss = 1.2378 (C: 1.2378, R: 0.0000)
Batch 4300/18276: Loss = 1.0379 (C: 1.0379, R: 0.0000)
Batch 4400/18276: Loss = 0.8003 (C: 0.8003, R: 0.0000)
Batch 4500/18276: Loss = 1.7087 (C: 1.7087, R: 0.0000)
Batch 4600/18276: Loss = 1.4875 (C: 1.4875, R: 0.0000)
Batch 4700/18276: Loss = 1.4699 (C: 1.4699, R: 0.0000)
Batch 4800/18276: Loss = 1.4849 (C: 1.4849, R: 0.0000)
Batch 4900/18276: Loss = 1.8268 (C: 1.8268, R: 0.0000)
Batch 5000/18276: Loss = 1.5294 (C: 1.5294, R: 0.0000)
Batch 5100/18276: Loss = 1.0374 (C: 1.0374, R: 0.0000)
Batch 5200/18276: Loss = 1.2399 (C: 1.2399, R: 0.0000)
Batch 5300/18276: Loss = 1.6705 (C: 1.6705, R: 0.0000)
Batch 5400/18276: Loss = 1.8383 (C: 1.8383, R: 0.0000)
Batch 5500/18276: Loss = 1.3649 (C: 1.3649, R: 0.0000)
Batch 5600/18276: Loss = 1.0226 (C: 1.0226, R: 0.0000)
Batch 5700/18276: Loss = 1.5527 (C: 1.5527, R: 0.0000)
Batch 5800/18276: Loss = 1.2001 (C: 1.2001, R: 0.0000)
Batch 5900/18276: Loss = 1.4212 (C: 1.4212, R: 0.0000)
Batch 6000/18276: Loss = 1.4875 (C: 1.4875, R: 0.0000)
Batch 6100/18276: Loss = 1.8148 (C: 1.8148, R: 0.0000)
Batch 6200/18276: Loss = 1.1476 (C: 1.1476, R: 0.0000)
Batch 6300/18276: Loss = 1.5525 (C: 1.5525, R: 0.0000)
Batch 6400/18276: Loss = 1.5526 (C: 1.5526, R: 0.0000)
Batch 6500/18276: Loss = 1.5143 (C: 1.5143, R: 0.0000)
Batch 6600/18276: Loss = 1.4227 (C: 1.4227, R: 0.0000)
Batch 6700/18276: Loss = 1.0711 (C: 1.0711, R: 0.0000)
Batch 6800/18276: Loss = 1.0143 (C: 1.0143, R: 0.0000)
Batch 6900/18276: Loss = 1.8310 (C: 1.8310, R: 0.0000)
Batch 7000/18276: Loss = 1.7497 (C: 1.7497, R: 0.0000)
Batch 7100/18276: Loss = 1.4191 (C: 1.4191, R: 0.0000)
Batch 7200/18276: Loss = 1.7926 (C: 1.7926, R: 0.0000)
Batch 7300/18276: Loss = 1.1438 (C: 1.1438, R: 0.0000)
Batch 7400/18276: Loss = 1.9195 (C: 1.9195, R: 0.0000)
Batch 7500/18276: Loss = 1.2390 (C: 1.2390, R: 0.0000)
Batch 7600/18276: Loss = 1.5486 (C: 1.5486, R: 0.0000)
Batch 7700/18276: Loss = 1.7174 (C: 1.7174, R: 0.0000)
Batch 7800/18276: Loss = 1.2080 (C: 1.2080, R: 0.0000)
Batch 7900/18276: Loss = 1.7030 (C: 1.7030, R: 0.0000)
Batch 8000/18276: Loss = 1.4970 (C: 1.4970, R: 0.0000)
Batch 8100/18276: Loss = 1.4235 (C: 1.4235, R: 0.0000)
Batch 8200/18276: Loss = 1.4122 (C: 1.4122, R: 0.0000)
Batch 8300/18276: Loss = 1.4335 (C: 1.4335, R: 0.0000)
Batch 8400/18276: Loss = 1.5485 (C: 1.5485, R: 0.0000)
Batch 8500/18276: Loss = 1.4669 (C: 1.4669, R: 0.0000)
Batch 8600/18276: Loss = 1.5791 (C: 1.5791, R: 0.0000)
Batch 8700/18276: Loss = 1.6977 (C: 1.6977, R: 0.0000)
Batch 8800/18276: Loss = 1.5537 (C: 1.5537, R: 0.0000)
Batch 8900/18276: Loss = 1.4208 (C: 1.4208, R: 0.0000)
Batch 9000/18276: Loss = 1.7593 (C: 1.7593, R: 0.0000)
Batch 9100/18276: Loss = 1.4285 (C: 1.4285, R: 0.0000)
Batch 9200/18276: Loss = 1.2099 (C: 1.2099, R: 0.0000)
Batch 9300/18276: Loss = 1.4217 (C: 1.4217, R: 0.0000)
Batch 9400/18276: Loss = 0.8053 (C: 0.8053, R: 0.0000)
Batch 9500/18276: Loss = 1.1440 (C: 1.1440, R: 0.0000)
Batch 9600/18276: Loss = 1.5727 (C: 1.5727, R: 0.0000)
Batch 9700/18276: Loss = 1.6590 (C: 1.6590, R: 0.0000)
Batch 9800/18276: Loss = 1.5473 (C: 1.5473, R: 0.0000)
Batch 9900/18276: Loss = 1.2067 (C: 1.2067, R: 0.0000)
Batch 10000/18276: Loss = 1.2374 (C: 1.2374, R: 0.0000)
Batch 10100/18276: Loss = 1.1513 (C: 1.1513, R: 0.0000)
Batch 10200/18276: Loss = 1.2402 (C: 1.2402, R: 0.0000)
Batch 10300/18276: Loss = 1.5876 (C: 1.5876, R: 0.0000)
Batch 10400/18276: Loss = 1.3666 (C: 1.3666, R: 0.0000)
Batch 10500/18276: Loss = 1.5709 (C: 1.5709, R: 0.0000)
Batch 10600/18276: Loss = 1.2096 (C: 1.2096, R: 0.0000)
Batch 10700/18276: Loss = 1.2914 (C: 1.2914, R: 0.0000)
Batch 10800/18276: Loss = 1.3659 (C: 1.3659, R: 0.0000)
Batch 10900/18276: Loss = 1.5813 (C: 1.5813, R: 0.0000)
Batch 11000/18276: Loss = 1.2047 (C: 1.2047, R: 0.0000)
Batch 11100/18276: Loss = 1.7133 (C: 1.7133, R: 0.0000)
Batch 11200/18276: Loss = 1.7753 (C: 1.7753, R: 0.0000)
Batch 11300/18276: Loss = 0.8201 (C: 0.8201, R: 0.0000)
Batch 11400/18276: Loss = 1.4181 (C: 1.4181, R: 0.0000)
Batch 11500/18276: Loss = 1.5825 (C: 1.5825, R: 0.0000)
Batch 11600/18276: Loss = 1.8074 (C: 1.8074, R: 0.0000)
Batch 11700/18276: Loss = 1.3798 (C: 1.3798, R: 0.0000)
Batch 11800/18276: Loss = 1.4745 (C: 1.4745, R: 0.0000)
Batch 11900/18276: Loss = 1.2047 (C: 1.2047, R: 0.0000)
Batch 12000/18276: Loss = 1.4009 (C: 1.4009, R: 0.0000)
Batch 12100/18276: Loss = 1.7024 (C: 1.7024, R: 0.0000)
Batch 12200/18276: Loss = 1.7925 (C: 1.7925, R: 0.0000)
Batch 12300/18276: Loss = 1.3726 (C: 1.3726, R: 0.0000)
Batch 12400/18276: Loss = 1.5320 (C: 1.5320, R: 0.0000)
Batch 12500/18276: Loss = 1.2540 (C: 1.2540, R: 0.0000)
Batch 12600/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 12700/18276: Loss = 1.4972 (C: 1.4972, R: 0.0000)
Batch 12800/18276: Loss = 1.7507 (C: 1.7507, R: 0.0000)
Batch 12900/18276: Loss = 1.3542 (C: 1.3542, R: 0.0000)
Batch 13000/18276: Loss = 1.6590 (C: 1.6590, R: 0.0000)
Batch 13100/18276: Loss = 1.4876 (C: 1.4876, R: 0.0000)
Batch 13200/18276: Loss = 1.1444 (C: 1.1444, R: 0.0000)
Batch 13300/18276: Loss = 1.1541 (C: 1.1541, R: 0.0000)
Batch 13400/18276: Loss = 1.7070 (C: 1.7070, R: 0.0000)
Batch 13500/18276: Loss = 1.5701 (C: 1.5701, R: 0.0000)
Batch 13600/18276: Loss = 1.4049 (C: 1.4049, R: 0.0000)
Batch 13700/18276: Loss = 1.0223 (C: 1.0223, R: 0.0000)
Batch 13800/18276: Loss = 1.2730 (C: 1.2730, R: 0.0000)
Batch 13900/18276: Loss = 1.5474 (C: 1.5474, R: 0.0000)
Batch 14000/18276: Loss = 1.2778 (C: 1.2778, R: 0.0000)
Batch 14100/18276: Loss = 1.9614 (C: 1.9614, R: 0.0000)
Batch 14200/18276: Loss = 1.0539 (C: 1.0539, R: 0.0000)
Batch 14300/18276: Loss = 1.3133 (C: 1.3133, R: 0.0000)
Batch 14400/18276: Loss = 0.9781 (C: 0.9781, R: 0.0000)
Batch 14500/18276: Loss = 1.4092 (C: 1.4092, R: 0.0000)
Batch 14600/18276: Loss = 1.4190 (C: 1.4190, R: 0.0000)
Batch 14700/18276: Loss = 1.5000 (C: 1.5000, R: 0.0000)
Batch 14800/18276: Loss = 1.4890 (C: 1.4890, R: 0.0000)
Batch 14900/18276: Loss = 1.4858 (C: 1.4858, R: 0.0000)
Batch 15000/18276: Loss = 1.3258 (C: 1.3258, R: 0.0000)
Batch 15100/18276: Loss = 1.1442 (C: 1.1442, R: 0.0000)
Batch 15200/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 15300/18276: Loss = 1.4004 (C: 1.4004, R: 0.0000)
Batch 15400/18276: Loss = 1.5769 (C: 1.5769, R: 0.0000)
Batch 15500/18276: Loss = 1.3949 (C: 1.3949, R: 0.0000)
Batch 15600/18276: Loss = 1.6017 (C: 1.6017, R: 0.0000)
Batch 15700/18276: Loss = 1.0565 (C: 1.0565, R: 0.0000)
Batch 15800/18276: Loss = 1.6553 (C: 1.6553, R: 0.0000)
Batch 15900/18276: Loss = 1.0640 (C: 1.0640, R: 0.0000)
Batch 16000/18276: Loss = 1.3643 (C: 1.3643, R: 0.0000)
Batch 16100/18276: Loss = 2.0019 (C: 2.0019, R: 0.0000)
Batch 16200/18276: Loss = 1.2026 (C: 1.2026, R: 0.0000)
Batch 16300/18276: Loss = 1.7943 (C: 1.7943, R: 0.0000)
Batch 16400/18276: Loss = 1.3549 (C: 1.3549, R: 0.0000)
Batch 16500/18276: Loss = 1.5414 (C: 1.5414, R: 0.0000)
Batch 16600/18276: Loss = 1.0679 (C: 1.0679, R: 0.0000)
Batch 16700/18276: Loss = 1.5692 (C: 1.5692, R: 0.0000)
Batch 16800/18276: Loss = 1.3560 (C: 1.3560, R: 0.0000)
Batch 16900/18276: Loss = 1.8979 (C: 1.8979, R: 0.0000)
Batch 17000/18276: Loss = 1.8267 (C: 1.8267, R: 0.0000)
Batch 17100/18276: Loss = 1.8837 (C: 1.8837, R: 0.0000)
Batch 17200/18276: Loss = 1.7075 (C: 1.7075, R: 0.0000)
Batch 17300/18276: Loss = 1.2773 (C: 1.2773, R: 0.0000)
Batch 17400/18276: Loss = 1.2949 (C: 1.2949, R: 0.0000)
Batch 17500/18276: Loss = 1.2356 (C: 1.2356, R: 0.0000)
Batch 17600/18276: Loss = 1.7107 (C: 1.7107, R: 0.0000)
Batch 17700/18276: Loss = 1.4884 (C: 1.4884, R: 0.0000)
Batch 17800/18276: Loss = 1.5794 (C: 1.5794, R: 0.0000)
Batch 17900/18276: Loss = 1.4177 (C: 1.4177, R: 0.0000)
Batch 18000/18276: Loss = 1.2057 (C: 1.2057, R: 0.0000)
Batch 18100/18276: Loss = 1.1766 (C: 1.1766, R: 0.0000)
Batch 18200/18276: Loss = 1.4015 (C: 1.4015, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.003189206123352
  reconstruction_loss raw: 0.0
  total_loss raw: 1.003189206123352
Epoch 22 completed in 71.20s
Train Loss: 1.4454 (C: 1.4454)
Val Loss: 1.4343 (C: 1.4343)
No improvement for 8 epochs

Epoch 23/50
------------------------------
Batch 0/18276: Loss = 1.5604 (C: 1.5604, R: 0.0000)
Batch 100/18276: Loss = 1.4864 (C: 1.4864, R: 0.0000)
Batch 200/18276: Loss = 1.6945 (C: 1.6945, R: 0.0000)
Batch 300/18276: Loss = 1.4179 (C: 1.4179, R: 0.0000)
Batch 400/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 500/18276: Loss = 1.7028 (C: 1.7028, R: 0.0000)
Batch 600/18276: Loss = 1.5487 (C: 1.5487, R: 0.0000)
Batch 700/18276: Loss = 1.4003 (C: 1.4003, R: 0.0000)
Batch 800/18276: Loss = 1.4053 (C: 1.4053, R: 0.0000)
Batch 900/18276: Loss = 1.5691 (C: 1.5691, R: 0.0000)
Batch 1000/18276: Loss = 1.2355 (C: 1.2355, R: 0.0000)
Batch 1100/18276: Loss = 1.2373 (C: 1.2373, R: 0.0000)
Batch 1200/18276: Loss = 1.7762 (C: 1.7762, R: 0.0000)
Batch 1300/18276: Loss = 1.2052 (C: 1.2052, R: 0.0000)
Batch 1400/18276: Loss = 1.5956 (C: 1.5956, R: 0.0000)
Batch 1500/18276: Loss = 1.5947 (C: 1.5947, R: 0.0000)
Batch 1600/18276: Loss = 1.1461 (C: 1.1461, R: 0.0000)
Batch 1700/18276: Loss = 1.5778 (C: 1.5778, R: 0.0000)
Batch 1800/18276: Loss = 1.5792 (C: 1.5792, R: 0.0000)
Batch 1900/18276: Loss = 1.5335 (C: 1.5335, R: 0.0000)
Batch 2000/18276: Loss = 0.9781 (C: 0.9781, R: 0.0000)
Batch 2100/18276: Loss = 1.7022 (C: 1.7022, R: 0.0000)
Batch 2200/18276: Loss = 1.9345 (C: 1.9345, R: 0.0000)
Batch 2300/18276: Loss = 1.4604 (C: 1.4604, R: 0.0000)
Batch 2400/18276: Loss = 1.8310 (C: 1.8310, R: 0.0000)
Batch 2500/18276: Loss = 1.6496 (C: 1.6496, R: 0.0000)
Batch 2600/18276: Loss = 1.5064 (C: 1.5064, R: 0.0000)
Batch 2700/18276: Loss = 1.5478 (C: 1.5478, R: 0.0000)
Batch 2800/18276: Loss = 1.7025 (C: 1.7025, R: 0.0000)
Batch 2900/18276: Loss = 1.5495 (C: 1.5495, R: 0.0000)
Batch 3000/18276: Loss = 1.5537 (C: 1.5537, R: 0.0000)
Batch 3100/18276: Loss = 1.9373 (C: 1.9373, R: 0.0000)
Batch 3200/18276: Loss = 1.2076 (C: 1.2076, R: 0.0000)
Batch 3300/18276: Loss = 1.2912 (C: 1.2912, R: 0.0000)
Batch 3400/18276: Loss = 1.2614 (C: 1.2614, R: 0.0000)
Batch 3500/18276: Loss = 1.0243 (C: 1.0243, R: 0.0000)
Batch 3600/18276: Loss = 1.4097 (C: 1.4097, R: 0.0000)
Batch 3700/18276: Loss = 1.5597 (C: 1.5597, R: 0.0000)
Batch 3800/18276: Loss = 1.6527 (C: 1.6527, R: 0.0000)
Batch 3900/18276: Loss = 1.4786 (C: 1.4786, R: 0.0000)
Batch 4000/18276: Loss = 1.2309 (C: 1.2309, R: 0.0000)
Batch 4100/18276: Loss = 1.2366 (C: 1.2366, R: 0.0000)
Batch 4200/18276: Loss = 1.4132 (C: 1.4132, R: 0.0000)
Batch 4300/18276: Loss = 1.8240 (C: 1.8240, R: 0.0000)
Batch 4400/18276: Loss = 1.1237 (C: 1.1237, R: 0.0000)
Batch 4500/18276: Loss = 0.9781 (C: 0.9781, R: 0.0000)
Batch 4600/18276: Loss = 1.5792 (C: 1.5792, R: 0.0000)
Batch 4700/18276: Loss = 1.7089 (C: 1.7089, R: 0.0000)
Batch 4800/18276: Loss = 1.8127 (C: 1.8127, R: 0.0000)
Batch 4900/18276: Loss = 1.5466 (C: 1.5466, R: 0.0000)
Batch 5000/18276: Loss = 1.5253 (C: 1.5253, R: 0.0000)
Batch 5100/18276: Loss = 1.5685 (C: 1.5685, R: 0.0000)
Batch 5200/18276: Loss = 1.1525 (C: 1.1525, R: 0.0000)
Batch 5300/18276: Loss = 1.5176 (C: 1.5176, R: 0.0000)
Batch 5400/18276: Loss = 1.8364 (C: 1.8364, R: 0.0000)
Batch 5500/18276: Loss = 1.0629 (C: 1.0629, R: 0.0000)
Batch 5600/18276: Loss = 1.5484 (C: 1.5484, R: 0.0000)
Batch 5700/18276: Loss = 1.4076 (C: 1.4076, R: 0.0000)
Batch 5800/18276: Loss = 1.2728 (C: 1.2728, R: 0.0000)
Batch 5900/18276: Loss = 1.5478 (C: 1.5478, R: 0.0000)
Batch 6000/18276: Loss = 0.9852 (C: 0.9852, R: 0.0000)
Batch 6100/18276: Loss = 1.4016 (C: 1.4016, R: 0.0000)
Batch 6200/18276: Loss = 1.2360 (C: 1.2360, R: 0.0000)
Batch 6300/18276: Loss = 1.7197 (C: 1.7197, R: 0.0000)
Batch 6400/18276: Loss = 1.7838 (C: 1.7838, R: 0.0000)
Batch 6500/18276: Loss = 1.2936 (C: 1.2936, R: 0.0000)
Batch 6600/18276: Loss = 1.5816 (C: 1.5816, R: 0.0000)
Batch 6700/18276: Loss = 1.0382 (C: 1.0382, R: 0.0000)
Batch 6800/18276: Loss = 0.9799 (C: 0.9799, R: 0.0000)
Batch 6900/18276: Loss = 1.4407 (C: 1.4407, R: 0.0000)
Batch 7000/18276: Loss = 1.2670 (C: 1.2670, R: 0.0000)
Batch 7100/18276: Loss = 1.2064 (C: 1.2064, R: 0.0000)
Batch 7200/18276: Loss = 1.5480 (C: 1.5480, R: 0.0000)
Batch 7300/18276: Loss = 1.5915 (C: 1.5915, R: 0.0000)
Batch 7400/18276: Loss = 1.1442 (C: 1.1442, R: 0.0000)
Batch 7500/18276: Loss = 1.2364 (C: 1.2364, R: 0.0000)
Batch 7600/18276: Loss = 1.7536 (C: 1.7536, R: 0.0000)
Batch 7700/18276: Loss = 1.7923 (C: 1.7923, R: 0.0000)
Batch 7800/18276: Loss = 1.2908 (C: 1.2908, R: 0.0000)
Batch 7900/18276: Loss = 1.2048 (C: 1.2048, R: 0.0000)
Batch 8000/18276: Loss = 1.2374 (C: 1.2374, R: 0.0000)
Batch 8100/18276: Loss = 1.8376 (C: 1.8376, R: 0.0000)
Batch 8200/18276: Loss = 1.2374 (C: 1.2374, R: 0.0000)
Batch 8300/18276: Loss = 1.5471 (C: 1.5471, R: 0.0000)
Batch 8400/18276: Loss = 1.9953 (C: 1.9953, R: 0.0000)
Batch 8500/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 8600/18276: Loss = 1.3620 (C: 1.3620, R: 0.0000)
Batch 8700/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 8800/18276: Loss = 1.4406 (C: 1.4406, R: 0.0000)
Batch 8900/18276: Loss = 1.1577 (C: 1.1577, R: 0.0000)
Batch 9000/18276: Loss = 1.4240 (C: 1.4240, R: 0.0000)
Batch 9100/18276: Loss = 1.8159 (C: 1.8159, R: 0.0000)
Batch 9200/18276: Loss = 1.7004 (C: 1.7004, R: 0.0000)
Batch 9300/18276: Loss = 1.4080 (C: 1.4080, R: 0.0000)
Batch 9400/18276: Loss = 1.0370 (C: 1.0370, R: 0.0000)
Batch 9500/18276: Loss = 1.2369 (C: 1.2369, R: 0.0000)
Batch 9600/18276: Loss = 1.7201 (C: 1.7201, R: 0.0000)
Batch 9700/18276: Loss = 1.5731 (C: 1.5731, R: 0.0000)
Batch 9800/18276: Loss = 1.2774 (C: 1.2774, R: 0.0000)
Batch 9900/18276: Loss = 1.7138 (C: 1.7138, R: 0.0000)
Batch 10000/18276: Loss = 1.5730 (C: 1.5730, R: 0.0000)
Batch 10100/18276: Loss = 1.5802 (C: 1.5802, R: 0.0000)
Batch 10200/18276: Loss = 1.3646 (C: 1.3646, R: 0.0000)
Batch 10300/18276: Loss = 1.5501 (C: 1.5501, R: 0.0000)
Batch 10400/18276: Loss = 1.4882 (C: 1.4882, R: 0.0000)
Batch 10500/18276: Loss = 1.5802 (C: 1.5802, R: 0.0000)
Batch 10600/18276: Loss = 1.4195 (C: 1.4195, R: 0.0000)
Batch 10700/18276: Loss = 1.4253 (C: 1.4253, R: 0.0000)
Batch 10800/18276: Loss = 1.7062 (C: 1.7062, R: 0.0000)
Batch 10900/18276: Loss = 1.2060 (C: 1.2060, R: 0.0000)
Batch 11000/18276: Loss = 1.2976 (C: 1.2976, R: 0.0000)
Batch 11100/18276: Loss = 1.3547 (C: 1.3547, R: 0.0000)
Batch 11200/18276: Loss = 1.2910 (C: 1.2910, R: 0.0000)
Batch 11300/18276: Loss = 1.6751 (C: 1.6751, R: 0.0000)
Batch 11400/18276: Loss = 1.5681 (C: 1.5681, R: 0.0000)
Batch 11500/18276: Loss = 1.3660 (C: 1.3660, R: 0.0000)
Batch 11600/18276: Loss = 1.5684 (C: 1.5684, R: 0.0000)
Batch 11700/18276: Loss = 1.8784 (C: 1.8784, R: 0.0000)
Batch 11800/18276: Loss = 1.3661 (C: 1.3661, R: 0.0000)
Batch 11900/18276: Loss = 1.4101 (C: 1.4101, R: 0.0000)
Batch 12000/18276: Loss = 1.4308 (C: 1.4308, R: 0.0000)
Batch 12100/18276: Loss = 1.0587 (C: 1.0587, R: 0.0000)
Batch 12200/18276: Loss = 1.7023 (C: 1.7023, R: 0.0000)
Batch 12300/18276: Loss = 1.5441 (C: 1.5441, R: 0.0000)
Batch 12400/18276: Loss = 1.3694 (C: 1.3694, R: 0.0000)
Batch 12500/18276: Loss = 1.6549 (C: 1.6549, R: 0.0000)
Batch 12600/18276: Loss = 1.0832 (C: 1.0832, R: 0.0000)
Batch 12700/18276: Loss = 1.6978 (C: 1.6978, R: 0.0000)
Batch 12800/18276: Loss = 1.4025 (C: 1.4025, R: 0.0000)
Batch 12900/18276: Loss = 1.2755 (C: 1.2755, R: 0.0000)
Batch 13000/18276: Loss = 1.2934 (C: 1.2934, R: 0.0000)
Batch 13100/18276: Loss = 1.3731 (C: 1.3731, R: 0.0000)
Batch 13200/18276: Loss = 1.3554 (C: 1.3554, R: 0.0000)
Batch 13300/18276: Loss = 1.5726 (C: 1.5726, R: 0.0000)
Batch 13400/18276: Loss = 0.9782 (C: 0.9782, R: 0.0000)
Batch 13500/18276: Loss = 1.1992 (C: 1.1992, R: 0.0000)
Batch 13600/18276: Loss = 1.5484 (C: 1.5484, R: 0.0000)
Batch 13700/18276: Loss = 1.3691 (C: 1.3691, R: 0.0000)
Batch 13800/18276: Loss = 1.4016 (C: 1.4016, R: 0.0000)
Batch 13900/18276: Loss = 1.0227 (C: 1.0227, R: 0.0000)
Batch 14000/18276: Loss = 1.2096 (C: 1.2096, R: 0.0000)
Batch 14100/18276: Loss = 1.4084 (C: 1.4084, R: 0.0000)
Batch 14200/18276: Loss = 1.1990 (C: 1.1990, R: 0.0000)
Batch 14300/18276: Loss = 1.4670 (C: 1.4670, R: 0.0000)
Batch 14400/18276: Loss = 1.5713 (C: 1.5713, R: 0.0000)
Batch 14500/18276: Loss = 1.0228 (C: 1.0228, R: 0.0000)
Batch 14600/18276: Loss = 1.6549 (C: 1.6549, R: 0.0000)
Batch 14700/18276: Loss = 1.3642 (C: 1.3642, R: 0.0000)
Batch 14800/18276: Loss = 1.2916 (C: 1.2916, R: 0.0000)
Batch 14900/18276: Loss = 1.0536 (C: 1.0536, R: 0.0000)
Batch 15000/18276: Loss = 1.2048 (C: 1.2048, R: 0.0000)
Batch 15100/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 15200/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 15300/18276: Loss = 1.3604 (C: 1.3604, R: 0.0000)
Batch 15400/18276: Loss = 1.2569 (C: 1.2569, R: 0.0000)
Batch 15500/18276: Loss = 1.5807 (C: 1.5807, R: 0.0000)
Batch 15600/18276: Loss = 0.9479 (C: 0.9479, R: 0.0000)
Batch 15700/18276: Loss = 1.5735 (C: 1.5735, R: 0.0000)
Batch 15800/18276: Loss = 1.7925 (C: 1.7925, R: 0.0000)
Batch 15900/18276: Loss = 1.2376 (C: 1.2376, R: 0.0000)
Batch 16000/18276: Loss = 1.8110 (C: 1.8110, R: 0.0000)
Batch 16100/18276: Loss = 1.6516 (C: 1.6516, R: 0.0000)
Batch 16200/18276: Loss = 1.1957 (C: 1.1957, R: 0.0000)
Batch 16300/18276: Loss = 0.9455 (C: 0.9455, R: 0.0000)
Batch 16400/18276: Loss = 1.6980 (C: 1.6980, R: 0.0000)
Batch 16500/18276: Loss = 1.0565 (C: 1.0565, R: 0.0000)
Batch 16600/18276: Loss = 1.0239 (C: 1.0239, R: 0.0000)
Batch 16700/18276: Loss = 1.2048 (C: 1.2048, R: 0.0000)
Batch 16800/18276: Loss = 1.6982 (C: 1.6982, R: 0.0000)
Batch 16900/18276: Loss = 0.9833 (C: 0.9833, R: 0.0000)
Batch 17000/18276: Loss = 1.2289 (C: 1.2289, R: 0.0000)
Batch 17100/18276: Loss = 1.4712 (C: 1.4712, R: 0.0000)
Batch 17200/18276: Loss = 1.2096 (C: 1.2096, R: 0.0000)
Batch 17300/18276: Loss = 1.5797 (C: 1.5797, R: 0.0000)
Batch 17400/18276: Loss = 1.2922 (C: 1.2922, R: 0.0000)
Batch 17500/18276: Loss = 0.9040 (C: 0.9040, R: 0.0000)
Batch 17600/18276: Loss = 1.5434 (C: 1.5434, R: 0.0000)
Batch 17700/18276: Loss = 1.1443 (C: 1.1443, R: 0.0000)
Batch 17800/18276: Loss = 1.2768 (C: 1.2768, R: 0.0000)
Batch 17900/18276: Loss = 1.6217 (C: 1.6217, R: 0.0000)
Batch 18000/18276: Loss = 1.4915 (C: 1.4915, R: 0.0000)
Batch 18100/18276: Loss = 1.7067 (C: 1.7067, R: 0.0000)
Batch 18200/18276: Loss = 1.6876 (C: 1.6876, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.091299295425415
  reconstruction_loss raw: 0.0
  total_loss raw: 1.091299295425415
Epoch 23 completed in 71.07s
Train Loss: 1.4387 (C: 1.4387)
Val Loss: 1.4227 (C: 1.4227)
No improvement for 9 epochs

Epoch 24/50
------------------------------
Batch 0/18276: Loss = 1.6806 (C: 1.6806, R: 0.0000)
Batch 100/18276: Loss = 1.4193 (C: 1.4193, R: 0.0000)
Batch 200/18276: Loss = 1.1457 (C: 1.1457, R: 0.0000)
Batch 300/18276: Loss = 1.5488 (C: 1.5488, R: 0.0000)
Batch 400/18276: Loss = 1.4015 (C: 1.4015, R: 0.0000)
Batch 500/18276: Loss = 1.7444 (C: 1.7444, R: 0.0000)
Batch 600/18276: Loss = 1.4113 (C: 1.4113, R: 0.0000)
Batch 700/18276: Loss = 1.0539 (C: 1.0539, R: 0.0000)
Batch 800/18276: Loss = 1.7453 (C: 1.7453, R: 0.0000)
Batch 900/18276: Loss = 1.2373 (C: 1.2373, R: 0.0000)
Batch 1000/18276: Loss = 1.4088 (C: 1.4088, R: 0.0000)
Batch 1100/18276: Loss = 1.2425 (C: 1.2425, R: 0.0000)
Batch 1200/18276: Loss = 1.2356 (C: 1.2356, R: 0.0000)
Batch 1300/18276: Loss = 1.1441 (C: 1.1441, R: 0.0000)
Batch 1400/18276: Loss = 1.2946 (C: 1.2946, R: 0.0000)
Batch 1500/18276: Loss = 1.0051 (C: 1.0051, R: 0.0000)
Batch 1600/18276: Loss = 1.0616 (C: 1.0616, R: 0.0000)
Batch 1700/18276: Loss = 1.9620 (C: 1.9620, R: 0.0000)
Batch 1800/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 1900/18276: Loss = 1.8387 (C: 1.8387, R: 0.0000)
Batch 2000/18276: Loss = 1.4077 (C: 1.4077, R: 0.0000)
Batch 2100/18276: Loss = 1.2369 (C: 1.2369, R: 0.0000)
Batch 2200/18276: Loss = 1.5684 (C: 1.5684, R: 0.0000)
Batch 2300/18276: Loss = 1.4744 (C: 1.4744, R: 0.0000)
Batch 2400/18276: Loss = 1.4893 (C: 1.4893, R: 0.0000)
Batch 2500/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 2600/18276: Loss = 0.9069 (C: 0.9069, R: 0.0000)
Batch 2700/18276: Loss = 1.5533 (C: 1.5533, R: 0.0000)
Batch 2800/18276: Loss = 1.2117 (C: 1.2117, R: 0.0000)
Batch 2900/18276: Loss = 1.0584 (C: 1.0584, R: 0.0000)
Batch 3000/18276: Loss = 1.5697 (C: 1.5697, R: 0.0000)
Batch 3100/18276: Loss = 1.2345 (C: 1.2345, R: 0.0000)
Batch 3200/18276: Loss = 1.2057 (C: 1.2057, R: 0.0000)
Batch 3300/18276: Loss = 1.4234 (C: 1.4234, R: 0.0000)
Batch 3400/18276: Loss = 1.8286 (C: 1.8286, R: 0.0000)
Batch 3500/18276: Loss = 1.4042 (C: 1.4042, R: 0.0000)
Batch 3600/18276: Loss = 1.5524 (C: 1.5524, R: 0.0000)
Batch 3700/18276: Loss = 1.6213 (C: 1.6213, R: 0.0000)
Batch 3800/18276: Loss = 1.4103 (C: 1.4103, R: 0.0000)
Batch 3900/18276: Loss = 1.8111 (C: 1.8111, R: 0.0000)
Batch 4000/18276: Loss = 1.0598 (C: 1.0598, R: 0.0000)
Batch 4100/18276: Loss = 1.4101 (C: 1.4101, R: 0.0000)
Batch 4200/18276: Loss = 1.8388 (C: 1.8388, R: 0.0000)
Batch 4300/18276: Loss = 1.6654 (C: 1.6654, R: 0.0000)
Batch 4400/18276: Loss = 1.1958 (C: 1.1958, R: 0.0000)
Batch 4500/18276: Loss = 1.3646 (C: 1.3646, R: 0.0000)
Batch 4600/18276: Loss = 1.0378 (C: 1.0378, R: 0.0000)
Batch 4700/18276: Loss = 1.2373 (C: 1.2373, R: 0.0000)
Batch 4800/18276: Loss = 1.7451 (C: 1.7451, R: 0.0000)
Batch 4900/18276: Loss = 1.2377 (C: 1.2377, R: 0.0000)
Batch 5000/18276: Loss = 1.8057 (C: 1.8057, R: 0.0000)
Batch 5100/18276: Loss = 1.4225 (C: 1.4225, R: 0.0000)
Batch 5200/18276: Loss = 1.4075 (C: 1.4075, R: 0.0000)
Batch 5300/18276: Loss = 1.5795 (C: 1.5795, R: 0.0000)
Batch 5400/18276: Loss = 1.3972 (C: 1.3972, R: 0.0000)
Batch 5500/18276: Loss = 1.2767 (C: 1.2767, R: 0.0000)
Batch 5600/18276: Loss = 1.4017 (C: 1.4017, R: 0.0000)
Batch 5700/18276: Loss = 1.5694 (C: 1.5694, R: 0.0000)
Batch 5800/18276: Loss = 1.3544 (C: 1.3544, R: 0.0000)
Batch 5900/18276: Loss = 1.5223 (C: 1.5223, R: 0.0000)
Batch 6000/18276: Loss = 1.7058 (C: 1.7058, R: 0.0000)
Batch 6100/18276: Loss = 1.2358 (C: 1.2358, R: 0.0000)
Batch 6200/18276: Loss = 1.5923 (C: 1.5923, R: 0.0000)
Batch 6300/18276: Loss = 1.6671 (C: 1.6671, R: 0.0000)
Batch 6400/18276: Loss = 1.5688 (C: 1.5688, R: 0.0000)
Batch 6500/18276: Loss = 1.6364 (C: 1.6364, R: 0.0000)
Batch 6600/18276: Loss = 1.5763 (C: 1.5763, R: 0.0000)
Batch 6700/18276: Loss = 1.2357 (C: 1.2357, R: 0.0000)
Batch 6800/18276: Loss = 1.3458 (C: 1.3458, R: 0.0000)
Batch 6900/18276: Loss = 1.4711 (C: 1.4711, R: 0.0000)
Batch 7000/18276: Loss = 1.8002 (C: 1.8002, R: 0.0000)
Batch 7100/18276: Loss = 1.7616 (C: 1.7616, R: 0.0000)
Batch 7200/18276: Loss = 1.5540 (C: 1.5540, R: 0.0000)
Batch 7300/18276: Loss = 1.6116 (C: 1.6116, R: 0.0000)
Batch 7400/18276: Loss = 1.7055 (C: 1.7055, R: 0.0000)
Batch 7500/18276: Loss = 1.6651 (C: 1.6651, R: 0.0000)
Batch 7600/18276: Loss = 1.0378 (C: 1.0378, R: 0.0000)
Batch 7700/18276: Loss = 1.5956 (C: 1.5956, R: 0.0000)
Batch 7800/18276: Loss = 1.1263 (C: 1.1263, R: 0.0000)
Batch 7900/18276: Loss = 1.5350 (C: 1.5350, R: 0.0000)
Batch 8000/18276: Loss = 1.2775 (C: 1.2775, R: 0.0000)
Batch 8100/18276: Loss = 1.4063 (C: 1.4063, R: 0.0000)
Batch 8200/18276: Loss = 1.2162 (C: 1.2162, R: 0.0000)
Batch 8300/18276: Loss = 1.4953 (C: 1.4953, R: 0.0000)
Batch 8400/18276: Loss = 1.5529 (C: 1.5529, R: 0.0000)
Batch 8500/18276: Loss = 1.3647 (C: 1.3647, R: 0.0000)
Batch 8600/18276: Loss = 1.2097 (C: 1.2097, R: 0.0000)
Batch 8700/18276: Loss = 1.2101 (C: 1.2101, R: 0.0000)
Batch 8800/18276: Loss = 1.1869 (C: 1.1869, R: 0.0000)
Batch 8900/18276: Loss = 1.4090 (C: 1.4090, R: 0.0000)
Batch 9000/18276: Loss = 1.1514 (C: 1.1514, R: 0.0000)
Batch 9100/18276: Loss = 1.2090 (C: 1.2090, R: 0.0000)
Batch 9200/18276: Loss = 1.5824 (C: 1.5824, R: 0.0000)
Batch 9300/18276: Loss = 1.5950 (C: 1.5950, R: 0.0000)
Batch 9400/18276: Loss = 1.4074 (C: 1.4074, R: 0.0000)
Batch 9500/18276: Loss = 1.5733 (C: 1.5733, R: 0.0000)
Batch 9600/18276: Loss = 1.5472 (C: 1.5472, R: 0.0000)
Batch 9700/18276: Loss = 1.5744 (C: 1.5744, R: 0.0000)
Batch 9800/18276: Loss = 1.0371 (C: 1.0371, R: 0.0000)
Batch 9900/18276: Loss = 1.4360 (C: 1.4360, R: 0.0000)
Batch 10000/18276: Loss = 1.5524 (C: 1.5524, R: 0.0000)
Batch 10100/18276: Loss = 1.5738 (C: 1.5738, R: 0.0000)
Batch 10200/18276: Loss = 1.5359 (C: 1.5359, R: 0.0000)
Batch 10300/18276: Loss = 1.0473 (C: 1.0473, R: 0.0000)
Batch 10400/18276: Loss = 1.5809 (C: 1.5809, R: 0.0000)
Batch 10500/18276: Loss = 1.5523 (C: 1.5523, R: 0.0000)
Batch 10600/18276: Loss = 1.4194 (C: 1.4194, R: 0.0000)
Batch 10700/18276: Loss = 1.5699 (C: 1.5699, R: 0.0000)
Batch 10800/18276: Loss = 0.9839 (C: 0.9839, R: 0.0000)
Batch 10900/18276: Loss = 1.7018 (C: 1.7018, R: 0.0000)
Batch 11000/18276: Loss = 1.8062 (C: 1.8062, R: 0.0000)
Batch 11100/18276: Loss = 1.0232 (C: 1.0232, R: 0.0000)
Batch 11200/18276: Loss = 1.8364 (C: 1.8364, R: 0.0000)
Batch 11300/18276: Loss = 1.7420 (C: 1.7420, R: 0.0000)
Batch 11400/18276: Loss = 1.2774 (C: 1.2774, R: 0.0000)
Batch 11500/18276: Loss = 1.6608 (C: 1.6608, R: 0.0000)
Batch 11600/18276: Loss = 1.5541 (C: 1.5541, R: 0.0000)
Batch 11700/18276: Loss = 1.3672 (C: 1.3672, R: 0.0000)
Batch 11800/18276: Loss = 1.2282 (C: 1.2282, R: 0.0000)
Batch 11900/18276: Loss = 1.4048 (C: 1.4048, R: 0.0000)
Batch 12000/18276: Loss = 1.3543 (C: 1.3543, R: 0.0000)
Batch 12100/18276: Loss = 0.9887 (C: 0.9887, R: 0.0000)
Batch 12200/18276: Loss = 1.4716 (C: 1.4716, R: 0.0000)
Batch 12300/18276: Loss = 1.1943 (C: 1.1943, R: 0.0000)
Batch 12400/18276: Loss = 1.8058 (C: 1.8058, R: 0.0000)
Batch 12500/18276: Loss = 1.2918 (C: 1.2918, R: 0.0000)
Batch 12600/18276: Loss = 1.4414 (C: 1.4414, R: 0.0000)
Batch 12700/18276: Loss = 1.4721 (C: 1.4721, R: 0.0000)
Batch 12800/18276: Loss = 1.4093 (C: 1.4093, R: 0.0000)
Batch 12900/18276: Loss = 1.8145 (C: 1.8145, R: 0.0000)
Batch 13000/18276: Loss = 1.5803 (C: 1.5803, R: 0.0000)
Batch 13100/18276: Loss = 1.4050 (C: 1.4050, R: 0.0000)
Batch 13200/18276: Loss = 1.4091 (C: 1.4091, R: 0.0000)
Batch 13300/18276: Loss = 1.3662 (C: 1.3662, R: 0.0000)
Batch 13400/18276: Loss = 1.2372 (C: 1.2372, R: 0.0000)
Batch 13500/18276: Loss = 1.6635 (C: 1.6635, R: 0.0000)
Batch 13600/18276: Loss = 1.3740 (C: 1.3740, R: 0.0000)
Batch 13700/18276: Loss = 1.5351 (C: 1.5351, R: 0.0000)
Batch 13800/18276: Loss = 1.5506 (C: 1.5506, R: 0.0000)
Batch 13900/18276: Loss = 1.4020 (C: 1.4020, R: 0.0000)
Batch 14000/18276: Loss = 1.2357 (C: 1.2357, R: 0.0000)
Batch 14100/18276: Loss = 1.4080 (C: 1.4080, R: 0.0000)
Batch 14200/18276: Loss = 1.5747 (C: 1.5747, R: 0.0000)
Batch 14300/18276: Loss = 0.9802 (C: 0.9802, R: 0.0000)
Batch 14400/18276: Loss = 1.5351 (C: 1.5351, R: 0.0000)
Batch 14500/18276: Loss = 1.7451 (C: 1.7451, R: 0.0000)
Batch 14600/18276: Loss = 1.7197 (C: 1.7197, R: 0.0000)
Batch 14700/18276: Loss = 1.5789 (C: 1.5789, R: 0.0000)
Batch 14800/18276: Loss = 1.2099 (C: 1.2099, R: 0.0000)
Batch 14900/18276: Loss = 1.8102 (C: 1.8102, R: 0.0000)
Batch 15000/18276: Loss = 1.2288 (C: 1.2288, R: 0.0000)
Batch 15100/18276: Loss = 1.6644 (C: 1.6644, R: 0.0000)
Batch 15200/18276: Loss = 1.4194 (C: 1.4194, R: 0.0000)
Batch 15300/18276: Loss = 1.2099 (C: 1.2099, R: 0.0000)
Batch 15400/18276: Loss = 1.5941 (C: 1.5941, R: 0.0000)
Batch 15500/18276: Loss = 1.5828 (C: 1.5828, R: 0.0000)
Batch 15600/18276: Loss = 1.2052 (C: 1.2052, R: 0.0000)
Batch 15700/18276: Loss = 1.5138 (C: 1.5138, R: 0.0000)
Batch 15800/18276: Loss = 1.6359 (C: 1.6359, R: 0.0000)
Batch 15900/18276: Loss = 1.4018 (C: 1.4018, R: 0.0000)
Batch 16000/18276: Loss = 1.4910 (C: 1.4910, R: 0.0000)
Batch 16100/18276: Loss = 1.7001 (C: 1.7001, R: 0.0000)
Batch 16200/18276: Loss = 1.2745 (C: 1.2745, R: 0.0000)
Batch 16300/18276: Loss = 1.5440 (C: 1.5440, R: 0.0000)
Batch 16400/18276: Loss = 1.5781 (C: 1.5781, R: 0.0000)
Batch 16500/18276: Loss = 1.4636 (C: 1.4636, R: 0.0000)
Batch 16600/18276: Loss = 1.0287 (C: 1.0287, R: 0.0000)
Batch 16700/18276: Loss = 1.6890 (C: 1.6890, R: 0.0000)
Batch 16800/18276: Loss = 1.4598 (C: 1.4598, R: 0.0000)
Batch 16900/18276: Loss = 1.8317 (C: 1.8317, R: 0.0000)
Batch 17000/18276: Loss = 1.7027 (C: 1.7027, R: 0.0000)
Batch 17100/18276: Loss = 1.5678 (C: 1.5678, R: 0.0000)
Batch 17200/18276: Loss = 1.4963 (C: 1.4963, R: 0.0000)
Batch 17300/18276: Loss = 1.5799 (C: 1.5799, R: 0.0000)
Batch 17400/18276: Loss = 1.5375 (C: 1.5375, R: 0.0000)
Batch 17500/18276: Loss = 1.2049 (C: 1.2049, R: 0.0000)
Batch 17600/18276: Loss = 1.2055 (C: 1.2055, R: 0.0000)
Batch 17700/18276: Loss = 1.7434 (C: 1.7434, R: 0.0000)
Batch 17800/18276: Loss = 1.4166 (C: 1.4166, R: 0.0000)
Batch 17900/18276: Loss = 1.2361 (C: 1.2361, R: 0.0000)
Batch 18000/18276: Loss = 1.5567 (C: 1.5567, R: 0.0000)
Batch 18100/18276: Loss = 1.3972 (C: 1.3972, R: 0.0000)
Batch 18200/18276: Loss = 1.4817 (C: 1.4817, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 1.5509800910949707
  reconstruction_loss raw: 0.0
  total_loss raw: 1.5509800910949707
Epoch 24 completed in 71.03s
Train Loss: 1.4440 (C: 1.4440)
Val Loss: 1.4249 (C: 1.4249)
No improvement for 10 epochs
Early stopping triggered after 24 epochs

Simplified training completed!
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/final_model.pt
Training history saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/training_history_20250711_234054.json
Training completed!
Best model saved at epoch 14
Best validation loss: 1.415994
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/checkpoints/best_model.pt
Starting model evaluation...
==================================================
Evaluator initialized on device: cuda
Starting comprehensive evaluation...
==================================================
Extracting latent representations...
Extracted 9824 latent representations
Evaluating clustering performance...
Clustering Results:
  Silhouette Score: 0.1039
  Adjusted Rand Score: 0.2374
  Clustering Accuracy: 0.6146
Evaluating Phase 1 style clustering (group-level)...
Created 4 groups for entailment (group size: 1000)
Created 4 groups for neutral (group size: 1000)
Created 4 groups for contradiction (group size: 1000)
Phase 1 Style Clustering Results:
  Group-level Silhouette Score: 0.9529
  Group-level Clustering Accuracy: 1.0000
  Group-level Adjusted Rand Score: 1.0000
  Total groups tested: 12
Evaluating classification performance...
Extracting training latent representations...
Extracting latent representations...
Extracted 548280 latent representations
Extracting validation latent representations...
Extracting latent representations...
Extracted 9690 latent representations
Training on 548280 samples, evaluating on 9690 samples
Classification Results:
  Accuracy: 0.5757
  Per-class F1 scores:
    entailment: 0.6170
    neutral: 0.4179
    contradiction: 0.6883
Evaluating reconstruction quality...
Reconstruction Results:
  Average MSE: 2.455349
Evaluating generative capabilities...
Testing contradiction -> entailment transformation...
Generative Results:
  Test samples: 10
  Transformation quality: 1.0000

Comprehensive evaluation completed!

EVALUATION SUMMARY
==================================================
Individual Clustering Performance:
  Silhouette Score: 0.1039
  Clustering Accuracy: 0.6146
  Adjusted Rand Score: 0.2374

Phase 1 Style Clustering Performance:
  Group-level Silhouette Score: 0.9529
  Group-level Clustering Accuracy: 1.0000
  Group-level Adjusted Rand Score: 1.0000
  Total groups tested: 12

Classification Performance:
  Accuracy: 0.5757

Reconstruction Quality:
  Average MSE: 2.455349

Generative Capabilities:
  Transformation Quality: 1.0000

==================================================
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/results/evaluation_results_20250711_234135.json
Evaluation results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/results/evaluation_results_20250711_234135.json
Saving final experiment results...
Final results saved to: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/final_results.json

KEY RESULTS SUMMARY
==================================================
Individual Clustering Accuracy: 0.6146
Phase 1 Style Clustering Accuracy: 1.0000
Classification Accuracy: 0.5757
Reconstruction MSE: 2.455349

PIPELINE COMPLETED SUCCESSFULLY!
Experiment directory: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149
Final results: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250711_231149/final_results.json
Pipeline completed successfully!

Analysis completed with exit code: 0
Time: Fri 11 Jul 23:41:37 BST 2025

=== ANALYSIS SUCCESSFUL ===
Autoencoder pipeline successful!


Job finished.
