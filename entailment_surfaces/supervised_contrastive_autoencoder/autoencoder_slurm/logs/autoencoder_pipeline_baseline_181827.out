Starting Surface Distance Metric Analysis job...
Job ID: 181827
Node: gpuvm15
Time: Sat 12 Jul 11:01:03 BST 2025
Loading CUDA...
Activating conda environment...
Activated conda environment: /vol/bitbucket/ahb24/tda_entailment_new
Python location: /vol/bitbucket/ahb24/tda_entailment_new/bin/python
Checking GPU availability...
Sat Jul 12 11:01:06 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla T4                       Off |   00000000:00:06.0 Off |                    0 |
| N/A   37C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+

Testing PyTorch and CUDA...
PyTorch version: 2.4.1
CUDA available: True
CUDA device: Tesla T4
GPU memory: 15.6 GB
PyTorch setup verified!

Starting AutoEncoder Pipeline...

SUPERVISED CONTRASTIVE AUTOENCODER - FULL PIPELINE
============================================================
Start time: 2025-07-12 11:02:05.103056

Using device: cuda
Experiment setup complete: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250712_110205
Loading SNLI data...
==================================================
Starting data loading pipeline...
==================================================
Loading training data from data/processed/snli_full_standard_SBERT.pt
Loaded 549367 training samples
Loading validation data from data/processed/snli_full_standard_SBERT_validation.pt
Loaded 9842 validation samples
Loading test data from data/processed/snli_full_standard_SBERT_test.pt
Loaded 9824 test samples
Generating lattice containment embeddings for training...
Generating lattice containment embeddings on cuda
Processing 549367 samples in batches of 1000
Processing batch 1/550
Processing batch 2/550
Processing batch 3/550
Processing batch 4/550
Processing batch 5/550
Processing batch 6/550
Processing batch 7/550
Processing batch 8/550
Processing batch 9/550
Processing batch 10/550
Processing batch 11/550
Processing batch 12/550
Processing batch 13/550
Processing batch 14/550
Processing batch 15/550
Processing batch 16/550
Processing batch 17/550
Processing batch 18/550
Processing batch 19/550
Processing batch 20/550
Processing batch 21/550
Processing batch 22/550
Processing batch 23/550
Processing batch 24/550
Processing batch 25/550
Processing batch 26/550
Processing batch 27/550
Processing batch 28/550
Processing batch 29/550
Processing batch 30/550
Processing batch 31/550
Processing batch 32/550
Processing batch 33/550
Processing batch 34/550
Processing batch 35/550
Processing batch 36/550
Processing batch 37/550
Processing batch 38/550
Processing batch 39/550
Processing batch 40/550
Processing batch 41/550
Processing batch 42/550
Processing batch 43/550
Processing batch 44/550
Processing batch 45/550
Processing batch 46/550
Processing batch 47/550
Processing batch 48/550
Processing batch 49/550
Processing batch 50/550
Processing batch 51/550
Processing batch 52/550
Processing batch 53/550
Processing batch 54/550
Processing batch 55/550
Processing batch 56/550
Processing batch 57/550
Processing batch 58/550
Processing batch 59/550
Processing batch 60/550
Processing batch 61/550
Processing batch 62/550
Processing batch 63/550
Processing batch 64/550
Processing batch 65/550
Processing batch 66/550
Processing batch 67/550
Processing batch 68/550
Processing batch 69/550
Processing batch 70/550
Processing batch 71/550
Processing batch 72/550
Processing batch 73/550
Processing batch 74/550
Processing batch 75/550
Processing batch 76/550
Processing batch 77/550
Processing batch 78/550
Processing batch 79/550
Processing batch 80/550
Processing batch 81/550
Processing batch 82/550
Processing batch 83/550
Processing batch 84/550
Processing batch 85/550
Processing batch 86/550
Processing batch 87/550
Processing batch 88/550
Processing batch 89/550
Processing batch 90/550
Processing batch 91/550
Processing batch 92/550
Processing batch 93/550
Processing batch 94/550
Processing batch 95/550
Processing batch 96/550
Processing batch 97/550
Processing batch 98/550
Processing batch 99/550
Processing batch 100/550
Processing batch 101/550
Processing batch 102/550
Processing batch 103/550
Processing batch 104/550
Processing batch 105/550
Processing batch 106/550
Processing batch 107/550
Processing batch 108/550
Processing batch 109/550
Processing batch 110/550
Processing batch 111/550
Processing batch 112/550
Processing batch 113/550
Processing batch 114/550
Processing batch 115/550
Processing batch 116/550
Processing batch 117/550
Processing batch 118/550
Processing batch 119/550
Processing batch 120/550
Processing batch 121/550
Processing batch 122/550
Processing batch 123/550
Processing batch 124/550
Processing batch 125/550
Processing batch 126/550
Processing batch 127/550
Processing batch 128/550
Processing batch 129/550
Processing batch 130/550
Processing batch 131/550
Processing batch 132/550
Processing batch 133/550
Processing batch 134/550
Processing batch 135/550
Processing batch 136/550
Processing batch 137/550
Processing batch 138/550
Processing batch 139/550
Processing batch 140/550
Processing batch 141/550
Processing batch 142/550
Processing batch 143/550
Processing batch 144/550
Processing batch 145/550
Processing batch 146/550
Processing batch 147/550
Processing batch 148/550
Processing batch 149/550
Processing batch 150/550
Processing batch 151/550
Processing batch 152/550
Processing batch 153/550
Processing batch 154/550
Processing batch 155/550
Processing batch 156/550
Processing batch 157/550
Processing batch 158/550
Processing batch 159/550
Processing batch 160/550
Processing batch 161/550
Processing batch 162/550
Processing batch 163/550
Processing batch 164/550
Processing batch 165/550
Processing batch 166/550
Processing batch 167/550
Processing batch 168/550
Processing batch 169/550
Processing batch 170/550
Processing batch 171/550
Processing batch 172/550
Processing batch 173/550
Processing batch 174/550
Processing batch 175/550
Processing batch 176/550
Processing batch 177/550
Processing batch 178/550
Processing batch 179/550
Processing batch 180/550
Processing batch 181/550
Processing batch 182/550
Processing batch 183/550
Processing batch 184/550
Processing batch 185/550
Processing batch 186/550
Processing batch 187/550
Processing batch 188/550
Processing batch 189/550
Processing batch 190/550
Processing batch 191/550
Processing batch 192/550
Processing batch 193/550
Processing batch 194/550
Processing batch 195/550
Processing batch 196/550
Processing batch 197/550
Processing batch 198/550
Processing batch 199/550
Processing batch 200/550
Processing batch 201/550
Processing batch 202/550
Processing batch 203/550
Processing batch 204/550
Processing batch 205/550
Processing batch 206/550
Processing batch 207/550
Processing batch 208/550
Processing batch 209/550
Processing batch 210/550
Processing batch 211/550
Processing batch 212/550
Processing batch 213/550
Processing batch 214/550
Processing batch 215/550
Processing batch 216/550
Processing batch 217/550
Processing batch 218/550
Processing batch 219/550
Processing batch 220/550
Processing batch 221/550
Processing batch 222/550
Processing batch 223/550
Processing batch 224/550
Processing batch 225/550
Processing batch 226/550
Processing batch 227/550
Processing batch 228/550
Processing batch 229/550
Processing batch 230/550
Processing batch 231/550
Processing batch 232/550
Processing batch 233/550
Processing batch 234/550
Processing batch 235/550
Processing batch 236/550
Processing batch 237/550
Processing batch 238/550
Processing batch 239/550
Processing batch 240/550
Processing batch 241/550
Processing batch 242/550
Processing batch 243/550
Processing batch 244/550
Processing batch 245/550
Processing batch 246/550
Processing batch 247/550
Processing batch 248/550
Processing batch 249/550
Processing batch 250/550
Processing batch 251/550
Processing batch 252/550
Processing batch 253/550
Processing batch 254/550
Processing batch 255/550
Processing batch 256/550
Processing batch 257/550
Processing batch 258/550
Processing batch 259/550
Processing batch 260/550
Processing batch 261/550
Processing batch 262/550
Processing batch 263/550
Processing batch 264/550
Processing batch 265/550
Processing batch 266/550
Processing batch 267/550
Processing batch 268/550
Processing batch 269/550
Processing batch 270/550
Processing batch 271/550
Processing batch 272/550
Processing batch 273/550
Processing batch 274/550
Processing batch 275/550
Processing batch 276/550
Processing batch 277/550
Processing batch 278/550
Processing batch 279/550
Processing batch 280/550
Processing batch 281/550
Processing batch 282/550
Processing batch 283/550
Processing batch 284/550
Processing batch 285/550
Processing batch 286/550
Processing batch 287/550
Processing batch 288/550
Processing batch 289/550
Processing batch 290/550
Processing batch 291/550
Processing batch 292/550
Processing batch 293/550
Processing batch 294/550
Processing batch 295/550
Processing batch 296/550
Processing batch 297/550
Processing batch 298/550
Processing batch 299/550
Processing batch 300/550
Processing batch 301/550
Processing batch 302/550
Processing batch 303/550
Processing batch 304/550
Processing batch 305/550
Processing batch 306/550
Processing batch 307/550
Processing batch 308/550
Processing batch 309/550
Processing batch 310/550
Processing batch 311/550
Processing batch 312/550
Processing batch 313/550
Processing batch 314/550
Processing batch 315/550
Processing batch 316/550
Processing batch 317/550
Processing batch 318/550
Processing batch 319/550
Processing batch 320/550
Processing batch 321/550
Processing batch 322/550
Processing batch 323/550
Processing batch 324/550
Processing batch 325/550
Processing batch 326/550
Processing batch 327/550
Processing batch 328/550
Processing batch 329/550
Processing batch 330/550
Processing batch 331/550
Processing batch 332/550
Processing batch 333/550
Processing batch 334/550
Processing batch 335/550
Processing batch 336/550
Processing batch 337/550
Processing batch 338/550
Processing batch 339/550
Processing batch 340/550
Processing batch 341/550
Processing batch 342/550
Processing batch 343/550
Processing batch 344/550
Processing batch 345/550
Processing batch 346/550
Processing batch 347/550
Processing batch 348/550
Processing batch 349/550
Processing batch 350/550
Processing batch 351/550
Processing batch 352/550
Processing batch 353/550
Processing batch 354/550
Processing batch 355/550
Processing batch 356/550
Processing batch 357/550
Processing batch 358/550
Processing batch 359/550
Processing batch 360/550
Processing batch 361/550
Processing batch 362/550
Processing batch 363/550
Processing batch 364/550
Processing batch 365/550
Processing batch 366/550
Processing batch 367/550
Processing batch 368/550
Processing batch 369/550
Processing batch 370/550
Processing batch 371/550
Processing batch 372/550
Processing batch 373/550
Processing batch 374/550
Processing batch 375/550
Processing batch 376/550
Processing batch 377/550
Processing batch 378/550
Processing batch 379/550
Processing batch 380/550
Processing batch 381/550
Processing batch 382/550
Processing batch 383/550
Processing batch 384/550
Processing batch 385/550
Processing batch 386/550
Processing batch 387/550
Processing batch 388/550
Processing batch 389/550
Processing batch 390/550
Processing batch 391/550
Processing batch 392/550
Processing batch 393/550
Processing batch 394/550
Processing batch 395/550
Processing batch 396/550
Processing batch 397/550
Processing batch 398/550
Processing batch 399/550
Processing batch 400/550
Processing batch 401/550
Processing batch 402/550
Processing batch 403/550
Processing batch 404/550
Processing batch 405/550
Processing batch 406/550
Processing batch 407/550
Processing batch 408/550
Processing batch 409/550
Processing batch 410/550
Processing batch 411/550
Processing batch 412/550
Processing batch 413/550
Processing batch 414/550
Processing batch 415/550
Processing batch 416/550
Processing batch 417/550
Processing batch 418/550
Processing batch 419/550
Processing batch 420/550
Processing batch 421/550
Processing batch 422/550
Processing batch 423/550
Processing batch 424/550
Processing batch 425/550
Processing batch 426/550
Processing batch 427/550
Processing batch 428/550
Processing batch 429/550
Processing batch 430/550
Processing batch 431/550
Processing batch 432/550
Processing batch 433/550
Processing batch 434/550
Processing batch 435/550
Processing batch 436/550
Processing batch 437/550
Processing batch 438/550
Processing batch 439/550
Processing batch 440/550
Processing batch 441/550
Processing batch 442/550
Processing batch 443/550
Processing batch 444/550
Processing batch 445/550
Processing batch 446/550
Processing batch 447/550
Processing batch 448/550
Processing batch 449/550
Processing batch 450/550
Processing batch 451/550
Processing batch 452/550
Processing batch 453/550
Processing batch 454/550
Processing batch 455/550
Processing batch 456/550
Processing batch 457/550
Processing batch 458/550
Processing batch 459/550
Processing batch 460/550
Processing batch 461/550
Processing batch 462/550
Processing batch 463/550
Processing batch 464/550
Processing batch 465/550
Processing batch 466/550
Processing batch 467/550
Processing batch 468/550
Processing batch 469/550
Processing batch 470/550
Processing batch 471/550
Processing batch 472/550
Processing batch 473/550
Processing batch 474/550
Processing batch 475/550
Processing batch 476/550
Processing batch 477/550
Processing batch 478/550
Processing batch 479/550
Processing batch 480/550
Processing batch 481/550
Processing batch 482/550
Processing batch 483/550
Processing batch 484/550
Processing batch 485/550
Processing batch 486/550
Processing batch 487/550
Processing batch 488/550
Processing batch 489/550
Processing batch 490/550
Processing batch 491/550
Processing batch 492/550
Processing batch 493/550
Processing batch 494/550
Processing batch 495/550
Processing batch 496/550
Processing batch 497/550
Processing batch 498/550
Processing batch 499/550
Processing batch 500/550
Processing batch 501/550
Processing batch 502/550
Processing batch 503/550
Processing batch 504/550
Processing batch 505/550
Processing batch 506/550
Processing batch 507/550
Processing batch 508/550
Processing batch 509/550
Processing batch 510/550
Processing batch 511/550
Processing batch 512/550
Processing batch 513/550
Processing batch 514/550
Processing batch 515/550
Processing batch 516/550
Processing batch 517/550
Processing batch 518/550
Processing batch 519/550
Processing batch 520/550
Processing batch 521/550
Processing batch 522/550
Processing batch 523/550
Processing batch 524/550
Processing batch 525/550
Processing batch 526/550
Processing batch 527/550
Processing batch 528/550
Processing batch 529/550
Processing batch 530/550
Processing batch 531/550
Processing batch 532/550
Processing batch 533/550
Processing batch 534/550
Processing batch 535/550
Processing batch 536/550
Processing batch 537/550
Processing batch 538/550
Processing batch 539/550
Processing batch 540/550
Processing batch 541/550
Processing batch 542/550
Processing batch 543/550
Processing batch 544/550
Processing batch 545/550
Processing batch 546/550
Processing batch 547/550
Processing batch 548/550
Processing batch 549/550
Processing batch 550/550
Generated lattice embeddings shape: torch.Size([549367, 768])
Generating lattice containment embeddings for validation...
Generating lattice containment embeddings on cuda
Processing 9842 samples in batches of 1000
Processing batch 1/10
Processing batch 2/10
Processing batch 3/10
Processing batch 4/10
Processing batch 5/10
Processing batch 6/10
Processing batch 7/10
Processing batch 8/10
Processing batch 9/10
Processing batch 10/10
Generated lattice embeddings shape: torch.Size([9842, 768])
Generating lattice containment embeddings for test...
Generating lattice containment embeddings on cuda
Processing 9824 samples in batches of 1000
Processing batch 1/10
Processing batch 2/10
Processing batch 3/10
Processing batch 4/10
Processing batch 5/10
Processing batch 6/10
Processing batch 7/10
Processing batch 8/10
Processing batch 9/10
Processing batch 10/10
Generated lattice embeddings shape: torch.Size([9824, 768])

Dataset Statistics:
------------------------------
Train: {'entailment': 183416, 'neutral': 182764, 'contradiction': 183187}
Validation: {'entailment': 3329, 'neutral': 3235, 'contradiction': 3278}
Test: {'entailment': 3368, 'neutral': 3219, 'contradiction': 3237}

Data loading pipeline completed!
Creating balanced data loaders...
Batch size: 1020
Samples per class per batch: 340
Effective batch size: 1020
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class: 340
  Batch size: 1020
  Number of batches: 537
  Class 2: 183187 samples
  Class 0: 183416 samples
  Class 1: 182764 samples
BalancedBatchSampler initialized:
  Classes: [2, 0, 1]
  Samples per class: 340
  Batch size: 1020
  Number of batches: 9
  Class 2: 3278 samples
  Class 0: 3329 samples
  Class 1: 3235 samples
Data loading completed!
Train: 549367 samples
Val: 9842 samples
Test: 9824 samples
Creating model and trainer...
==================================================
Model created with 1,089,355 parameters
Loss function created: default contrastive loss
  Contrastive weight: 1.0
  Reconstruction weight: 0
  Margin: 1.0
Optimizer created (lr=0.001)
Trainer initialized on device: cuda
Model parameters: 1,089,355
Starting model training...
==================================================
Starting training...
==================================================

Epoch 1/50
------------------------------
Batch 0/537: Loss = 11.0438 (C: 11.0438, R: 0.0000)
Batch 0/537: Loss = 11.0438 (C: 11.0438, R: 0.0000)
  Distance Debug: Pos=0.37±0.05, Neg=0.37±0.04, Ratio=1.01x, Gap=-0.41
Batch 100/537: Loss = 9.7368 (C: 9.7368, R: 0.0000)
Batch 200/537: Loss = 9.7086 (C: 9.7086, R: 0.0000)
Batch 300/537: Loss = 9.7002 (C: 9.7002, R: 0.0000)
Batch 400/537: Loss = 9.6860 (C: 9.6860, R: 0.0000)
Batch 500/537: Loss = 9.6668 (C: 9.6668, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.646066665649414
  reconstruction_loss raw: 0.0
  total_loss raw: 9.646066665649414
Epoch 1 completed in 15.13s
Train Loss: 9.7217 (C: 9.7217)
Val Loss: 9.6740 (C: 9.6740)
Distance Stats:
  Train: Pos=0.37, Neg=0.37, Ratio=1.01x
  Val:   Pos=1.01, Neg=1.44, Ratio=1.43x
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250712_110205/checkpoints/best_model.pt
New best model saved (Val Loss: 9.6740)

Epoch 2/50
------------------------------
Batch 0/537: Loss = 9.6769 (C: 9.6769, R: 0.0000)
Batch 0/537: Loss = 9.6769 (C: 9.6769, R: 0.0000)
  Distance Debug: Pos=1.05±1.08, Neg=1.43±1.35, Ratio=1.36x, Gap=-7.45
Batch 100/537: Loss = 9.6524 (C: 9.6524, R: 0.0000)
Batch 200/537: Loss = 9.6626 (C: 9.6626, R: 0.0000)
Batch 300/537: Loss = 9.6621 (C: 9.6621, R: 0.0000)
Batch 400/537: Loss = 9.6946 (C: 9.6946, R: 0.0000)
Batch 500/537: Loss = 9.6415 (C: 9.6415, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.656937599182129
  reconstruction_loss raw: 0.0
  total_loss raw: 9.656937599182129
Epoch 2 completed in 7.96s
Train Loss: 9.6607 (C: 9.6607)
Val Loss: 9.6361 (C: 9.6361)
Distance Stats:
  Train: Pos=1.05, Neg=1.43, Ratio=1.36x
  Val:   Pos=0.90, Neg=1.31, Ratio=1.45x
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250712_110205/checkpoints/best_model.pt
New best model saved (Val Loss: 9.6361)

Epoch 3/50
------------------------------
Batch 0/537: Loss = 9.6274 (C: 9.6274, R: 0.0000)
Batch 0/537: Loss = 9.6274 (C: 9.6274, R: 0.0000)
  Distance Debug: Pos=0.88±1.14, Neg=1.20±1.39, Ratio=1.36x, Gap=-7.45
Batch 100/537: Loss = 9.6493 (C: 9.6493, R: 0.0000)
Batch 200/537: Loss = 9.6803 (C: 9.6803, R: 0.0000)
Batch 300/537: Loss = 9.6222 (C: 9.6222, R: 0.0000)
Batch 400/537: Loss = 9.6240 (C: 9.6240, R: 0.0000)
Batch 500/537: Loss = 9.6401 (C: 9.6401, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.628328323364258
  reconstruction_loss raw: 0.0
  total_loss raw: 9.628328323364258
Epoch 3 completed in 7.75s
Train Loss: 9.6231 (C: 9.6231)
Val Loss: 9.6315 (C: 9.6315)
Distance Stats:
  Train: Pos=0.88, Neg=1.20, Ratio=1.36x
  Val:   Pos=0.82, Neg=1.21, Ratio=1.47x
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250712_110205/checkpoints/best_model.pt
New best model saved (Val Loss: 9.6315)

Epoch 4/50
------------------------------
Batch 0/537: Loss = 9.5988 (C: 9.5988, R: 0.0000)
Batch 0/537: Loss = 9.5988 (C: 9.5988, R: 0.0000)
  Distance Debug: Pos=0.86±1.20, Neg=1.24±1.48, Ratio=1.44x, Gap=-9.41
Batch 100/537: Loss = 9.5955 (C: 9.5955, R: 0.0000)
Batch 200/537: Loss = 9.6432 (C: 9.6432, R: 0.0000)
Batch 300/537: Loss = 9.5779 (C: 9.5779, R: 0.0000)
Batch 400/537: Loss = 9.5679 (C: 9.5679, R: 0.0000)
Batch 500/537: Loss = 9.5821 (C: 9.5821, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.66159439086914
  reconstruction_loss raw: 0.0
  total_loss raw: 9.66159439086914
Epoch 4 completed in 7.12s
Train Loss: 9.5932 (C: 9.5932)
Val Loss: 9.6221 (C: 9.6221)
Distance Stats:
  Train: Pos=0.86, Neg=1.24, Ratio=1.44x
  Val:   Pos=0.76, Neg=1.12, Ratio=1.47x
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250712_110205/checkpoints/best_model.pt
New best model saved (Val Loss: 9.6221)

Epoch 5/50
------------------------------
Batch 0/537: Loss = 9.5580 (C: 9.5580, R: 0.0000)
Batch 0/537: Loss = 9.5580 (C: 9.5580, R: 0.0000)
  Distance Debug: Pos=0.79±1.06, Neg=1.13±1.31, Ratio=1.43x, Gap=-7.90
Batch 100/537: Loss = 9.5921 (C: 9.5921, R: 0.0000)
Batch 200/537: Loss = 9.5354 (C: 9.5354, R: 0.0000)
Batch 300/537: Loss = 9.5586 (C: 9.5586, R: 0.0000)
Batch 400/537: Loss = 9.5632 (C: 9.5632, R: 0.0000)
Batch 500/537: Loss = 9.5864 (C: 9.5864, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.624629020690918
  reconstruction_loss raw: 0.0
  total_loss raw: 9.624629020690918
Epoch 5 completed in 7.55s
Train Loss: 9.5655 (C: 9.5655)
Val Loss: 9.6227 (C: 9.6227)
Distance Stats:
  Train: Pos=0.79, Neg=1.13, Ratio=1.43x
  Val:   Pos=0.70, Neg=1.05, Ratio=1.50x
No improvement for 1 epochs
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250712_110205/checkpoints/checkpoint_epoch_5.pt

Epoch 6/50
------------------------------
Batch 0/537: Loss = 9.5486 (C: 9.5486, R: 0.0000)
Batch 0/537: Loss = 9.5486 (C: 9.5486, R: 0.0000)
  Distance Debug: Pos=0.73±1.09, Neg=1.05±1.32, Ratio=1.45x, Gap=-7.73
Batch 100/537: Loss = 9.5303 (C: 9.5303, R: 0.0000)
Batch 200/537: Loss = 9.5183 (C: 9.5183, R: 0.0000)
Batch 300/537: Loss = 9.5441 (C: 9.5441, R: 0.0000)
Batch 400/537: Loss = 9.5617 (C: 9.5617, R: 0.0000)
Batch 500/537: Loss = 9.5627 (C: 9.5627, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.644110679626465
  reconstruction_loss raw: 0.0
  total_loss raw: 9.644110679626465
Epoch 6 completed in 7.29s
Train Loss: 9.5389 (C: 9.5389)
Val Loss: 9.6245 (C: 9.6245)
Distance Stats:
  Train: Pos=0.73, Neg=1.05, Ratio=1.45x
  Val:   Pos=0.67, Neg=0.97, Ratio=1.46x
No improvement for 2 epochs

Epoch 7/50
------------------------------
Batch 0/537: Loss = 9.4704 (C: 9.4704, R: 0.0000)
Batch 0/537: Loss = 9.4704 (C: 9.4704, R: 0.0000)
  Distance Debug: Pos=0.66±0.96, Neg=0.97±1.17, Ratio=1.48x, Gap=-6.89
Batch 100/537: Loss = 9.5284 (C: 9.5284, R: 0.0000)
Batch 200/537: Loss = 9.4936 (C: 9.4936, R: 0.0000)
Batch 300/537: Loss = 9.4571 (C: 9.4571, R: 0.0000)
Batch 400/537: Loss = 9.5230 (C: 9.5230, R: 0.0000)
Batch 500/537: Loss = 9.5060 (C: 9.5060, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.614115715026855
  reconstruction_loss raw: 0.0
  total_loss raw: 9.614115715026855
Epoch 7 completed in 6.94s
Train Loss: 9.5126 (C: 9.5126)
Val Loss: 9.6252 (C: 9.6252)
Distance Stats:
  Train: Pos=0.66, Neg=0.97, Ratio=1.48x
  Val:   Pos=0.64, Neg=0.91, Ratio=1.43x
No improvement for 3 epochs

Epoch 8/50
------------------------------
Batch 0/537: Loss = 9.4700 (C: 9.4700, R: 0.0000)
Batch 0/537: Loss = 9.4700 (C: 9.4700, R: 0.0000)
  Distance Debug: Pos=0.58±0.76, Neg=0.84±0.94, Ratio=1.46x, Gap=-5.45
Batch 100/537: Loss = 9.5238 (C: 9.5238, R: 0.0000)
Batch 200/537: Loss = 9.5754 (C: 9.5754, R: 0.0000)
Batch 300/537: Loss = 9.5082 (C: 9.5082, R: 0.0000)
Batch 400/537: Loss = 9.5029 (C: 9.5029, R: 0.0000)
Batch 500/537: Loss = 9.5318 (C: 9.5318, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.648381233215332
  reconstruction_loss raw: 0.0
  total_loss raw: 9.648381233215332
Epoch 8 completed in 7.28s
Train Loss: 9.4875 (C: 9.4875)
Val Loss: 9.6260 (C: 9.6260)
Distance Stats:
  Train: Pos=0.58, Neg=0.84, Ratio=1.46x
  Val:   Pos=0.61, Neg=0.88, Ratio=1.45x
No improvement for 4 epochs

Epoch 9/50
------------------------------
Batch 0/537: Loss = 9.4319 (C: 9.4319, R: 0.0000)
Batch 0/537: Loss = 9.4319 (C: 9.4319, R: 0.0000)
  Distance Debug: Pos=0.59±0.90, Neg=0.87±1.09, Ratio=1.48x, Gap=-8.44
Batch 100/537: Loss = 9.4418 (C: 9.4418, R: 0.0000)
Batch 200/537: Loss = 9.5133 (C: 9.5133, R: 0.0000)
Batch 300/537: Loss = 9.4705 (C: 9.4705, R: 0.0000)
Batch 400/537: Loss = 9.5002 (C: 9.5002, R: 0.0000)
Batch 500/537: Loss = 9.5192 (C: 9.5192, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.661857604980469
  reconstruction_loss raw: 0.0
  total_loss raw: 9.661857604980469
Epoch 9 completed in 7.27s
Train Loss: 9.4669 (C: 9.4669)
Val Loss: 9.6491 (C: 9.6491)
Distance Stats:
  Train: Pos=0.59, Neg=0.87, Ratio=1.48x
  Val:   Pos=0.60, Neg=0.88, Ratio=1.46x
No improvement for 5 epochs

Epoch 10/50
------------------------------
Batch 0/537: Loss = 9.4009 (C: 9.4009, R: 0.0000)
Batch 0/537: Loss = 9.4009 (C: 9.4009, R: 0.0000)
  Distance Debug: Pos=0.57±0.90, Neg=0.85±1.10, Ratio=1.50x, Gap=-7.21
Batch 100/537: Loss = 9.4030 (C: 9.4030, R: 0.0000)
Batch 200/537: Loss = 9.4364 (C: 9.4364, R: 0.0000)
Batch 300/537: Loss = 9.4104 (C: 9.4104, R: 0.0000)
Batch 400/537: Loss = 9.4449 (C: 9.4449, R: 0.0000)
Batch 500/537: Loss = 9.4692 (C: 9.4692, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.637436866760254
  reconstruction_loss raw: 0.0
  total_loss raw: 9.637436866760254
Epoch 10 completed in 7.38s
Train Loss: 9.4449 (C: 9.4449)
Val Loss: 9.6507 (C: 9.6507)
Distance Stats:
  Train: Pos=0.57, Neg=0.85, Ratio=1.50x
  Val:   Pos=0.59, Neg=0.84, Ratio=1.43x
No improvement for 6 epochs
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250712_110205/checkpoints/checkpoint_epoch_10.pt

Epoch 11/50
------------------------------
Batch 0/537: Loss = 9.4184 (C: 9.4184, R: 0.0000)
Batch 0/537: Loss = 9.4184 (C: 9.4184, R: 0.0000)
  Distance Debug: Pos=0.57±0.86, Neg=0.84±1.06, Ratio=1.47x, Gap=-5.78
Batch 100/537: Loss = 9.4068 (C: 9.4068, R: 0.0000)
Batch 200/537: Loss = 9.4195 (C: 9.4195, R: 0.0000)
Batch 300/537: Loss = 9.4244 (C: 9.4244, R: 0.0000)
Batch 400/537: Loss = 9.4265 (C: 9.4265, R: 0.0000)
Batch 500/537: Loss = 9.4780 (C: 9.4780, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.731135368347168
  reconstruction_loss raw: 0.0
  total_loss raw: 9.731135368347168
Epoch 11 completed in 7.33s
Train Loss: 9.4272 (C: 9.4272)
Val Loss: 9.6758 (C: 9.6758)
Distance Stats:
  Train: Pos=0.57, Neg=0.84, Ratio=1.47x
  Val:   Pos=0.60, Neg=0.86, Ratio=1.45x
No improvement for 7 epochs

Epoch 12/50
------------------------------
Batch 0/537: Loss = 9.3665 (C: 9.3665, R: 0.0000)
Batch 0/537: Loss = 9.3665 (C: 9.3665, R: 0.0000)
  Distance Debug: Pos=0.56±0.86, Neg=0.85±1.04, Ratio=1.52x, Gap=-7.95
Batch 100/537: Loss = 9.4298 (C: 9.4298, R: 0.0000)
Batch 200/537: Loss = 9.3949 (C: 9.3949, R: 0.0000)
Batch 300/537: Loss = 9.4587 (C: 9.4587, R: 0.0000)
Batch 400/537: Loss = 9.4054 (C: 9.4054, R: 0.0000)
Batch 500/537: Loss = 9.4676 (C: 9.4676, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.65243148803711
  reconstruction_loss raw: 0.0
  total_loss raw: 9.65243148803711
Epoch 12 completed in 7.38s
Train Loss: 9.4105 (C: 9.4105)
Val Loss: 9.6949 (C: 9.6949)
Distance Stats:
  Train: Pos=0.56, Neg=0.85, Ratio=1.52x
  Val:   Pos=0.59, Neg=0.85, Ratio=1.44x
No improvement for 8 epochs

Epoch 13/50
------------------------------
Batch 0/537: Loss = 9.3740 (C: 9.3740, R: 0.0000)
Batch 0/537: Loss = 9.3740 (C: 9.3740, R: 0.0000)
  Distance Debug: Pos=0.58±0.88, Neg=0.87±1.08, Ratio=1.50x, Gap=-8.61
Batch 100/537: Loss = 9.3623 (C: 9.3623, R: 0.0000)
Batch 200/537: Loss = 9.4000 (C: 9.4000, R: 0.0000)
Batch 300/537: Loss = 9.4245 (C: 9.4245, R: 0.0000)
Batch 400/537: Loss = 9.4246 (C: 9.4246, R: 0.0000)
Batch 500/537: Loss = 9.4487 (C: 9.4487, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.693509101867676
  reconstruction_loss raw: 0.0
  total_loss raw: 9.693509101867676
Epoch 13 completed in 7.67s
Train Loss: 9.3953 (C: 9.3953)
Val Loss: 9.6813 (C: 9.6813)
Distance Stats:
  Train: Pos=0.58, Neg=0.87, Ratio=1.50x
  Val:   Pos=0.56, Neg=0.81, Ratio=1.44x
No improvement for 9 epochs

Epoch 14/50
------------------------------
Batch 0/537: Loss = 9.3270 (C: 9.3270, R: 0.0000)
Batch 0/537: Loss = 9.3270 (C: 9.3270, R: 0.0000)
  Distance Debug: Pos=0.55±0.83, Neg=0.83±1.02, Ratio=1.52x, Gap=-5.48
Batch 100/537: Loss = 9.3294 (C: 9.3294, R: 0.0000)
Batch 200/537: Loss = 9.3181 (C: 9.3181, R: 0.0000)
Batch 300/537: Loss = 9.3854 (C: 9.3854, R: 0.0000)
Batch 400/537: Loss = 9.4190 (C: 9.4190, R: 0.0000)
Batch 500/537: Loss = 9.3865 (C: 9.3865, R: 0.0000)
DEBUG: First validation batch:
  contrastive_loss raw: 9.650391578674316
  reconstruction_loss raw: 0.0
  total_loss raw: 9.650391578674316
Epoch 14 completed in 7.91s
Train Loss: 9.3824 (C: 9.3824)
Val Loss: 9.6923 (C: 9.6923)
Distance Stats:
  Train: Pos=0.55, Neg=0.83, Ratio=1.52x
  Val:   Pos=0.57, Neg=0.82, Ratio=1.44x
No improvement for 10 epochs
Early stopping triggered after 14 epochs

Simplified training completed!
Checkpoint saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250712_110205/checkpoints/final_model.pt
Training history saved: entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250712_110205/checkpoints/training_history_20250712_110433.json
Training completed!
Best model saved at epoch 4
Best validation loss: 9.622093
Loading best model from entailment_surfaces/supervised_contrastive_autoencoder/experiments/contrastive_autoencoder_20250712_110205/checkpoints/best_model.pt

PIPELINE FAILED: Weights only load failed. This file can still be loaded, to do so you have two options 
	(1) Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
Pipeline failed!

Analysis completed with exit code: 1
Time: Sat 12 Jul 11:04:36 BST 2025

=== ANALYSIS FAILED ===
Please check the error output above for debugging information.


Job finished.
